
import os
import uuid
import re
import io
import tempfile
import urllib.request
from pathlib import Path
from datetime import datetime, timedelta, date

from flask import (
    Flask, request, render_template,
    redirect, url_for, session, abort, jsonify
)
import boto3
from boto3.s3.transfer import TransferConfig
import qrcode
from PIL import Image, ImageDraw, ImageFont
from urllib.parse import urlparse, parse_qs
import requests
import zipfile
import jwt  # PyJWT
from functools import wraps

import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage

# â”€â”€ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ â”€â”€
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
import atexit
import threading

# â”€â”€ ë³€ê²½ëœ ë¶€ë¶„: video íŒŒì¼ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ import (MoviePy ìµœì‹  ê²½ë¡œ) â”€â”€
from moviepy.video.io.VideoFileClip import VideoFileClip

# â”€â”€ ë²ˆì—­ ê´€ë ¨ import ì¶”ê°€ â”€â”€
from googletrans import Translator
import time

# ===== ìˆ˜ë£Œì¦ ê´€ë ¨ ì¶”ê°€ import =====
from reportlab.lib.pagesizes import A4, landscape
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.utils import ImageReader

import base64
from concurrent.futures import ThreadPoolExecutor
import hashlib


# ==== í™˜ê²½ë³€ìˆ˜ ì„¤ì • ====
ADMIN_EMAIL       = os.environ.get('ADMIN_EMAIL', '')
ADMIN_PASSWORD    = os.environ.get('ADMIN_PASSWORD', 'changeme')
JWT_SECRET        = os.environ.get('JWT_SECRET', 'supersecretjwt')
JWT_ALGORITHM     = 'HS256'
JWT_EXPIRES_HOURS = 4

AWS_ACCESS_KEY    = os.environ['AWS_ACCESS_KEY']
AWS_SECRET_KEY    = os.environ['AWS_SECRET_KEY']
REGION_NAME       = os.environ['REGION_NAME']
BUCKET_NAME       = os.environ['BUCKET_NAME']
APP_BASE_URL      = os.environ.get('APP_BASE_URL', 'http://localhost:5000/watch/')
SECRET_KEY        = os.environ.get('FLASK_SECRET_KEY', 'supersecret')


# ===== ì „ì—­ ë³€ìˆ˜ ì¶”ê°€ (í™˜ê²½ë³€ìˆ˜ ì„¹ì…˜ ë’¤ì—) =====
# ìˆ˜ë£Œì¦ ê´€ë ¨ ì„¤ì •
CERTIFICATE_CONFIG = {
    'org_name': 'í•œêµ­ì‚°ì—…ì•ˆì „ë³´ê±´ê³µë‹¨ì´ì‚¬ì¥',
    'agency_name': 'ì¤‘ë¶€ì¬í•´ì˜ˆë°©ê´€ë¦¬ì›',
    'title_kor': 'QR ê¸°ì´ˆì•ˆì „ ì´ìˆ˜ì¦',
    'title_eng': 'Certificate of Basic OSH Training in Construction',
    'background_image': 'static/certificate_bg.png',
    'profile_image': 'static/profile_sample.png',
    'default_profile': 'static/profile_default.png',
}

# ìŠ¤ë ˆë“œ í’€ (PDF ìƒì„± ë³‘ë ¬ ì²˜ë¦¬ìš©)
pdf_executor = ThreadPoolExecutor(max_workers=4)

# ==== ë²ˆì—­ ê´€ë ¨ ì„¤ì • - ìˆ˜ì •ë¨ ====
# ì „ì—­ ë²ˆì—­ê¸° ì¸ìŠ¤í„´ìŠ¤
translator = Translator()

# ì§€ì› ì–¸ì–´ ì½”ë“œ ë§¤í•‘ - ì¤‘êµ­ì–´ ì½”ë“œ ìˆ˜ì •
SUPPORTED_LANGUAGES = {
    'ko': 'í•œêµ­ì–´',
    'en': 'English',
    'zh-cn': 'ä¸­æ–‡',      # 'zh' â†’ 'zh-cn'ìœ¼ë¡œ ë³€ê²½
    'vi': 'Tiáº¿ng Viá»‡t',
    'th': 'à¹„à¸—à¸¢',
    'uz': 'O\'zbek',
    'ja': 'æ—¥æœ¬èª'
}

# ==== Firebase Admin + Firestore + Storage ì´ˆê¸°í™” ====
if not firebase_admin._apps:
    firebase_creds = {
        "type":                        os.environ["type"],
        "project_id":                  os.environ["project_id"],
        "private_key_id":              os.environ["private_key_id"],
        "private_key":                 os.environ["private_key"].replace('\\n','\n'),
        "client_email":                os.environ["client_email"],
        "client_id":                   os.environ["client_id"],
        "auth_uri":                    os.environ["auth_uri"],
        "token_uri":                   os.environ["token_uri"],
        "auth_provider_x509_cert_url": os.environ["auth_provider_x509_cert_url"],
        "client_x509_cert_url":        os.environ["client_x509_cert_url"]
    }
    cred = credentials.Certificate(firebase_creds)
    firebase_admin.initialize_app(cred, {
        'storageBucket': f"{os.environ['project_id']}.appspot.com"
    })

db     = firestore.client()
bucket = storage.bucket()  # Firebase Storage ê¸°ë³¸ ë²„í‚·

# ==== Flask ì•± ì„¤ì • ====
app = Flask(__name__)
app.secret_key                   = SECRET_KEY
app.config['UPLOAD_FOLDER']      = 'static'
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MBë¡œ ì œí•œ (Railway ìµœì í™”)
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# ==== Wasabi S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ====
s3 = boto3.client(
    's3',
    aws_access_key_id     = AWS_ACCESS_KEY,
    aws_secret_access_key = AWS_SECRET_KEY,
    region_name           = REGION_NAME,
    endpoint_url          = f'https://s3.{REGION_NAME}.wasabisys.com'
)
config = TransferConfig(
    multipart_threshold = 1024 * 1024 * 25,
    multipart_chunksize = 1024 * 1024 * 50,
    max_concurrency     = 5,
    use_threads         = True
)

# ==== ìˆ˜ì •ëœ ë²ˆì—­ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====

def translate_text(text, target_language):
    """
    ìˆ˜ì •ëœ ë²ˆì—­ í•¨ìˆ˜ - Railway í™˜ê²½ ìµœì í™”
    """
    try:
        if target_language == 'ko' or not text.strip():
            return text
        
        # ì¤‘êµ­ì–´ ì–¸ì–´ ì½”ë“œ ìˆ˜ì •
        google_lang_code = target_language
        if target_language == 'zh-cn':
            google_lang_code = 'zh'
        
        # ë²ˆì—­ ìš”ì²­ (í•œêµ­ì–´ â†’ ëŒ€ìƒ ì–¸ì–´)
        result = translator.translate(text, src='ko', dest=google_lang_code)
        translated_text = result.text
        
        app.logger.info(f"ë²ˆì—­ ì™„ë£Œ: '{text}' â†’ '{translated_text}' ({target_language})")
        return translated_text
        
    except Exception as e:
        app.logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨ ({target_language}): {e}, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
        return text

def create_multilingual_metadata(korean_text):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë“  ì§€ì› ì–¸ì–´ë¡œ ë²ˆì—­
    """
    translations = {}
    
    if not korean_text.strip():
        return {lang: '' for lang in SUPPORTED_LANGUAGES.keys()}
    
    for lang_code in SUPPORTED_LANGUAGES.keys():
        try:
            translated = translate_text(korean_text, lang_code)
            translations[lang_code] = translated
            
            if lang_code != 'ko':
                time.sleep(0.2)
                
        except Exception as e:
            app.logger.error(f"ì–¸ì–´ {lang_code} ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
            translations[lang_code] = korean_text
    
    return translations

# ==== ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====

def generate_presigned_url(key, expires_in=86400):
    """
    S3 ê°ì²´ì— ëŒ€í•´ presigned URL ìƒì„±
    expires_in: URL ìœ íš¨ ê¸°ê°„(ì´ˆ)
    """
    return s3.generate_presigned_url(
        ClientMethod='get_object',
        Params={'Bucket': BUCKET_NAME, 'Key': key},
        ExpiresIn=expires_in
    )

# ==== ìˆ˜ì •ëœ í•œêµ­ì–´ í°íŠ¸ í•¨ìˆ˜ë“¤ ====

def download_korean_font():
    """
    Railway í™˜ê²½ì—ì„œ ì•ˆì •ì ì¸ í•œêµ­ì–´ í°íŠ¸ ë‹¤ìš´ë¡œë“œ - ì‹¤ì œ ì‘ë™í•˜ëŠ” URLë¡œ ìˆ˜ì •
    """
    font_dir = Path("fonts")
    font_dir.mkdir(exist_ok=True)
    
    font_path = font_dir / "NotoSansKR-Regular.ttf"
    
    if font_path.exists():
        return str(font_path)
    
    # ì‹¤ì œ ì‘ë™í•˜ëŠ” í•œêµ­ì–´ í°íŠ¸ URLë“¤
    font_urls = [
        # TTF í˜•ì‹ (PILì—ì„œ ê°€ì¥ ì•ˆì •ì )
        "https://cdn.jsdelivr.net/gh/fonts-archive/NotoSansKR/NotoSansKR-Regular.ttf",
        # OTF í˜•ì‹ ë°±ì—…
        "https://fonts.gstatic.com/ea/notosanskr/v2/NotoSansKR-Regular.otf",
        # ë‹¤ë¥¸ ë°±ì—… ì†ŒìŠ¤
        "https://github.com/notofonts/noto-cjk/raw/main/Sans/OTF/Korean/NotoSansCJKkr-Regular.otf"
    ]
    
    for i, font_url in enumerate(font_urls):
        try:
            app.logger.info(f"ğŸ“¥ í•œêµ­ì–´ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ {i+1}/{len(font_urls)}: {font_url}")
            
            # User-Agent í—¤ë” ì¶”ê°€ (ì¼ë¶€ ì„œë²„ì—ì„œ í•„ìš”)
            req = urllib.request.Request(font_url, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            
            with urllib.request.urlopen(req, timeout=30) as response:
                font_data = response.read()
                
            # íŒŒì¼ ì“°ê¸°
            font_path.write_bytes(font_data)
            
            # íŒŒì¼ì´ ì‹¤ì œë¡œ ë‹¤ìš´ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if font_path.exists() and font_path.stat().st_size > 10240:  # ìµœì†Œ 10KB
                app.logger.info(f"âœ… í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {font_path} (í¬ê¸°: {font_path.stat().st_size:,} bytes)")
                return str(font_path)
            else:
                font_path.unlink(missing_ok=True)  # ì‹¤íŒ¨í•œ íŒŒì¼ ì‚­ì œ
                
        except Exception as e:
            app.logger.warning(f"âŒ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({i+1}): {e}")
            font_path.unlink(missing_ok=True)
    
    app.logger.error("âŒ ëª¨ë“  í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ ì‹¤íŒ¨")
    return None

def get_korean_font(size=36):  # ê¸°ë³¸ í¬ê¸°ë¥¼ 24ì—ì„œ 36ìœ¼ë¡œ ì¦ê°€
    """
    Railway í™˜ê²½ì—ì„œ ì•ˆì „í•œ í•œêµ­ì–´ í°íŠ¸ ë¡œë“œ
    """
    try:
        # 1. ì‹œìŠ¤í…œ í°íŠ¸ ìš°ì„  ì‹œë„ (Railway Dockerfileì—ì„œ ì„¤ì¹˜í•œ í°íŠ¸)
        system_fonts = [
            '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc',
            '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
            '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'
        ]
        
        for font_path in system_fonts:
            if os.path.exists(font_path):
                try:
                    font = ImageFont.truetype(font_path, size)
                    app.logger.info(f"âœ… ì‹œìŠ¤í…œ í°íŠ¸ ì‚¬ìš©: {font_path}")
                    return font
                except Exception as e:
                    app.logger.warning(f"ì‹œìŠ¤í…œ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ {font_path}: {e}")
                    continue
        
        # 2. ë‹¤ìš´ë¡œë“œí•œ í°íŠ¸ ì‹œë„
        korean_font_path = download_korean_font()
        if korean_font_path and os.path.exists(korean_font_path):
            try:
                font = ImageFont.truetype(korean_font_path, size)
                app.logger.info(f"âœ… ë‹¤ìš´ë¡œë“œ í°íŠ¸ ì‚¬ìš©: {korean_font_path}")
                return font
            except Exception as e:
                app.logger.warning(f"ë‹¤ìš´ë¡œë“œ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. í´ë°±: ê¸°ë³¸ í°íŠ¸ (í•œêµ­ì–´ ì§€ì› ì•ˆ ë¨)
        app.logger.warning("âš ï¸ í•œêµ­ì–´ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return ImageFont.load_default()
        
    except Exception as e:
        app.logger.error(f"í°íŠ¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        return ImageFont.load_default()

def get_text_dimensions(text, font, draw):
    """
    ì•ˆì „í•œ í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° (ìœ ë‹ˆì½”ë“œ ì˜¤ë¥˜ ë°©ì§€)
    """
    try:
        # í•œêµ­ì–´ í…ìŠ¤íŠ¸ê°€ ê¸°ë³¸ í°íŠ¸ì—ì„œ ì˜¤ë¥˜ë‚˜ëŠ” ê²½ìš° ì²˜ë¦¬
        bbox = draw.textbbox((0, 0), text, font=font)
        return bbox[2] - bbox[0], bbox[3] - bbox[1]
    except (UnicodeEncodeError, AttributeError) as e:
        app.logger.warning(f"í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° ì˜¤ë¥˜: {e}, í´ë°± ì‚¬ìš©")
        try:
            # êµ¬ë²„ì „ Pillow ë°©ì‹ ì‹œë„
            return draw.textsize(text, font=font)
        except (UnicodeEncodeError, AttributeError):
            # ìµœí›„ ìˆ˜ë‹¨: ëŒ€ëµì ì¸ í¬ê¸° ê³„ì‚°
            char_width = 12  # í‰ê·  ë¬¸ì í­
            char_height = font.size if hasattr(font, 'size') else 24
            return len(text) * char_width, char_height

def split_korean_text(text, font, max_width, draw):
    """
    ì•ˆì „í•œ í•œêµ­ì–´ í…ìŠ¤íŠ¸ ë¶„í•  (ìœ ë‹ˆì½”ë“œ ì˜¤ë¥˜ ë°©ì§€)
    """
    try:
        words = text.split()
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + (" " if current_line else "") + word
            
            try:
                test_width, _ = get_text_dimensions(test_line, font, draw)
            except Exception as e:
                app.logger.warning(f"í…ìŠ¤íŠ¸ í­ ê³„ì‚° ì‹¤íŒ¨: {e}")
                # ë¬¸ì ìˆ˜ë¡œ ëŒ€ëµ ê³„ì‚°
                if len(test_line) * 12 <= max_width:  # í‰ê·  ë¬¸ìí­ 12px
                    test_width = len(test_line) * 12
                else:
                    test_width = max_width + 1  # ê°•ì œë¡œ ì¤„ë°”ê¿ˆ
            
            if test_width <= max_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                    current_line = word
                else:
                    # ë‹¨ì–´ê°€ ë„ˆë¬´ ê¸´ ê²½ìš° ê°•ì œ ë¶„í• 
                    while word:
                        try:
                            word_width, _ = get_text_dimensions(word, font, draw)
                        except:
                            word_width = len(word) * 12
                            
                        if word_width <= max_width:
                            lines.append(word)
                            break
                        
                        # ê¸€ì ë‹¨ìœ„ë¡œ ë¶„í• 
                        for i in range(len(word), 0, -1):
                            substr = word[:i]
                            try:
                                substr_width, _ = get_text_dimensions(substr, font, draw)
                            except:
                                substr_width = len(substr) * 12
                                
                            if substr_width <= max_width:
                                lines.append(substr)
                                word = word[i:]
                                break
                    current_line = ""
        
        if current_line:
            lines.append(current_line)
        
        return lines
        
    except Exception as e:
        app.logger.error(f"í…ìŠ¤íŠ¸ ë¶„í•  ì¤‘ ì˜¤ë¥˜: {e}")
        # ì•ˆì „í•œ í´ë°±: ë‹¨ìˆœ ë¶„í• 
        max_chars = max(1, max_width // 12)  # ëŒ€ëµì ì¸ ë¬¸ì ìˆ˜
        return [text[i:i+max_chars] for i in range(0, len(text), max_chars)]

def create_qr_with_logo(link_url, output_path, logo_path='static/logo.png', size_ratio=0.25, lecture_title=""):
    """
    ê°œì„ ëœ QR ì½”ë“œ ìƒì„± - ì¤‘ì•™ ê³µë°± í™•ë³´, í•œê¸€ í°íŠ¸ í¬ê¸° ì¦ê°€, ìœ„ì¹˜ ì¡°ì •
    """
    from PIL import ImageDraw, ImageFont
    
    try:
        # QR ì½”ë“œ ìƒì„± (ì¤‘ì•™ ê³µë°± í™•ë³´ë¥¼ ìœ„í•´ ë†’ì€ ì˜¤ë¥˜ ì •ì • ìˆ˜ì¤€ ì‚¬ìš©)
        qr = qrcode.QRCode(
            version=1,
            error_correction=qrcode.constants.ERROR_CORRECT_H,  # ìµœê³  ìˆ˜ì¤€ (30% ë³µêµ¬ ê°€ëŠ¥)
            box_size=12,
            border=4,
        )
        qr.add_data(link_url)
        qr.make(fit=True)
        
        # QR ì´ë¯¸ì§€ ìƒì„±
        qr_img = qr.make_image(fill_color="black", back_color="white").convert("RGB")
        qr_size = 600  # í¬ê¸° ì¦ê°€
        qr_img = qr_img.resize((qr_size, qr_size), Image.LANCZOS)
        qr_w, qr_h = qr_img.size

        # ë¡œê³  ì‚½ì… (ì¤‘ì•™ ê³µë°± í™œìš©)
        if os.path.exists(logo_path):
            try:
                logo = Image.open(logo_path)
                # ë¡œê³  í¬ê¸°ë¥¼ QR ì½”ë“œì˜ 20%ë¡œ ì„¤ì • (ì¤‘ì•™ ê³µë°± í™œìš©)
                logo_size = int(qr_w * 0.2)
                logo = logo.resize((logo_size, logo_size), Image.LANCZOS)
                
                # í°ìƒ‰ ë°°ê²½ ì¶”ê°€ (ë¡œê³  ì£¼ë³€)
                logo_bg_size = int(logo_size * 1.2)
                logo_bg = Image.new('RGB', (logo_bg_size, logo_bg_size), 'white')
                logo_bg_pos = ((logo_bg_size - logo_size) // 2, (logo_bg_size - logo_size) // 2)
                
                if logo.mode == 'RGBA':
                    logo_bg.paste(logo, logo_bg_pos, mask=logo.split()[3])
                else:
                    logo_bg.paste(logo, logo_bg_pos)
                
                # QR ì½”ë“œ ì¤‘ì•™ì— ë¡œê³  ë°°ì¹˜
                pos = ((qr_w - logo_bg_size) // 2, (qr_h - logo_bg_size) // 2)
                qr_img.paste(logo_bg, pos)
                
            except Exception as e:
                app.logger.warning(f"ë¡œê³  ì‚½ì… ì‹¤íŒ¨: {e}")

        # ê°•ì˜ëª… í…ìŠ¤íŠ¸ ì¶”ê°€ (ë” í¬ê³  ê°€ê¹Œìš´ ìœ„ì¹˜)
        if lecture_title.strip():
            try:
                # í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ì¡°ì • (QR ì½”ë“œì— ë” ê°€ê¹ê²Œ)
                text_height = 100  # ê³ ì • ë†’ì´
                margin = 20  # QR ì½”ë“œì™€ì˜ ê°„ê²© ì¤„ì„
                
                total_height = qr_h + text_height + margin
                final_img = Image.new('RGB', (qr_w, total_height), 'white')
                final_img.paste(qr_img, (0, 0))
                
                draw = ImageDraw.Draw(final_img)
                
                # í°íŠ¸ í¬ê¸° ì¦ê°€
                base_font_size = 36  # ë” í° í°íŠ¸ í¬ê¸°
                font = get_korean_font(base_font_size)
                
                max_width = qr_w - 40  # ì¢Œìš° ì—¬ë°±
                
                # í…ìŠ¤íŠ¸ ë¶„í• 
                lines = split_korean_text(lecture_title, font, max_width, draw)
                
                # ìµœëŒ€ 2ì¤„ë¡œ ì œí•œ
                if len(lines) > 2:
                    lines = lines[:2]
                    if len(lines[1]) > 30:
                        lines[1] = lines[1][:30] + "..."
                
                # í…ìŠ¤íŠ¸ ë†’ì´ ê³„ì‚°
                try:
                    _, line_height = get_text_dimensions("í•œê¸€Ag", font, draw)
                except:
                    line_height = base_font_size
                
                # í…ìŠ¤íŠ¸ ì‹œì‘ ìœ„ì¹˜ (QR ì½”ë“œ ë°”ë¡œ ì•„ë˜)
                text_y_start = qr_h + margin
                
                # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
                for i, line in enumerate(lines):
                    if not line.strip():
                        continue
                    
                    try:
                        text_width, _ = get_text_dimensions(line, font, draw)
                        text_x = (qr_w - text_width) // 2
                        text_y = text_y_start + (i * (line_height + 5))  # ì¤„ ê°„ê²© ì¤„ì„
                        
                        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ì™¸ê³½ì„  ì—†ì´ ê¹”ë”í•˜ê²Œ)
                        draw.text((text_x, text_y), line, font=font, fill='black')
                            
                    except Exception as text_error:
                        app.logger.warning(f"í…ìŠ¤íŠ¸ ë Œë”ë§ ì‹¤íŒ¨ (ì¤„ {i}): {text_error}")
                        # í´ë°±: ì˜ì–´ë¡œ ëŒ€ì²´
                        try:
                            fallback_text = f"Lecture {i+1}"
                            draw.text((text_x, text_y), fallback_text, font=font, fill='black')
                        except:
                            pass
                
                # ê³ í’ˆì§ˆ ì €ì¥
                final_img.save(output_path, quality=95, optimize=True)
                app.logger.info(f"âœ… QR ì½”ë“œ ìƒì„± ì™„ë£Œ (ê°œì„ ëœ ë²„ì „): {lecture_title}")
                
            except Exception as text_error:
                app.logger.warning(f"í…ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨, QRë§Œ ì €ì¥: {text_error}")
                qr_img.save(output_path, quality=95, optimize=True)
                
        else:
            # ê°•ì˜ëª…ì´ ì—†ìœ¼ë©´ QR ì½”ë“œë§Œ ì €ì¥
            qr_img.save(output_path, quality=95, optimize=True)
            app.logger.info("âœ… QR ì½”ë“œ ìƒì„± ì™„ë£Œ (ê°•ì˜ëª… ì—†ìŒ)")
            
    except Exception as e:
        app.logger.error(f"âŒ QR ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {e}")
        # ìµœí›„ ìˆ˜ë‹¨: ê°„ë‹¨í•œ QR ì½”ë“œë§Œ ìƒì„±
        try:
            simple_qr = qrcode.make(link_url)
            simple_qr.save(output_path)
            app.logger.info("âœ… ê°„ë‹¨ QR ì½”ë“œë¡œ ëŒ€ì²´ ìƒì„± ì™„ë£Œ")
        except Exception as final_error:
            app.logger.error(f"âŒ ê°„ë‹¨ QR ì½”ë“œë„ ì‹¤íŒ¨: {final_error}")
            raise

def initialize_korean_fonts():
    """ì•ˆì „í•œ í•œêµ­ì–´ í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™”"""
    try:
        font_dir = Path("fonts")
        font_dir.mkdir(exist_ok=True)
        
        # í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
        try:
            download_korean_font()
        except Exception as e:
            app.logger.warning(f"í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ê³„ì† ì§„í–‰: {e}")
        
        app.logger.info("âœ… í•œêµ­ì–´ í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ (ì•ˆì „ ëª¨ë“œ)")
        return True
    except Exception as e:
        app.logger.error(f"âŒ í•œêµ­ì–´ í°íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def is_presigned_url_expired(url, safety_margin_minutes=60):
    """
    presigned URL ë§Œë£Œ ì—¬ë¶€ í™•ì¸
    safety_margin_minutes: ë§Œë£Œ ì „ì— ì•ˆì „ ì—¬ìœ  ì‹œê°„(ë¶„)
    """
    try:
        parsed      = urlparse(url)
        query       = parse_qs(parsed.query)
        if 'X-Amz-Date' not in query or 'X-Amz-Expires' not in query:
            return True
        issued_str  = query['X-Amz-Date'][0]
        expires_in  = int(query['X-Amz-Expires'][0])
        issued_time = datetime.strptime(issued_str, '%Y%m%dT%H%M%SZ')
        expiry_time = issued_time + timedelta(seconds=expires_in)
        margin_time = datetime.utcnow() + timedelta(minutes=safety_margin_minutes)
        return margin_time >= expiry_time
    except Exception as e:
        app.logger.warning(f"URL ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return True

def parse_iso_week(week_str: str):
    """
    week_str í˜•ì‹: "YYYY-Www" (ì˜ˆ: "2025-W23")
    â†’ í•´ë‹¹ ISO ì£¼ì˜ ì›”ìš”ì¼ 00:00:00 ~ ì¼ìš”ì¼ 23:59:59 (UTC) ë°˜í™˜
    """
    try:
        year_part, week_part = week_str.split('-W')
        year     = int(year_part)
        week_num = int(week_part)
        week_start_date = date.fromisocalendar(year, week_num, 1)  # ì›”ìš”ì¼
        week_end_date   = week_start_date + timedelta(days=6)      # ì¼ìš”ì¼

        week_start_dt = datetime.combine(week_start_date, datetime.min.time())
        week_end_dt   = datetime.combine(week_end_date,   datetime.max.time())
        return week_start_dt, week_end_dt
    except Exception as e:
        raise ValueError(f"ì˜ëª»ëœ week_str í˜•ì‹: {week_str} ({e})")

def create_jwt_for_admin():
    """
    ê´€ë¦¬ì ë¡œê·¸ì¸ ì‹œ JWT ë°œê¸‰
    - payloadì— ë°œê¸‰ ì‹œê°„, ë§Œë£Œ ì‹œê°„, ì‹ë³„ìë¡œ admin_email í¬í•¨
    """
    now      = datetime.utcnow()
    payload  = {
        'sub': ADMIN_EMAIL,
        'iat': now,
        'exp': now + timedelta(hours=JWT_EXPIRES_HOURS)
    }
    token = jwt.encode(payload, JWT_SECRET, algorithm=JWT_ALGORITHM)
    return token

def verify_jwt_token(token: str) -> bool:
    """
    JWT í† í° ê²€ì¦
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload.get('sub') == ADMIN_EMAIL
    except jwt.ExpiredSignatureError:
        return False
    except Exception:
        return False

def admin_required(f):
    """
    ë°ì½”ë ˆì´í„°: ìš”ì²­ í—¤ë”ì— 'Authorization: Bearer <JWT>'ê°€ ìˆì–´ì•¼ ì ‘ê·¼ í—ˆìš©
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        auth_header = request.headers.get('Authorization', None)
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'ê´€ë¦¬ì ì¸ì¦ í•„ìš”'}), 401

        token = auth_header.split(' ', 1)[1]
        if not verify_jwt_token(token):
            return jsonify({'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ ë˜ëŠ” ë§Œë£Œëœ í† í°'}), 401

        return f(*args, **kwargs)
    return decorated
# ===================================================================
# ìˆ˜ë£Œì¦ PDF ìƒì„± í•¨ìˆ˜ë“¤
# ===================================================================

def register_korean_font_for_reportlab():
    """ReportLabìš© í•œêµ­ì–´ í°íŠ¸ ë“±ë¡"""
    try:
        # ì´ë¯¸ ë‹¤ìš´ë¡œë“œí•œ í°íŠ¸ ì‚¬ìš©
        font_path = download_korean_font()
        if font_path and os.path.exists(font_path):
            pdfmetrics.registerFont(TTFont('NotoSansKR', font_path))
            app.logger.info("âœ… ReportLab í•œêµ­ì–´ í°íŠ¸ ë“±ë¡ ì™„ë£Œ")
            return True
    except Exception as e:
        app.logger.error(f"âŒ ReportLab í°íŠ¸ ë“±ë¡ ì‹¤íŒ¨: {e}")
    return False

def create_certificate_pdf_server(cert_data):
    """
    ì„œë²„ì—ì„œ ìˆ˜ë£Œì¦ PDF ìƒì„± (ReportLab ì‚¬ìš©)
    ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì´ê³  ë¹ ë¥¸ ì²˜ë¦¬
    """
    try:
        # ì„ì‹œ íŒŒì¼ ê²½ë¡œ
        temp_pdf = f"/tmp/cert_{uuid.uuid4().hex}.pdf"
        
        # A4 ê°€ë¡œ ëª¨ë“œ
        width, height = landscape(A4)
        c = canvas.Canvas(temp_pdf, pagesize=landscape(A4))
        
        # í•œêµ­ì–´ í°íŠ¸ ì„¤ì •
        try:
            c.setFont("NotoSansKR", 12)
            font_available = True
        except:
            font_available = False
            app.logger.warning("í•œêµ­ì–´ í°íŠ¸ ì‚¬ìš© ë¶ˆê°€, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        
        # ë°°ê²½ ì´ë¯¸ì§€
        if os.path.exists(CERTIFICATE_CONFIG['background_image']):
            c.drawImage(CERTIFICATE_CONFIG['background_image'], 0, 0, 
                       width=width, height=height, preserveAspectRatio=False)
        
        # í—¤ë” í…ìŠ¤íŠ¸
        if font_available:
            c.setFont("NotoSansKR", 40)
        c.drawCentredString(width/2, height * 0.85, CERTIFICATE_CONFIG['title_kor'])
        
        if font_available:
            c.setFont("NotoSansKR", 24)
        c.drawCentredString(width/2, height * 0.78, CERTIFICATE_CONFIG['title_eng'])
        
        # í”„ë¡œí•„ ì´ë¯¸ì§€ ì˜ì—­
        profile_x = width * 0.09
        profile_y = height * 0.35
        profile_width = width * 0.20
        profile_height = height * 0.40
        
        # í”„ë¡œí•„ ì´ë¯¸ì§€ ë˜ëŠ” í”Œë ˆì´ìŠ¤í™€ë”
        profile_path = CERTIFICATE_CONFIG['profile_image']
        if not os.path.exists(profile_path):
            profile_path = CERTIFICATE_CONFIG['default_profile']
        
        if os.path.exists(profile_path):
            c.drawImage(profile_path, profile_x, profile_y, 
                       width=profile_width, height=profile_height)
        else:
            # íšŒìƒ‰ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            c.setStrokeColorRGB(0.3, 0.3, 0.3)
            c.setLineWidth(2)
            c.rect(profile_x, profile_y, profile_width, profile_height)
        
        # ì •ë³´ í…ìŠ¤íŠ¸
        if font_available:
            c.setFont("NotoSansKR", 20)
        
        info_x = width * 0.33
        info_y = height * 0.65
        line_height = 35
        
        info_items = [
            ('ì´    ë¦„', cert_data.get('userName', '')),
            ('ìƒë…„ì›”ì¼', cert_data.get('userBirth', '')),
            ('ì´ìˆ˜ê³¼ëª©', cert_data.get('lectureTitle', '')),
            ('ì´ìˆ˜ì¼ì', cert_data.get('issueDate', '')),
            ('êµìœ¡ì‹¤ì‹œê¸°ê´€', CERTIFICATE_CONFIG['agency_name']),
            ('ë°œê¸‰ì¼ì', cert_data.get('issueDate', ''))
        ]
        
        for i, (label, value) in enumerate(info_items):
            y_pos = info_y - (i * line_height)
            text = f"{label} : {value}"
            if font_available:
                c.drawString(info_x, y_pos, text)
            else:
                # í°íŠ¸ê°€ ì—†ì„ ê²½ìš° ì˜ì–´ë¡œ ëŒ€ì²´
                c.drawString(info_x, y_pos, text.encode('ascii', 'ignore').decode())
        
        # í•˜ë‹¨ ê¸°ê´€ëª…
        if font_available:
            c.setFont("NotoSansKR", 24)
        c.drawCentredString(width/2, height * 0.08, CERTIFICATE_CONFIG['org_name'])
        
        # PDF ì €ì¥
        c.save()
        
        # íŒŒì¼ ì½ê¸°
        with open(temp_pdf, 'rb') as f:
            pdf_bytes = f.read()
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(temp_pdf)
        
        app.logger.info(f"âœ… ì„œë²„ PDF ìƒì„± ì™„ë£Œ: {len(pdf_bytes)} bytes")
        return pdf_bytes
        
    except Exception as e:
        app.logger.error(f"âŒ PDF ìƒì„± ì‹¤íŒ¨: {e}")
        raise

def optimize_image_for_pdf(image_path, max_size=800):
    """PDFìš© ì´ë¯¸ì§€ ìµœì í™”"""
    try:
        img = PILImage.open(image_path)
        
        # í¬ê¸° ì¡°ì •
        if img.width > max_size or img.height > max_size:
            img.thumbnail((max_size, max_size), PILImage.LANCZOS)
        
        # RGBë¡œ ë³€í™˜ (PDF í˜¸í™˜ì„±)
        if img.mode != 'RGB':
            img = img.convert('RGB')
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_path = f"/tmp/optimized_{uuid.uuid4().hex}.jpg"
        img.save(temp_path, 'JPEG', quality=85, optimize=True)
        
        return temp_path
    except Exception as e:
        app.logger.error(f"ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}")
        return image_path

# ===================================================================
# ìˆ˜ë£Œì¦ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/api/certificate/generate', methods=['POST'])
def generate_certificate_server():
    """
    ì„œë²„ì—ì„œ ìˆ˜ë£Œì¦ PDF ìƒì„± ë° ì €ì¥
    Flutter ì•±ì€ ì´ APIë§Œ í˜¸ì¶œí•˜ë©´ ë¨
    
    Body: {
        "videoId": "ê°•ì˜ID",
        "userId": "ì‚¬ìš©ìID",
        "userName": "í™ê¸¸ë™",
        "userBirth": "1990.01.01",
        "lectureTitle": "QR ê¸°ì´ˆì•ˆì „êµìœ¡",
        "issueDate": "2025.01.01"
    }
    """
    try:
        data = request.get_json() or {}
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        required_fields = ['videoId', 'userId', 'userName', 'userBirth', 
                          'lectureTitle', 'issueDate']
        for field in required_fields:
            if field not in data:
                return jsonify({'error': f'{field}ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        video_id = data['videoId']
        user_id = data['userId']
        
        # ì¤‘ë³µ ì²´í¬
        existing_cert = db.collection('users').document(user_id) \
                         .collection('completedCertificates').document(video_id).get()
        
        if existing_cert.exists and existing_cert.to_dict().get('pdfUrl'):
            # ì´ë¯¸ ë°œê¸‰ëœ ê²½ìš°
            cert_info = existing_cert.to_dict()
            return jsonify({
                'success': True,
                'message': 'ì´ë¯¸ ë°œê¸‰ëœ ìˆ˜ë£Œì¦ì…ë‹ˆë‹¤.',
                'pdfUrl': cert_info['pdfUrl'],
                'issuedAt': cert_info.get('issuedAt'),
                'alreadyIssued': True
            })
        
        # PDF ìƒì„± (ë¹„ë™ê¸° ì²˜ë¦¬ ê°€ëŠ¥)
        app.logger.info(f"[ìˆ˜ë£Œì¦ ìƒì„±] ì‹œì‘ - User: {user_id}, Video: {video_id}")
        
        pdf_bytes = create_certificate_pdf_server({
            'userName': data['userName'],
            'userBirth': data['userBirth'],
            'lectureTitle': data['lectureTitle'],
            'issueDate': data['issueDate']
        })
        
        # Firebase Storage ì—…ë¡œë“œ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        storage_path = f'users/{user_id}/certificates/{video_id}_{timestamp}.pdf'
        
        blob = bucket.blob(storage_path)
        blob.upload_from_string(
            pdf_bytes,
            content_type='application/pdf'
        )
        
        # ê³µê°œ URL ìƒì„±
        blob.make_public()
        pdf_url = blob.public_url
        
        # Firestore ì €ì¥
        cert_data = {
            'videoId': video_id,
            'lectureTitle': data['lectureTitle'],
            'userName': data['userName'],
            'userBirth': data['userBirth'],
            'issuedAt': firestore.SERVER_TIMESTAMP,
            'pdfUrl': pdf_url,
            'storageType': 'cloud',
            'savedLocally': False,
            'excelUpdated': False,
            'readyForExcel': True,
            'generatedBy': 'server',
            'fileSize': len(pdf_bytes),
            'storagePath': storage_path
        }
        
        db.collection('users').document(user_id) \
          .collection('completedCertificates').document(video_id) \
          .set(cert_data, merge=True)
        
        app.logger.info(f"âœ… ìˆ˜ë£Œì¦ ìƒì„± ì™„ë£Œ - URL: {pdf_url}")
        
        # ë°±ê·¸ë¼ìš´ë“œë¡œ ì—‘ì…€ ì—…ë°ì´íŠ¸ íŠ¸ë¦¬ê±°
        thread = threading.Thread(
            target=_update_master_excel_background,
            args=(user_id, video_id)
        )
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'success': True,
            'message': 'ìˆ˜ë£Œì¦ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'pdfUrl': pdf_url,
            'fileSize': len(pdf_bytes),
            'storagePath': storage_path,
            'alreadyIssued': False
        })
        
    except Exception as e:
        app.logger.error(f"âŒ ìˆ˜ë£Œì¦ ìƒì„± API ì˜¤ë¥˜: {e}")
        return jsonify({
            'success': False,
            'error': 'ìˆ˜ë£Œì¦ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'details': str(e)
        }), 500

@app.route('/api/certificate/status/<user_id>/<video_id>', methods=['GET'])
def check_certificate_status(user_id, video_id):
    """
    ìˆ˜ë£Œì¦ ë°œê¸‰ ìƒíƒœ í™•ì¸
    """
    try:
        cert_doc = db.collection('users').document(user_id) \
                     .collection('completedCertificates').document(video_id).get()
        
        if not cert_doc.exists:
            return jsonify({
                'issued': False,
                'status': 'not_issued'
            })
        
        cert_data = cert_doc.to_dict()
        pdf_url = cert_data.get('pdfUrl', '')
        
        # URL ê°±ì‹  í•„ìš” ì—¬ë¶€ í™•ì¸
        if pdf_url and is_presigned_url_expired(pdf_url, 60):
            # ìƒˆ URL ìƒì„± ë¡œì§
            storage_path = cert_data.get('storagePath', '')
            if storage_path:
                blob = bucket.blob(storage_path)
                new_url = blob.generate_signed_url(
                    version="v4",
                    expiration=timedelta(days=7),
                    method="GET"
                )
                
                # URL ì—…ë°ì´íŠ¸
                cert_doc.reference.update({'pdfUrl': new_url})
                pdf_url = new_url
        
        return jsonify({
            'issued': True,
            'status': 'issued',
            'pdfUrl': pdf_url,
            'issuedAt': cert_data.get('issuedAt'),
            'storageType': cert_data.get('storageType', 'unknown'),
            'excelUpdated': cert_data.get('excelUpdated', False)
        })
        
    except Exception as e:
        app.logger.error(f"ìƒíƒœ í™•ì¸ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/certificate/batch', methods=['POST'])
@admin_required
def batch_generate_certificates():
    """
    ê´€ë¦¬ììš©: ì—¬ëŸ¬ ìˆ˜ë£Œì¦ ì¼ê´„ ìƒì„±
    """
    try:
        data = request.get_json() or {}
        certificates = data.get('certificates', [])
        
        if not certificates:
            return jsonify({'error': 'ìƒì„±í•  ìˆ˜ë£Œì¦ ëª©ë¡ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        results = []
        success_count = 0
        error_count = 0
        
        # ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=5) as executor:
            futures = []
            
            for cert in certificates:
                future = executor.submit(
                    _generate_single_certificate,
                    cert
                )
                futures.append((cert, future))
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for cert, future in futures:
                try:
                    result = future.result(timeout=30)
                    results.append(result)
                    if result['success']:
                        success_count += 1
                    else:
                        error_count += 1
                except Exception as e:
                    error_count += 1
                    results.append({
                        'success': False,
                        'userId': cert.get('userId'),
                        'videoId': cert.get('videoId'),
                        'error': str(e)
                    })
        
        return jsonify({
            'results': results,
            'summary': {
                'total': len(certificates),
                'success': success_count,
                'error': error_count
            }
        })
        
    except Exception as e:
        app.logger.error(f"ì¼ê´„ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'ì¼ê´„ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ===================================================================

def _generate_single_certificate(cert_data):
    """ë‹¨ì¼ ìˆ˜ë£Œì¦ ìƒì„± (ë³‘ë ¬ ì²˜ë¦¬ìš©)"""
    try:
        # generate_certificate_serverì™€ ë™ì¼í•œ ë¡œì§
        # ì½”ë“œ ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ ì‹¤ì œë¡œëŠ” í•¨ìˆ˜ë¥¼ ë¶„ë¦¬
        user_id = cert_data['userId']
        video_id = cert_data['videoId']
        
        # PDF ìƒì„±
        pdf_bytes = create_certificate_pdf_server(cert_data)
        
        # Storage ì—…ë¡œë“œ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        storage_path = f'users/{user_id}/certificates/{video_id}_{timestamp}.pdf'
        
        blob = bucket.blob(storage_path)
        blob.upload_from_string(pdf_bytes, content_type='application/pdf')
        blob.make_public()
        
        # Firestore ì €ì¥
        db.collection('users').document(user_id) \
          .collection('completedCertificates').document(video_id) \
          .set({
              'videoId': video_id,
              'lectureTitle': cert_data.get('lectureTitle'),
              'issuedAt': firestore.SERVER_TIMESTAMP,
              'pdfUrl': blob.public_url,
              'generatedBy': 'batch_server'
          }, merge=True)
        
        return {
            'success': True,
            'userId': user_id,
            'videoId': video_id,
            'pdfUrl': blob.public_url
        }
        
    except Exception as e:
        return {
            'success': False,
            'userId': cert_data.get('userId'),
            'videoId': cert_data.get('videoId'),
            'error': str(e)
        }

def _update_master_excel_background(user_id, video_id):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ë§ˆìŠ¤í„° ì—‘ì…€ ì—…ë°ì´íŠ¸"""
    try:
        time.sleep(2)  # ì•½ê°„ì˜ ë”œë ˆì´
        
        # ê¸°ì¡´ add_certificate_to_master ë¡œì§ í™œìš©
        cert_ref = db.collection('users').document(user_id) \
                     .collection('completedCertificates').document(video_id)
        cert_doc = cert_ref.get()
        
        if cert_doc.exists:
            # ì—‘ì…€ ì—…ë°ì´íŠ¸ ë¡œì§
            # ... (ê¸°ì¡´ ì½”ë“œ í™œìš©) ...
            
            cert_ref.update({
                "excelUpdated": True,
                "readyForExcel": False,
                "excelUpdatedAt": datetime.utcnow().isoformat()
            })
            
            app.logger.info(f"âœ… ë°±ê·¸ë¼ìš´ë“œ ì—‘ì…€ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {user_id}/{video_id}")
            
    except Exception as e:
        app.logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì—‘ì…€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

# ===================================================================
# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì—”ë“œí¬ì¸íŠ¸
# ===================================================================

@app.route('/api/certificate/metrics', methods=['GET'])
@admin_required
def get_certificate_metrics():
    """
    ìˆ˜ë£Œì¦ ìƒì„± í†µê³„ ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­
    """
    try:
        # ìµœê·¼ 24ì‹œê°„ í†µê³„
        yesterday = datetime.utcnow() - timedelta(days=1)
        
        # ì „ì²´ ìˆ˜ë£Œì¦ ìˆ˜
        total_certs = len(list(
            db.collection_group('completedCertificates').stream()
        ))
        
        # ìµœê·¼ 24ì‹œê°„ ë°œê¸‰ ìˆ˜
        recent_certs = len(list(
            db.collection_group('completedCertificates')
              .where('issuedAt', '>=', yesterday)
              .stream()
        ))
        
        # ìƒì„± ë°©ì‹ë³„ í†µê³„
        server_generated = len(list(
            db.collection_group('completedCertificates')
              .where('generatedBy', '==', 'server')
              .stream()
        ))
        
        # í‰ê·  íŒŒì¼ í¬ê¸° (ìƒ˜í”Œë§)
        sample_certs = db.collection_group('completedCertificates') \
                        .limit(100).stream()
        
        file_sizes = []
        for cert in sample_certs:
            data = cert.to_dict()
            if 'fileSize' in data:
                file_sizes.append(data['fileSize'])
        
        avg_file_size = sum(file_sizes) / len(file_sizes) if file_sizes else 0
        
        return jsonify({
            'metrics': {
                'total_certificates': total_certs,
                'recent_24h': recent_certs,
                'server_generated': server_generated,
                'average_file_size_kb': round(avg_file_size / 1024, 2),
                'generation_methods': {
                    'server': server_generated,
                    'client': total_certs - server_generated
                }
            },
            'performance': {
                'pdf_thread_pool_size': pdf_executor._max_workers,
                'active_threads': len(pdf_executor._threads)
            },
            'timestamp': datetime.utcnow().isoformat()
        })
        
    except Exception as e:
        app.logger.error(f"ë©”íŠ¸ë¦­ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return jsonify({'error': 'í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500
# ===================================================================
# ê°œì„ ëœ ë‹¤êµ­ì–´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ===================================================================

def get_video_with_translation(group_id, lang_code='ko'):
    """
    íŠ¹ì • ì–¸ì–´ë¡œ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ
    
    Args:
        group_id: ë¹„ë””ì˜¤ ê·¸ë£¹ ID
        lang_code: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'ko')
    
    Returns:
        dict: ë£¨íŠ¸ ë°ì´í„° + í•´ë‹¹ ì–¸ì–´ ë²ˆì—­ ë°ì´í„°
    """
    try:
        # 1) ë£¨íŠ¸ ë¬¸ì„œ ì¡°íšŒ
        root_doc = db.collection('uploads').document(group_id).get()
        if not root_doc.exists:
            return None
        
        root_data = root_doc.to_dict()
        
        # 2) ë²ˆì—­ ë¬¸ì„œ ì¡°íšŒ
        translation_doc = db.collection('uploads').document(group_id) \
                           .collection('translations').document(lang_code).get()
        
        if translation_doc.exists:
            translation_data = translation_doc.to_dict()
            # ë²ˆì—­ ë°ì´í„°ë¥¼ ë£¨íŠ¸ ë°ì´í„°ì— ì˜¤ë²„ë¼ì´ë“œ
            root_data.update({
                'display_title': translation_data.get('title', root_data.get('group_name')),
                'display_main_category': translation_data.get('main_category', root_data.get('main_category')),
                'display_sub_category': translation_data.get('sub_category', root_data.get('sub_category')),
                'display_sub_sub_category': translation_data.get('sub_sub_category', root_data.get('sub_sub_category')),
                'current_language': lang_code,
                'language_name': translation_data.get('language_name', SUPPORTED_LANGUAGES.get(lang_code, lang_code))
            })
        else:
            # ë²ˆì—­ì´ ì—†ìœ¼ë©´ í•œêµ­ì–´(ì›ë³¸) ì‚¬ìš©
            root_data.update({
                'display_title': root_data.get('group_name'),
                'display_main_category': root_data.get('main_category'),
                'display_sub_category': root_data.get('sub_category'),
                'display_sub_sub_category': root_data.get('sub_sub_category'),
                'current_language': 'ko',
                'language_name': 'í•œêµ­ì–´'
            })
        
        return root_data
        
    except Exception as e:
        app.logger.error(f"ë¹„ë””ì˜¤ ì¡°íšŒ ì‹¤íŒ¨ ({group_id}, {lang_code}): {e}")
        return None

def add_language_to_existing_videos(new_lang_code, new_lang_name):
    """
    ê¸°ì¡´ ë¹„ë””ì˜¤ë“¤ì— ìƒˆë¡œìš´ ì–¸ì–´ ë²ˆì—­ ì¶”ê°€
    
    Args:
        new_lang_code: ìƒˆ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'fr')
        new_lang_name: ìƒˆ ì–¸ì–´ ì´ë¦„ (ì˜ˆ: 'FranÃ§ais')
    """
    try:
        # ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads = db.collection('uploads').stream()
        
        for doc in uploads:
            root_data = doc.to_dict()
            group_id = doc.id
            
            # í•œêµ­ì–´ ì›ë³¸ í…ìŠ¤íŠ¸ë“¤
            korean_title = root_data.get('group_name', '')
            korean_main_cat = root_data.get('main_category', '')
            korean_sub_cat = root_data.get('sub_category', '')
            korean_leaf_cat = root_data.get('sub_sub_category', '')
            
            # ìƒˆ ì–¸ì–´ë¡œ ë²ˆì—­
            translated_title = translate_text(korean_title, new_lang_code)
            translated_main = translate_text(korean_main_cat, new_lang_code)
            translated_sub = translate_text(korean_sub_cat, new_lang_code)
            translated_leaf = translate_text(korean_leaf_cat, new_lang_code)
            
            # ìƒˆ ë²ˆì—­ ë¬¸ì„œ ìƒì„±
            translation_data = {
                'title': translated_title,
                'main_category': translated_main,
                'sub_category': translated_sub,
                'sub_sub_category': translated_leaf,
                'language_code': new_lang_code,
                'language_name': new_lang_name,
                'is_original': False,
                'translated_at': datetime.utcnow().isoformat()
            }
            
            # ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ì— ì¶”ê°€
            db.collection('uploads').document(group_id) \
              .collection('translations').document(new_lang_code) \
              .set(translation_data)
            
            app.logger.info(f"ì–¸ì–´ ì¶”ê°€ ì™„ë£Œ: {group_id} -> {new_lang_code}")
            
            # API ì œí•œ ë°©ì§€
            time.sleep(0.3)
        
        app.logger.info(f"âœ… ëª¨ë“  ë¹„ë””ì˜¤ì— {new_lang_name}({new_lang_code}) ì–¸ì–´ ì¶”ê°€ ì™„ë£Œ")
        
    except Exception as e:
        app.logger.error(f"ì–¸ì–´ ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ===================================================================
# ë°±ê·¸ë¼ìš´ë“œ ìë™ ê°±ì‹  ì‹œìŠ¤í…œ
# ===================================================================

def refresh_expiring_urls():
    """
    ë§Œë£Œ ì„ë°•í•œ presigned URLë“¤ì„ ì¼ê´„ ê°±ì‹ í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
    - 2ì‹œê°„(120ë¶„) ì—¬ìœ ë¥¼ ë‘ê³  ë¯¸ë¦¬ ê°±ì‹ 
    """
    try:
        app.logger.info("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì‘ì—… ì‹œì‘...")
        
        # Firestoreì—ì„œ ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        updated_count = 0
        total_count = 0
        
        for doc in docs:
            total_count += 1
            data = doc.to_dict()
            
            current_url = data.get('presigned_url', '')
            video_key = data.get('video_key', '')
            
            if not video_key:
                app.logger.warning(f"âš ï¸  ë¬¸ì„œ {doc.id}ì— video_keyê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # URLì´ ì—†ê±°ë‚˜ ë§Œë£Œ ì„ë°•(2ì‹œê°„ ì—¬ìœ ) ì‹œ ê°±ì‹ 
            if not current_url or is_presigned_url_expired(current_url, safety_margin_minutes=120):
                try:
                    # ìƒˆ presigned URL ìƒì„± (7ì¼ ìœ íš¨)
                    new_presigned_url = generate_presigned_url(video_key, expires_in=604800)
                    
                    # Firestore ì—…ë°ì´íŠ¸
                    update_data = {
                        'presigned_url': new_presigned_url,
                        'auto_updated_at': datetime.utcnow().isoformat(),
                        'auto_update_reason': 'background_refresh'
                    }
                    
                    # QR URLë„ ê°±ì‹ 
                    qr_key = data.get('qr_key', '')
                    if qr_key:
                        new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
                        update_data['qr_presigned_url'] = new_qr_url
                    
                    # ì¸ë„¤ì¼ URLë„ ê°±ì‹ 
                    thumbnail_key = data.get('thumbnail_key', '')
                    if thumbnail_key:
                        new_thumbnail_url = generate_presigned_url(thumbnail_key, expires_in=604800)
                        update_data['thumbnail_presigned_url'] = new_thumbnail_url
                    
                    doc.reference.update(update_data)
                    
                    updated_count += 1
                    app.logger.info(f"âœ… ë¬¸ì„œ {doc.id} URL ê°±ì‹  ì™„ë£Œ")
                    
                except Exception as update_error:
                    app.logger.error(f"âŒ ë¬¸ì„œ {doc.id} URL ê°±ì‹  ì‹¤íŒ¨: {update_error}")
        
        app.logger.info(f"ğŸ‰ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì™„ë£Œ: {updated_count}/{total_count} ê°œ ê°±ì‹ ë¨")
        
    except Exception as e:
        app.logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

def refresh_qr_presigned_urls():
    """
    QR ì´ë¯¸ì§€ì˜ presigned URLë„ ê°±ì‹  (ë‹¨ì¼ QR ì´ë¯¸ì§€)
    """
    try:
        app.logger.info("ğŸ”„ QR ì´ë¯¸ì§€ URL ê°±ì‹  ì‘ì—… ì‹œì‘...")
        
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        updated_count = 0
        
        for doc in docs:
            data = doc.to_dict()
            qr_key = data.get('qr_key', '')
            
            if not qr_key:
                continue
                
            try:
                # QR ì´ë¯¸ì§€ìš© ìƒˆ presigned URL ìƒì„± (7ì¼ ìœ íš¨)
                new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
                
                doc.reference.update({
                    'qr_presigned_url': new_qr_url,
                    'qr_updated_at': datetime.utcnow().isoformat()
                })
                
                updated_count += 1
                
            except Exception as qr_error:
                app.logger.error(f"âŒ QR URL ê°±ì‹  ì‹¤íŒ¨ {doc.id}: {qr_error}")
        
        app.logger.info(f"ğŸ‰ QR URL ê°±ì‹  ì™„ë£Œ: {updated_count}ê°œ")
        
    except Exception as e:
        app.logger.error(f"âŒ QR URL ê°±ì‹  ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

# ===================================================================
# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ë° ì‹œì‘
# ===================================================================

# ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
scheduler = BackgroundScheduler(
    timezone='UTC',
    job_defaults={
        'coalesce': True,  # ê°™ì€ ì‘ì—…ì´ ì¤‘ë³µ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡
        'max_instances': 1  # ìµœëŒ€ 1ê°œ ì¸ìŠ¤í„´ìŠ¤ë§Œ ì‹¤í–‰
    }
)

def start_background_scheduler():
    """
    ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    """
    try:
        # 1. ë™ì˜ìƒ URL ê°±ì‹  ì‘ì—… (3ì‹œê°„ë§ˆë‹¤)
        scheduler.add_job(
            func=refresh_expiring_urls,
            trigger=IntervalTrigger(hours=3),
            id='refresh_video_urls',
            name='ë™ì˜ìƒ URL ìë™ ê°±ì‹ ',
            replace_existing=True
        )
        
        # 2. QR ì´ë¯¸ì§€ URL ê°±ì‹  ì‘ì—… (6ì‹œê°„ë§ˆë‹¤)
        scheduler.add_job(
            func=refresh_qr_presigned_urls,
            trigger=IntervalTrigger(hours=6),
            id='refresh_qr_urls',
            name='QR ì´ë¯¸ì§€ URL ìë™ ê°±ì‹ ',
            replace_existing=True
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        scheduler.start()
        app.logger.info("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ URL ìë™ ê°±ì‹  ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        app.logger.info("   - ë™ì˜ìƒ URL: 3ì‹œê°„ë§ˆë‹¤ ê°±ì‹ ")
        app.logger.info("   - QR ì´ë¯¸ì§€ URL: 6ì‹œê°„ë§ˆë‹¤ ê°±ì‹ ")
        
        # ì•± ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ë„ í•¨ê»˜ ì¢…ë£Œ
        atexit.register(lambda: scheduler.shutdown())
        
    except Exception as e:
        app.logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

# ===================================================================
# ìˆ˜ë™ ê°±ì‹  API (ê´€ë¦¬ììš©)
# ===================================================================

@app.route('/api/admin/refresh-urls', methods=['POST'])
@admin_required
def manual_refresh_urls():
    """
    ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ URL ê°±ì‹ ì„ íŠ¸ë¦¬ê±°í•  ìˆ˜ ìˆëŠ” ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ì‘ë‹µ ì§€ì—° ë°©ì§€
        thread = threading.Thread(target=refresh_expiring_urls)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'message': 'URL ê°±ì‹  ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'status': 'started'
        }), 200
        
    except Exception as e:
        app.logger.error(f"ìˆ˜ë™ URL ê°±ì‹  ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ê°±ì‹  ì‘ì—… ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/admin/scheduler-status', methods=['GET'])
@admin_required
def get_scheduler_status():
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        jobs = []
        for job in scheduler.get_jobs():
            jobs.append({
                'id': job.id,
                'name': job.name,
                'next_run': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
        
        return jsonify({
            'running': scheduler.running,
            'jobs': jobs
        }), 200
        
    except Exception as e:
        app.logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# ê°œì„ ëœ ì—…ë¡œë“œ í•¸ë“¤ëŸ¬: ì¸ë„¤ì¼ ì¶”ê°€ ì§€ì›
# ===================================================================
@app.route('/upload', methods=['POST'])
def upload_video():
    """
    ê°œì„ ëœ ì—…ë¡œë“œ ì²˜ë¦¬: ë£¨íŠ¸ ë¬¸ì„œì™€ ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ë¶„ë¦¬ + ì¸ë„¤ì¼ ì§€ì›
    1) í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì¼ê³¼ ê¸°íƒ€ ë©”íƒ€ë°ì´í„° ìˆ˜ì‹ 
    2) í•œêµ­ì–´ ê°•ì˜ëª…ì„ 7ê°œ ì–¸ì–´ë¡œ ìë™ ë²ˆì—­
    3) íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥ â†’ S3 ì—…ë¡œë“œ
    4) moviepyë¡œ ë™ì˜ìƒ ê¸¸ì´(ì´ˆ ë‹¨ìœ„) ê³„ì‚° â†’ "ë¶„:ì´ˆ" ë¬¸ìì—´ë¡œ ë³€í™˜
    5) ì¸ë„¤ì¼ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ S3ì— ì—…ë¡œë“œ
    6) ë£¨íŠ¸ ë¬¸ì„œì— í•µì‹¬ ë©”íƒ€ë°ì´í„° ì €ì¥
    7) ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ì— ì–¸ì–´ë³„ ë²ˆì—­ ì €ì¥
    """
    # ì„¸ì…˜ ì¸ì¦(ê¸°ì¡´ ë¡œì§)
    if not session.get('logged_in'):
        return redirect(url_for('login_page'))

    file          = request.files.get('file')
    thumbnail     = request.files.get('thumbnail')  # ì¸ë„¤ì¼ íŒŒì¼ ì¶”ê°€
    group_name    = request.form.get('group_name', 'default')  # í•œêµ­ì–´ ê°•ì˜ëª…
    main_cat      = request.form.get('main_category', '')
    sub_cat       = request.form.get('sub_category', '')
    leaf_cat      = request.form.get('sub_sub_category', '')
    lecture_level = request.form.get('level', '')
    lecture_tag   = request.form.get('tag', '')

    if not file:
        return "íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.", 400

    # ğŸŒ 1) í•œêµ­ì–´ ê°•ì˜ëª…ì„ 7ê°œ ì–¸ì–´ë¡œ ë²ˆì—­
    app.logger.info(f"ë‹¤êµ­ì–´ ë²ˆì—­ ì‹œì‘: '{group_name}'")
    translated_titles = create_multilingual_metadata(group_name)
    
    # ì¹´í…Œê³ ë¦¬ë“¤ë„ ë²ˆì—­ (ì„ íƒì‚¬í•­)
    translated_main_cat = create_multilingual_metadata(main_cat) if main_cat else {}
    translated_sub_cat = create_multilingual_metadata(sub_cat) if sub_cat else {}
    translated_leaf_cat = create_multilingual_metadata(leaf_cat) if leaf_cat else {}

    # 2) ê·¸ë£¹ ID ìƒì„± ë° S3 í‚¤ êµ¬ì„±
    group_id = uuid.uuid4().hex
    date_str = datetime.now().strftime('%Y%m%d')
    safe_name = re.sub(r'[^\w]', '_', group_name)
    folder = f"videos/{group_id}_{safe_name}_{date_str}"
    
    # ë™ì˜ìƒ íŒŒì¼ í™•ì¥ì (MP4ê°€ ì•„ë‹ˆì–´ë„ ê°€ëŠ¥)
    ext = Path(file.filename).suffix.lower() or '.mp4'
    video_key = f"{folder}/video{ext}"

    # 3) ì„ì‹œ ì €ì¥ ë° S3 ì—…ë¡œë“œ
    tmp_path = Path(tempfile.gettempdir()) / f"{group_id}{ext}"
    file.save(tmp_path)

    # 4) moviepyë¥¼ ì‚¬ìš©í•´ ë™ì˜ìƒ ê¸¸ì´ ê³„ì‚° (ëª¨ë“  ë¹„ë””ì˜¤ í˜•ì‹ ì§€ì›)
    try:
        with VideoFileClip(str(tmp_path)) as clip:
            duration_sec = int(clip.duration)
    except Exception as e:
        duration_sec = 0
        app.logger.warning(f"moviepyë¡œ ë™ì˜ìƒ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    # "ë¶„:ì´ˆ" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    minutes = duration_sec // 60
    seconds = duration_sec % 60
    lecture_time = f"{minutes}:{seconds:02d}"
    app.logger.info(f"ê³„ì‚°ëœ ë™ì˜ìƒ ê¸¸ì´: {lecture_time} (ì´ {duration_sec}ì´ˆ)")

    # S3 ì—…ë¡œë“œ
    s3.upload_file(str(tmp_path), BUCKET_NAME, video_key, Config=config)
    tmp_path.unlink(missing_ok=True)

    # 5) Presigned URL ìƒì„±
    presigned_url = generate_presigned_url(video_key, expires_in=604800)

    # 5-1) ì¸ë„¤ì¼ ì²˜ë¦¬
    thumbnail_key = None
    thumbnail_presigned_url = None
    if thumbnail and thumbnail.filename:
        try:
            # ì¸ë„¤ì¼ í™•ì¥ì
            thumb_ext = Path(thumbnail.filename).suffix.lower() or '.jpg'
            thumbnail_key = f"{folder}/thumbnail{thumb_ext}"
            
            # ì¸ë„¤ì¼ ì„ì‹œ ì €ì¥
            thumb_tmp_path = Path(tempfile.gettempdir()) / f"{group_id}_thumb{thumb_ext}"
            thumbnail.save(thumb_tmp_path)
            
            # S3 ì—…ë¡œë“œ
            s3.upload_file(str(thumb_tmp_path), BUCKET_NAME, thumbnail_key, Config=config)
            thumb_tmp_path.unlink(missing_ok=True)
            
            # ì¸ë„¤ì¼ Presigned URL ìƒì„±
            thumbnail_presigned_url = generate_presigned_url(thumbnail_key, expires_in=604800)
            app.logger.info(f"âœ… ì¸ë„¤ì¼ ì—…ë¡œë“œ ì™„ë£Œ: {thumbnail_key}")
            
        except Exception as e:
            app.logger.error(f"âŒ ì¸ë„¤ì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

    # 6) ë‹¨ì¼ QR ì½”ë“œ ìƒì„± (í•œêµ­ì–´ ê¸°ë³¸)
    qr_link = f"{APP_BASE_URL}{group_id}"  # ì–¸ì–´ íŒŒë¼ë¯¸í„° ì—†ì´
    qr_filename = f"{uuid.uuid4().hex}.png"
    local_qr = os.path.join(app.config['UPLOAD_FOLDER'], qr_filename)
    
    # í•œêµ­ì–´ ê°•ì˜ëª…ìœ¼ë¡œ QR ì½”ë“œ ìƒì„±
    display_title = group_name
    if main_cat or sub_cat or leaf_cat:
        categories = [cat for cat in [main_cat, sub_cat, leaf_cat] if cat]
        if categories:
            display_title = f"{group_name}\n({' > '.join(categories)})"
    
    create_qr_with_logo(qr_link, local_qr, lecture_title=display_title)
    
    qr_key = f"{folder}/{qr_filename}"
    s3.upload_file(local_qr, BUCKET_NAME, qr_key)
    
    # QR ì´ë¯¸ì§€ URL ìƒì„±
    qr_presigned_url = generate_presigned_url(qr_key, expires_in=604800)
    
    # ë¡œì»¬ íŒŒì¼ ì‚­ì œ
    try:
        os.remove(local_qr)
    except OSError:
        pass

    # ğŸ“ 7) ë£¨íŠ¸ ë¬¸ì„œ ì €ì¥ (í•µì‹¬ ë©”íƒ€ë°ì´í„°ë§Œ)
    root_doc_data = {
        'group_id': group_id,
        'group_name': group_name,           # ê¸°ë³¸ ì–¸ì–´(í•œêµ­ì–´)
        'main_category': main_cat,
        'sub_category': sub_cat,
        'sub_sub_category': leaf_cat,
        'time': lecture_time,
        'level': lecture_level,
        'tag': lecture_tag,
        'video_key': video_key,
        'presigned_url': presigned_url,
        'qr_link': qr_link,
        'qr_key': qr_key,
        'qr_presigned_url': qr_presigned_url,
        'upload_date': date_str,
        'created_at': datetime.utcnow().isoformat(),
        'updated_at': datetime.utcnow().isoformat()
    }

    # ì¸ë„¤ì¼ ì •ë³´ ì¶”ê°€
    if thumbnail_key:
        root_doc_data['thumbnail_key'] = thumbnail_key
        root_doc_data['thumbnail_presigned_url'] = thumbnail_presigned_url

    # ë£¨íŠ¸ ë¬¸ì„œ ì €ì¥
    root_doc_ref = db.collection('uploads').document(group_id)
    root_doc_ref.set(root_doc_data)

    # ğŸ“ 8) ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ì €ì¥ (ì–¸ì–´ë³„ë¡œ ë¶„ë¦¬)
    translations_ref = root_doc_ref.collection('translations')
    
    for lang_code in SUPPORTED_LANGUAGES.keys():
        if lang_code == 'ko':
            # í•œêµ­ì–´ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ
            translation_data = {
                'title': group_name,
                'main_category': main_cat,
                'sub_category': sub_cat,
                'sub_sub_category': leaf_cat,
                'language_code': lang_code,
                'language_name': SUPPORTED_LANGUAGES[lang_code],
                'is_original': True,
                'translated_at': datetime.utcnow().isoformat()
            }
        else:
            # ë²ˆì—­ëœ ì–¸ì–´ë“¤
            translation_data = {
                'title': translated_titles.get(lang_code, group_name),
                'main_category': translated_main_cat.get(lang_code, main_cat),
                'sub_category': translated_sub_cat.get(lang_code, sub_cat),
                'sub_sub_category': translated_leaf_cat.get(lang_code, leaf_cat),
                'language_code': lang_code,
                'language_name': SUPPORTED_LANGUAGES[lang_code],
                'is_original': False,
                'translated_at': datetime.utcnow().isoformat()
            }
        
        # ê° ì–¸ì–´ë³„ ë¬¸ì„œ ì €ì¥
        translations_ref.document(lang_code).set(translation_data)
        app.logger.info(f"ë²ˆì—­ ì €ì¥ ì™„ë£Œ: {lang_code} - {translation_data.get('title')}")

    app.logger.info(f"âœ… ê°œì„ ëœ êµ¬ì¡°ë¡œ ì—…ë¡œë“œ ì™„ë£Œ: {group_id}")
    app.logger.info(f"ë²ˆì—­ëœ ì–¸ì–´: {list(translated_titles.keys())}")

    return render_template(
        'success.html',
        group_id=group_id,
        translations=translated_titles,
        time=lecture_time,
        level=lecture_level,
        tag=lecture_tag,
        presigned_url=presigned_url,
        qr_url=qr_presigned_url,
        thumbnail_url=thumbnail_presigned_url
    )

# ===================================================================
# ìˆ˜ë£Œì¦ ì •ë³´ ìƒì„± ì‹œ Firestoreì— readyForExcel & excelUpdated í”Œë˜ê·¸ ì¶”ê°€
# ===================================================================
@app.route('/create_certificate', methods=['POST'])
def create_certificate():
    """
    í´ë¼ì´ì–¸íŠ¸(Flutter ë“±)ì—ì„œ ìˆ˜ë£Œì¦ì„ ë°œê¸‰í•  ë•Œ í˜¸ì¶œ.
    1) user_uid, cert_id, lectureTitle, pdfUrl ë“±ì„ JSON ë°”ë””ë¡œ ì „ë‹¬
    2) Firestoreì— ìƒˆ ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´ì„œ
       excelUpdated: False, readyForExcel: True í”Œë˜ê·¸ë¥¼ í•¨ê»˜ ì„¤ì •
    """
    data = request.get_json() or {}
    user_uid      = data.get('user_uid')
    cert_id       = data.get('cert_id')
    lecture_title = data.get('lectureTitle', '')
    pdf_url       = data.get('pdfUrl', '')

    if not user_uid or not cert_id or not pdf_url:
        return jsonify({'error': 'user_uid, cert_id, lectureTitle, pdfUrlì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    # Firestore Timestampë¡œ ìë™ ì €ì¥
    cert_ref = db.collection('users').document(user_uid) \
                 .collection('completedCertificates').document(cert_id)
    cert_ref.set({
        'lectureTitle':    lecture_title,
        'issuedAt':        firestore.SERVER_TIMESTAMP,
        'pdfUrl':          pdf_url,
        'excelUpdated':    False,
        'readyForExcel':   True
    }, merge=True)

    return jsonify({'message': 'ìˆ˜ë£Œì¦ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì›Œì»¤ê°€ ì—‘ì…€ ì—…ë°ì´íŠ¸ ëŒ€ìƒì— ì¶”ê°€ë©ë‹ˆë‹¤.'}), 200

# ===================================================================
# ìˆ˜ë£Œì¦ì´ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ Master ì—‘ì…€ì— ìë™ìœ¼ë¡œ ì¶”ê°€í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
# ===================================================================
@app.route('/add_certificate_to_master', methods=['POST'])
def add_certificate_to_master():
    """
    ì‚¬ìš©ìê°€ ìˆ˜ë£Œì¦ì„ ë°œê¸‰(ì €ì¥)í•œ í›„, í•„ìš”ì— ë”°ë¼ í˜¸ì¶œ.
    1) Firestoreì—ì„œ user_uid, cert_idë¡œ ìˆ˜ë£Œì¦ ì •ë³´ ì¡°íšŒ
    2) Firebase Storageì— ì €ì¥ëœ master_certificates.xlsx ë‹¤ìš´ë¡œë“œ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    3) Pandasë¡œ DataFrame ë¡œë“œ â†’ ìƒˆë¡œìš´ í–‰ ì¶”ê°€
    4) ìˆ˜ì •ëœ ì—‘ì…€ì„ Firebase Storageì— ì—…ë¡œë“œ(ë®ì–´ì“°ê¸°)
    5) Firestore ë¬¸ì„œì— excelUpdated=True, readyForExcel=Falseë¡œ ì—…ë°ì´íŠ¸
    """
    data = request.get_json() or {}
    user_uid = data.get('user_uid')
    cert_id  = data.get('cert_id')

    if not user_uid or not cert_id:
        return jsonify({'error': 'user_uidì™€ cert_idê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    # 1) Firestoreì—ì„œ í•´ë‹¹ ìˆ˜ë£Œì¦ ë¬¸ì„œ ì¡°íšŒ
    cert_ref = db.collection('users').document(user_uid) \
                 .collection('completedCertificates').document(cert_id)
    cert_doc = cert_ref.get()
    if not cert_doc.exists:
        return jsonify({'error': 'í•´ë‹¹ ìˆ˜ë£Œì¦ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'}), 404

    cert_info = cert_doc.to_dict()
    # PDF URL í•„ìˆ˜ í™•ì¸
    pdf_url       = cert_info.get('pdfUrl', '')
    if not pdf_url:
        return jsonify({'error': 'PDF URLì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

    lecture_title = cert_info.get('lectureTitle', cert_id)
    issued_at     = cert_info.get('issuedAt')  # Firestore Timestamp

    # Firestore Timestamp â†’ datetime ë³€í™˜
    if hasattr(issued_at, 'to_datetime'):
        issued_dt = issued_at.to_datetime()
    else:
        issued_dt = datetime.utcnow()

    # 2) Firebase Storageì—ì„œ master_certificates.xlsx ë‹¤ìš´ë¡œë“œ (ì—†ìœ¼ë©´ ë¹ˆ DataFrame ìƒì„±)
    master_blob_name = 'master_certificates.xlsx'
    master_blob = bucket.blob(master_blob_name)

    try:
        existing_bytes = master_blob.download_as_bytes()
        excel_buffer   = io.BytesIO(existing_bytes)
        df_master      = pd.read_excel(excel_buffer, engine='openpyxl')
    except Exception:
        # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨ ì‹œ: ë¹ˆ DataFrame ìƒì„±
        df_master = pd.DataFrame(columns=[
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼',
            'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL'
        ])

    # 3) DataFrameì— ìƒˆë¡œìš´ í–‰ ì¶”ê°€ (append ëŒ€ì‹  concat ì‚¬ìš©)
    # ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ (ì´ë¦„/ì „í™”/ì´ë©”ì¼), í•„ìš”ì‹œ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
    user_ref = db.collection("users").document(user_uid)
    user_snapshot = user_ref.get()
    if user_snapshot.exists:
        user_data  = user_snapshot.to_dict()
        user_name  = user_data.get("name", "")
        user_phone = user_data.get("phone", "")
        user_email = user_data.get("email", "")
    else:
        user_name  = ""
        user_phone = ""
        user_email = ""

    updated_date = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
    issued_str   = issued_dt.strftime("%Y-%m-%d %H:%M:%S")

    new_row = pd.DataFrame([{
        'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
        'ì‚¬ìš©ì UID':    user_uid,
        'ì „í™”ë²ˆí˜¸':      user_phone,
        'ì´ë©”ì¼':        user_email,
        'ì‚¬ìš©ì ì´ë¦„':   user_name,
        'ê°•ì˜ ì œëª©':     lecture_title,
        'ë°œê¸‰ ì¼ì‹œ':     issued_str,
        'PDF URL':       pdf_url
    }])
    df_master = pd.concat([df_master, new_row], ignore_index=True)

    # 4) ìˆ˜ì •ëœ DataFrameì„ BytesIO ë²„í¼ì— ì—‘ì…€ë¡œ ì“°ê¸°
    out_buffer = io.BytesIO()
    with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
        df_master.to_excel(writer, index=False, sheet_name="Certificates")
    out_buffer.seek(0)

    # Firebase Storageì— ë®ì–´ì“°ê¸°
    try:
        master_blob.upload_from_file(
            out_buffer,
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
    except Exception as e:
        app.logger.error(f"ë§ˆìŠ¤í„° ì—‘ì…€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ìˆ˜ì •ëœ ì—‘ì…€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

    # 5) Firestore ë¬¸ì„œì— excelUpdated=True, readyForExcel=Falseë¡œ ì—…ë°ì´íŠ¸
    cert_ref.update({
        "excelUpdated": True,
        "readyForExcel": False
    })

    return jsonify({'message': 'ë§ˆìŠ¤í„° ì—‘ì…€ì— ìˆ˜ë£Œì¦ ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 200

# ===================================================================
# ê°œì„ ëœ ë¼ìš°íŒ… ì„¤ì •
# ===================================================================

@app.route('/', methods=['GET'])
def login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€ ë Œë”ë§ (ê´€ë¦¬ììš©)"""
    return render_template('login.html')

@app.route('/login', methods=['POST'])
def login():
    """
    (ê¸°ì¡´ ì„¸ì…˜ ê¸°ë°˜) ê´€ë¦¬ì í˜ì´ì§€ ë¡œê·¸ì¸.
    ê·¸ëŸ¬ë‚˜ í”ŒëŸ¬í„° ì•±ì—ì„œëŠ” ì´ ì—”ë“œí¬ì¸íŠ¸ ëŒ€ì‹  ì•„ë˜ /api/admin/login ì„ ì‚¬ìš©í•˜ì—¬ JWTë¥¼ ë°œê¸‰ë°›ìŠµë‹ˆë‹¤.
    """
    pw = request.form.get('password', '')
    email = request.form.get('email', '')

    if email == ADMIN_EMAIL and pw == ADMIN_PASSWORD:
        session['logged_in'] = True
        return redirect(url_for('upload_form'))
    return render_template('login.html', error="ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

@app.route('/api/admin/login', methods=['POST'])
def api_admin_login():
    """
    Flutter ê´€ë¦¬ì ë¡œê·¸ì¸(JWT ë°œê¸‰ìš©).
    Body: { "email": "...", "password": "..." }
    """
    data = request.get_json() or {}
    email    = data.get('email', '').strip()
    password = data.get('password', '')

    if email == ADMIN_EMAIL and password == ADMIN_PASSWORD:
        token = create_jwt_for_admin()
        return jsonify({'token': token}), 200
    else:
        return jsonify({'error': 'ê´€ë¦¬ì ì¸ì¦ ì‹¤íŒ¨'}), 401

@app.route('/upload_form', methods=['GET'])
def upload_form():
    """
    (ê¸°ì¡´) ê´€ë¦¬ìê°€ ì›¹ì—ì„œ ì—…ë¡œë“œ í˜ì´ì§€ ì ‘ê·¼ ì‹œ ì„¸ì…˜ ê¸°ë°˜ ì¸ì¦
    """
    if not session.get('logged_in'):
        return redirect(url_for('login_page'))

    main_cats = ['ê¸°ê³„', 'ê³µêµ¬', 'ì¥ë¹„', 'ì•½í’ˆ']
    sub_map = {
        'ê¸°ê³„': ['ê³µì‘ê¸°ê³„', 'ì œì¡°ê¸°ê³„', 'ì‚°ì—…ê¸°ê³„'],
        'ê³µêµ¬': ['ìˆ˜ê³µêµ¬', 'ì „ë™ê³µêµ¬', 'ì ˆì‚­ê³µêµ¬'],
        'ì¥ë¹„': ['ì•ˆì „ì¥ë¹„', 'ìš´ì†¡ì¥ë¹„', 'ì‘ì—…ì¥ë¹„'],
        'ì•½í’ˆ': ['ì˜ì•½í’ˆ', 'í™”ê³µì•½í’ˆ'],
    }
    leaf_map = {
        'ê³µì‘ê¸°ê³„': ['ë¶ˆë„ì €', 'í¬ë ˆì¸', 'êµ´ì°©ê¸°'],
        'ì œì¡°ê¸°ê³„': ['ì‚¬ì¶œ ì„±í˜•ê¸°', 'í”„ë ˆìŠ¤ê¸°', 'ì—´ì„±í˜•ê¸°'],
        'ì‚°ì—…ê¸°ê³„': ['CNC ì„ ë°˜', 'ì ˆì‚­ê¸°', 'ì—°ì‚­ê¸°'],
        'ìˆ˜ê³µêµ¬':   ['ë“œë¦´', 'í•´ë¨¸', 'í”Œë¼ì´ì–´'],
        'ì „ë™ê³µêµ¬': ['ê·¸ë¼ì¸ë”', 'ì „ë™ ë“œë¦´', 'í•´ë¨¸ë“œë¦´'],
        'ì ˆì‚­ê³µêµ¬': ['ì»¤í„°', 'í”Œë¼ì¦ˆë§ˆ ë…¸ì¦', 'ë“œë¦´ ë¹„íŠ¸'],
        'ì•ˆì „ì¥ë¹„': ['í—¬ë©§', 'ë°©ì§„ ë§ˆìŠ¤í¬', 'ë‚™í•˜ ë°©ì§€ë²¨íŠ¸'],
        'ìš´ì†¡ì¥ë¹„': ['ë¦¬í”„íŠ¸ ì¥ë¹„', 'ì²´ì¸ ë¸”ë¡', 'í˜¸ì´ìŠ¤íŠ¸'],
        'ì‘ì—…ì¥ë¹„': ['ìŠ¤ìºí´ë”©', 'ì‘ì—…ëŒ€', 'ë¦¬í”„íŠ¸ í…Œì´ë¸”'],
        'ì˜ì•½í’ˆ': ['í•­ìƒì œ', 'ì¸ìŠë¦°', 'í•­ì‘ê³ ì œ'],
        'í™”ê³µì•½í’ˆ': ['í™©ì‚°', 'ì—¼ì‚°', 'ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨']
    }
    return render_template('upload_form.html', mains=main_cats, subs=sub_map, leafs=leaf_map)

@app.route('/watch/<group_id>', methods=['GET'])
def watch(group_id):
    """
    ê°œì„ ëœ ë™ì˜ìƒ ì‹œì²­ í˜ì´ì§€: ì–¸ì–´ë³„ ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ í™œìš©
    Flutter ì•±ì—ì„œ ì–¸ì–´ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
    """
    # URLì—ì„œ ì–¸ì–´ íŒŒë¼ë¯¸í„° í™•ì¸
    requested_lang = request.args.get('lang', 'ko')
    
    # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ë©´ í•œêµ­ì–´ë¡œ í´ë°±
    if requested_lang not in SUPPORTED_LANGUAGES:
        requested_lang = 'ko'
    
    # User-Agent í™•ì¸í•˜ì—¬ Flutter ì•±ì¸ì§€ ê°ì§€
    user_agent = request.headers.get('User-Agent', '').lower()
    is_flutter_app = 'flutter' in user_agent or 'dart' in user_agent
    
    if is_flutter_app:
        # Flutter ì•±ì¸ ê²½ìš° JSON ì‘ë‹µìœ¼ë¡œ ë¹„ë””ì˜¤ ì •ë³´ ë°˜í™˜
        video_data = get_video_with_translation(group_id, requested_lang)
        if not video_data:
            return jsonify({'error': 'Video not found'}), 404
        
        # URL ê°±ì‹ 
        current_presigned = video_data.get('presigned_url', '')
        if not current_presigned or is_presigned_url_expired(current_presigned, 60):
            new_presigned_url = generate_presigned_url(video_data['video_key'], expires_in=604800)
            db.collection('uploads').document(group_id).update({
                'presigned_url': new_presigned_url,
                'updated_at': datetime.utcnow().isoformat()
            })
            video_data['presigned_url'] = new_presigned_url
        
        # ì¸ë„¤ì¼ URLë„ ê°±ì‹  í™•ì¸
        current_thumbnail_url = video_data.get('thumbnail_presigned_url', '')
        thumbnail_key = video_data.get('thumbnail_key', '')
        if thumbnail_key and (not current_thumbnail_url or is_presigned_url_expired(current_thumbnail_url, 60)):
            new_thumbnail_url = generate_presigned_url(thumbnail_key, expires_in=604800)
            db.collection('uploads').document(group_id).update({
                'thumbnail_presigned_url': new_thumbnail_url
            })
            video_data['thumbnail_presigned_url'] = new_thumbnail_url
        
        return jsonify({
            'groupId': group_id,
            'title': video_data['display_title'],
            'main_category': video_data['display_main_category'],
            'sub_category': video_data['display_sub_category'],
            'video_url': video_data['presigned_url'],
            'qr_url': video_data.get('qr_presigned_url', ''),
            'thumbnail_url': video_data.get('thumbnail_presigned_url', ''),
            'language': requested_lang,
            'time': video_data.get('time', '0:00'),
            'level': video_data.get('level', ''),
            'tag': video_data.get('tag', '')
        })
    else:
        # ì›¹ ë¸Œë¼ìš°ì €ì¸ ê²½ìš° ê¸°ì¡´ HTML í…œí”Œë¦¿ ë Œë”ë§
        video_data = get_video_with_translation(group_id, requested_lang)
        if not video_data:
            abort(404)
        
        # URL ê°±ì‹  ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
        current_presigned = video_data.get('presigned_url', '')
        if not current_presigned or is_presigned_url_expired(current_presigned, 60):
            new_presigned_url = generate_presigned_url(video_data['video_key'], expires_in=604800)
            db.collection('uploads').document(group_id).update({
                'presigned_url': new_presigned_url,
                'updated_at': datetime.utcnow().isoformat()
            })
            video_data['presigned_url'] = new_presigned_url
        
        # QR URLë„ ê°±ì‹  í™•ì¸
        current_qr_url = video_data.get('qr_presigned_url', '')
        qr_key = video_data.get('qr_key', '')
        if qr_key and (not current_qr_url or is_presigned_url_expired(current_qr_url, 60)):
            new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
            db.collection('uploads').document(group_id).update({
                'qr_presigned_url': new_qr_url,
                'qr_updated_at': datetime.utcnow().isoformat()
            })
            video_data['qr_presigned_url'] = new_qr_url
        
        # ì¸ë„¤ì¼ URLë„ ê°±ì‹  í™•ì¸
        current_thumbnail_url = video_data.get('thumbnail_presigned_url', '')
        thumbnail_key = video_data.get('thumbnail_key', '')
        if thumbnail_key and (not current_thumbnail_url or is_presigned_url_expired(current_thumbnail_url, 60)):
            new_thumbnail_url = generate_presigned_url(thumbnail_key, expires_in=604800)
            db.collection('uploads').document(group_id).update({
                'thumbnail_presigned_url': new_thumbnail_url
            })
            video_data['thumbnail_presigned_url'] = new_thumbnail_url
        
        # í…œí”Œë¦¿ì— ë²ˆì—­ëœ ë°ì´í„° ì „ë‹¬
        return render_template(
            'watch.html',
            video_url=video_data['presigned_url'],
            video_data=video_data,
            available_languages=SUPPORTED_LANGUAGES,
            current_language=requested_lang
        )

# ===================================================================
# Flutterìš© ì¶”ê°€ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/api/videos/search', methods=['GET'])
def search_videos_multilingual():
    """
    Flutter ì•±ì˜ ê²€ìƒ‰ ê¸°ëŠ¥ìš© ë‹¤êµ­ì–´ ë¹„ë””ì˜¤ ê²€ìƒ‰ API
    Query params:
    - q: ê²€ìƒ‰ì–´
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    - limit: ê²°ê³¼ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: 50)
    """
    query = request.args.get('q', '').strip()
    lang_code = request.args.get('lang', 'ko')
    limit = int(request.args.get('limit', 50))
    
    if not query:
        return jsonify({'videos': [], 'total': 0, 'query': query})
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    try:
        # Firestoreì—ì„œ ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        matched_videos = []
        
        for doc in docs:
            root_data = doc.to_dict()
            group_id = doc.id
            
            # ë²ˆì—­ ë¬¸ì„œ ì¡°íšŒ
            translation_doc = doc.reference.collection('translations').document(lang_code).get()
            
            # ê²€ìƒ‰ ë§¤ì¹­ í™•ì¸
            is_match = False
            display_title = root_data.get('group_name', '')
            display_main_category = root_data.get('main_category', '')
            display_sub_category = root_data.get('sub_category', '')
            display_sub_sub_category = root_data.get('sub_sub_category', '')
            
            if translation_doc.exists:
                translation_data = translation_doc.to_dict()
                display_title = translation_data.get('title', display_title)
                display_main_category = translation_data.get('main_category', display_main_category)
                display_sub_category = translation_data.get('sub_category', display_sub_category)
                display_sub_sub_category = translation_data.get('sub_sub_category', display_sub_sub_category)
            
            # ì œëª©, ì¹´í…Œê³ ë¦¬ì—ì„œ ê²€ìƒ‰
            search_fields = [display_title, display_main_category, display_sub_category, display_sub_sub_category]
            for field in search_fields:
                if query.lower() in field.lower():
                    is_match = True
                    break
            
            if is_match:
                # URL ê°±ì‹  í™•ì¸
                current_presigned = root_data.get('presigned_url', '')
                if not current_presigned or is_presigned_url_expired(current_presigned, 60):
                    new_presigned_url = generate_presigned_url(root_data['video_key'], expires_in=604800)
                    doc.reference.update({
                        'presigned_url': new_presigned_url,
                        'updated_at': datetime.utcnow().isoformat()
                    })
                    video_url = new_presigned_url
                else:
                    video_url = current_presigned
                
                # ì¸ë„¤ì¼ URL í™•ì¸
                thumbnail_url = root_data.get('thumbnail_presigned_url', '')
                if root_data.get('thumbnail_key') and (not thumbnail_url or is_presigned_url_expired(thumbnail_url, 60)):
                    new_thumbnail_url = generate_presigned_url(root_data['thumbnail_key'], expires_in=604800)
                    doc.reference.update({
                        'thumbnail_presigned_url': new_thumbnail_url
                    })
                    thumbnail_url = new_thumbnail_url
                
                matched_videos.append({
                    'groupId': group_id,
                    'title': display_title,
                    'main_category': display_main_category,
                    'sub_category': display_sub_category,
                    'sub_sub_category': display_sub_sub_category,
                    'level': root_data.get('level', ''),
                    'time': root_data.get('time', '0:00'),
                    'tag': root_data.get('tag', ''),
                    'upload_date': root_data.get('upload_date', ''),
                    'video_url': video_url,
                    'qr_url': root_data.get('qr_presigned_url', ''),
                    'thumbnail_url': thumbnail_url,
                    'language': lang_code
                })
        
        # ì œí•œëœ ê²°ê³¼ ë°˜í™˜
        limited_results = matched_videos[:limit]
        
        return jsonify({
            'videos': limited_results,
            'total': len(limited_results),
            'query': query,
            'language': lang_code,
            'language_name': SUPPORTED_LANGUAGES[lang_code]
        })
        
    except Exception as e:
        app.logger.error(f"ë¹„ë””ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/videos/category/<category>', methods=['GET'])
def get_videos_by_category(category):
    """
    íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ (Flutter LectureListScreenìš©)
    Path params:
    - category: ì¹´í…Œê³ ë¦¬ëª…
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    """
    lang_code = request.args.get('lang', 'ko')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    try:
        # ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        category_videos = []
        
        for doc in docs:
            root_data = doc.to_dict()
            group_id = doc.id
            
            # ë²ˆì—­ ë¬¸ì„œ ì¡°íšŒ
            translation_doc = doc.reference.collection('translations').document(lang_code).get()
            
            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­ í™•ì¸
            check_categories = [
                root_data.get('main_category', ''),
                root_data.get('sub_category', ''),
                root_data.get('sub_sub_category', '')
            ]
            
            if translation_doc.exists:
                translation_data = translation_doc.to_dict()
                check_categories.extend([
                    translation_data.get('main_category', ''),
                    translation_data.get('sub_category', ''),
                    translation_data.get('sub_sub_category', '')
                ])
            
            # ì¹´í…Œê³ ë¦¬ ë§¤ì¹­
            if any(category.lower() in cat.lower() for cat in check_categories if cat):
                # URL ê°±ì‹ 
                current_presigned = root_data.get('presigned_url', '')
                if not current_presigned or is_presigned_url_expired(current_presigned, 60):
                    new_presigned_url = generate_presigned_url(root_data['video_key'], expires_in=604800)
                    doc.reference.update({
                        'presigned_url': new_presigned_url,
                        'updated_at': datetime.utcnow().isoformat()
                    })
                    video_url = new_presigned_url
                else:
                    video_url = current_presigned
                
                # ì¸ë„¤ì¼ URL í™•ì¸
                thumbnail_url = root_data.get('thumbnail_presigned_url', '')
                if root_data.get('thumbnail_key') and (not thumbnail_url or is_presigned_url_expired(thumbnail_url, 60)):
                    new_thumbnail_url = generate_presigned_url(root_data['thumbnail_key'], expires_in=604800)
                    doc.reference.update({
                        'thumbnail_presigned_url': new_thumbnail_url
                    })
                    thumbnail_url = new_thumbnail_url
                
                # ë²ˆì—­ëœ ë°ì´í„° ì‚¬ìš©
                display_data = get_video_with_translation(group_id, lang_code)
                if display_data:
                    category_videos.append({
                        'groupId': group_id,
                        'title': display_data['display_title'],
                        'main_category': display_data['display_main_category'],
                        'sub_category': display_data['display_sub_category'],
                        'sub_sub_category': display_data['display_sub_sub_category'],
                        'level': display_data.get('level', ''),
                        'time': display_data.get('time', '0:00'),
                        'tag': display_data.get('tag', ''),
                        'upload_date': display_data.get('upload_date', ''),
                        'video_url': video_url,
                        'qr_url': display_data.get('qr_presigned_url', ''),
                        'thumbnail_url': thumbnail_url,
                        'language': lang_code
                    })
        
        return jsonify({
            'videos': category_videos,
            'category': category,
            'total': len(category_videos),
            'language': lang_code,
            'language_name': SUPPORTED_LANGUAGES[lang_code]
        })
        
    except Exception as e:
        app.logger.error(f"ì¹´í…Œê³ ë¦¬ë³„ ë¹„ë””ì˜¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ë¹„ë””ì˜¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/user/lectures', methods=['GET'])
def get_user_lectures():
    """
    í˜„ì¬ ì‚¬ìš©ìê°€ ì‹ ì²­í•œ ê°•ì˜ ëª©ë¡ ì¡°íšŒ
    Headers: Authorization: Bearer <firebase_id_token>
    """
    try:
        # Firebase ID í† í° ê²€ì¦ (ì‹¤ì œ êµ¬í˜„ ì‹œ í•„ìš”)
        auth_header = request.headers.get('Authorization', '')
        if not auth_header.startswith('Bearer '):
            return jsonify({'error': 'ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 401
        
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ uidë¥¼ ë°›ëŠ”ë‹¤ê³  ê°€ì •
        uid = request.args.get('uid')
        if not uid:
            return jsonify({'error': 'UIDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        # ì‚¬ìš©ì ë¬¸ì„œì—ì„œ availableLectures ì¡°íšŒ
        user_doc = db.collection('users').document(uid).get()
        
        if not user_doc.exists:
            return jsonify({'lectures': [], 'total': 0})
        
        user_data = user_doc.to_dict()
        available_lectures = user_data.get('availableLectures', [])
        
        # ê° ê°•ì˜ì˜ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        lecture_details = []
        lang_code = request.args.get('lang', 'ko')
        
        for lecture_id in available_lectures:
            lecture_data = get_video_with_translation(lecture_id, lang_code)
            if lecture_data:
                lecture_details.append({
                    'groupId': lecture_id,
                    'title': lecture_data['display_title'],
                    'main_category': lecture_data['display_main_category'],
                    'sub_category': lecture_data['display_sub_category'],
                    'level': lecture_data.get('level', ''),
                    'time': lecture_data.get('time', '0:00'),
                    'video_url': lecture_data.get('presigned_url', ''),
                    'qr_url': lecture_data.get('qr_presigned_url', ''),
                    'thumbnail_url': lecture_data.get('thumbnail_presigned_url', ''),
                })
        
        return jsonify({
            'lectures': lecture_details,
            'total': len(lecture_details),
            'user_uid': uid,
            'language': lang_code
        })
        
    except Exception as e:
        app.logger.error(f"ì‚¬ìš©ì ê°•ì˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ê°•ì˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/user/lectures', methods=['POST'])
def apply_for_lectures():
    """
    ì‚¬ìš©ì ê°•ì˜ ì‹ ì²­ API
    Body: { "uid": "user_uid", "lecture_ids": ["group_id1", "group_id2"] }
    """
    try:
        data = request.get_json() or {}
        uid = data.get('uid')
        lecture_ids = data.get('lecture_ids', [])
        
        if not uid or not lecture_ids:
            return jsonify({'error': 'UIDì™€ ê°•ì˜ IDê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
        
        # Firestoreì— ê°•ì˜ ì‹ ì²­ ì •ë³´ ì €ì¥
        user_ref = db.collection('users').document(uid)
        user_ref.set({
            'availableLectures': firestore.ArrayUnion(lecture_ids),
            'lastUpdated': firestore.SERVER_TIMESTAMP,
        }, merge=True)
        
        return jsonify({
            'message': 'ê°•ì˜ ì‹ ì²­ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'applied_lectures': lecture_ids,
            'user_uid': uid
        }), 200
        
    except Exception as e:
        app.logger.error(f"ê°•ì˜ ì‹ ì²­ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ê°•ì˜ ì‹ ì²­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/categories', methods=['GET'])
def get_categories():
    """
    ë‹¤êµ­ì–´ ì¹´í…Œê³ ë¦¬ êµ¬ì¡° ë°˜í™˜ (Flutter ì•±ì˜ í•˜ë“œì½”ë”© ëŒ€ì‹  ì‚¬ìš©)
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    """
    lang_code = request.args.get('lang', 'ko')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    # ê° ì–¸ì–´ë³„ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (Flutter ì•±ê³¼ ë™ì¼í•œ êµ¬ì¡°)
    categories_ko = {
        'main_categories': ['ì „ì²´', 'ê¸°ê³„', 'ê³µêµ¬', 'ì¥ë¹„', 'ì•½í’ˆ', 'í™”ê³µì•½í’ˆ'],
        'sub_categories': {
            'ì „ì²´': ['ê±´ì„¤ê¸°ê³„', 'ê³µì‘ê¸°ê³„', 'ì‚°ì—…ê¸°ê³„', 'ì œì¡°ê¸°ê³„', 'ìˆ˜ê³µêµ¬', 'ì „ë™ê³µêµ¬', 'ì ˆì‚­ê³µêµ¬', 'ì¸¡ì •ê³µêµ¬', 'ì•ˆì „ì¥ë¹„', 'ìš´ì†¡ì¥ë¹„', 'í•­ìƒì œ', 'ì¸ìŠë¦°', 'í•­ì‘ê³ ì œ', 'í™©ì‚°', 'ì—¼ì‚°', 'ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨'],
            'ê¸°ê³„': ['ê±´ì„¤ê¸°ê³„', 'ê³µì‘ê¸°ê³„', 'ì‚°ì—…ê¸°ê³„', 'ì œì¡°ê¸°ê³„'],
            'ê³µêµ¬': ['ìˆ˜ê³µêµ¬', 'ì „ë™ê³µêµ¬', 'ì ˆì‚­ê³µêµ¬', 'ì¸¡ì •ê³µêµ¬'],
            'ì¥ë¹„': ['ì•ˆì „ì¥ë¹„', 'ìš´ì†¡ì¥ë¹„'],
            'ì•½í’ˆ': ['í•­ìƒì œ', 'ì¸ìŠë¦°', 'í•­ì‘ê³ ì œ'],
            'í™”ê³µì•½í’ˆ': ['í™©ì‚°', 'ì—¼ì‚°', 'ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨']
        },
        'leaf_categories': {
            'ê±´ì„¤ê¸°ê³„': ['ë¶ˆë„ì €', 'í¬ë ˆì¸', 'êµ´ì°©ê¸°'],
            'ê³µì‘ê¸°ê³„': ['CNC ì„ ë°˜', 'ì ˆì‚­ê¸°', 'ì—°ì‚­ê¸°'],
            'ì‚°ì—…ê¸°ê³„': ['ìœ ì•• í”„ë ˆìŠ¤', 'ì»¨ë² ì´ì–´ ì‹œìŠ¤í…œ', 'êµ´ì°©ê¸°'],
            'ì œì¡°ê¸°ê³„': ['ì‚¬ì¶œ ì„±í˜•ê¸°', 'í”„ë ˆìŠ¤ê¸°', 'ì—´ì„±í˜•ê¸°'],
            'ìˆ˜ê³µêµ¬': ['ë“œë¦´', 'í•´ë¨¸', 'í”Œë¼ì´ì–´'],
            'ì „ë™ê³µêµ¬': ['ê·¸ë¼ì¸ë”', 'ì „ë™ í†±', 'í•´ë¨¸ë“œë¦´'],
            'ì ˆì‚­ê³µêµ¬': ['ì»¤í„°', 'í”Œë¼ì¦ˆë§ˆ ë…¸ì¦', 'ë“œë¦´ ë¹„íŠ¸'],
            'ì¸¡ì •ê³µêµ¬': ['ìº˜ë¦¬í¼ìŠ¤', 'í•˜ì´íŠ¸ ê²Œì´ì§€', 'ë§ˆì´í¬ë¡œë¯¸í„°'],
            'ì•ˆì „ì¥ë¹„': ['í—¬ë©§', 'ë°©ì§„ ë§ˆìŠ¤í¬', 'ë‚™í•˜ ë°©ì§€ë²¨íŠ¸', 'ì•ˆì „ëª¨', 'ì•ˆì „í™”', 'ë³´í˜¸ì•ˆê²½', 'ê·€ë§ˆê°œ', 'ë³´í˜¸ì¥ê°‘', 'í˜¸í¡ ë³´í˜¸êµ¬'],
            'ìš´ì†¡ì¥ë¹„': ['ë¦¬í”„íŒ… ì¥ë¹„', 'ì²´ì¸ ë¸”ë¡', 'í˜¸ì´ìŠ¤íŠ¸'],
            'í•­ìƒì œ': ['í˜ë‹ˆì‹¤ë¦°', 'ì•„ëª©ì‹œì‹¤ë¦°', 'ì„¸íŒ”ë¡œìŠ¤í¬ë¦°'],
            'ì¸ìŠë¦°': ['ì†íš¨ì„± ì¸ìŠë¦°', 'ì¤‘ê°„í˜• ì¸ìŠë¦°', 'ì§€ì†í˜• ì¸ìŠë¦°'],
            'í•­ì‘ê³ ì œ': ['ì™€íŒŒë¦°', 'í—¤íŒŒë¦°', 'ë¦¬ë°”ë¡ì‚¬ë°˜'],
            'í™©ì‚°': ['ì§„í•œ í™©ì‚°', 'ë¬½ì€ í™©ì‚°', 'ë°œì—° í™©ì‚°'],
            'ì—¼ì‚°': ['ì§„í•œ ì—¼ì‚°', 'ë¬½ì€ ì—¼ì‚°', 'ê³µì—…ìš© ì—¼ì‚°'],
            'ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨': ['ê³ ì²´ ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨', 'ìˆ˜ìš©ì•¡ ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨', 'í”Œë ˆì´í¬í˜• ìˆ˜ì‚°í™”ë‚˜íŠ¸ë¥¨']
        }
    }
    
    return jsonify({
        'categories': categories_ko,
        'language': lang_code,
        'language_name': SUPPORTED_LANGUAGES[lang_code],
        'supported_languages': SUPPORTED_LANGUAGES
    })

# ===================================================================
# ë‹¤êµ­ì–´ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/api/videos', methods=['GET'])
def get_videos_list():
    """
    ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ API (ë‹¤êµ­ì–´ ì§€ì›)
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    - category: ì¹´í…Œê³ ë¦¬ í•„í„°
    - level: ë ˆë²¨ í•„í„°
    """
    lang_code = request.args.get('lang', 'ko')
    category_filter = request.args.get('category')
    level_filter = request.args.get('level')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    try:
        # ë£¨íŠ¸ ì»¬ë ‰ì…˜ì—ì„œ ê¸°ë³¸ í•„í„°ë§
        query = db.collection('uploads')
        
        if category_filter:
            query = query.where('main_category', '==', category_filter)
        if level_filter:
            query = query.where('level', '==', level_filter)
        
        docs = query.stream()
        
        videos = []
        for doc in docs:
            video_data = get_video_with_translation(doc.id, lang_code)
            if video_data:
                # í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒí•´ì„œ ì‘ë‹µ í¬ê¸° ìµœì†Œí™”
                videos.append({
                    'group_id': video_data['group_id'],
                    'title': video_data['display_title'],
                    'main_category': video_data['display_main_category'],
                    'sub_category': video_data['display_sub_category'],
                    'sub_sub_category': video_data['display_sub_sub_category'],
                    'time': video_data['time'],
                    'level': video_data['level'],
                    'tag': video_data.get('tag', ''),
                    'upload_date': video_data['upload_date'],
                    'language': lang_code,
                    'qr_url': video_data.get('qr_presigned_url', ''),
                    'thumbnail_url': video_data.get('thumbnail_presigned_url', '')
                })
        
        return jsonify({
            'videos': videos,
            'language': lang_code,
            'language_name': SUPPORTED_LANGUAGES[lang_code],
            'total': len(videos)
        })
        
    except Exception as e:
        app.logger.error(f"ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ë¹„ë””ì˜¤ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/videos/<group_id>', methods=['GET'])
def get_video_detail(group_id):
    """
    íŠ¹ì • ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ API (ë‹¤êµ­ì–´ ì§€ì›)
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    """
    lang_code = request.args.get('lang', 'ko')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    video_data = get_video_with_translation(group_id, lang_code)
    if not video_data:
        return jsonify({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
    
    # URL ê°±ì‹  í™•ì¸
    current_presigned = video_data.get('presigned_url', '')
    if not current_presigned or is_presigned_url_expired(current_presigned, 60):
        new_presigned_url = generate_presigned_url(video_data['video_key'], expires_in=604800)
        db.collection('uploads').document(group_id).update({
            'presigned_url': new_presigned_url,
            'updated_at': datetime.utcnow().isoformat()
        })
        video_data['presigned_url'] = new_presigned_url
    
    # ì¸ë„¤ì¼ URL ê°±ì‹  í™•ì¸
    current_thumbnail_url = video_data.get('thumbnail_presigned_url', '')
    thumbnail_key = video_data.get('thumbnail_key', '')
    if thumbnail_key and (not current_thumbnail_url or is_presigned_url_expired(current_thumbnail_url, 60)):
        new_thumbnail_url = generate_presigned_url(thumbnail_key, expires_in=604800)
        db.collection('uploads').document(group_id).update({
            'thumbnail_presigned_url': new_thumbnail_url
        })
        video_data['thumbnail_presigned_url'] = new_thumbnail_url
    
    return jsonify({
        'group_id': video_data['group_id'],
        'title': video_data['display_title'],
        'main_category': video_data['display_main_category'],
        'sub_category': video_data['display_sub_category'],
        'sub_sub_category': video_data['display_sub_sub_category'],
        'time': video_data['time'],
        'level': video_data['level'],
        'tag': video_data.get('tag', ''),
        'video_url': video_data['presigned_url'],
        'qr_url': video_data.get('qr_presigned_url', ''),
        'thumbnail_url': video_data.get('thumbnail_presigned_url', ''),
        'qr_link': video_data.get('qr_link', ''),
        'language': lang_code,
        'language_name': SUPPORTED_LANGUAGES[lang_code],
        'upload_date': video_data['upload_date']
    })

@app.route('/api/admin/add-language', methods=['POST'])
@admin_required
def api_add_language():
    """
    ê´€ë¦¬ììš©: ìƒˆë¡œìš´ ì–¸ì–´ ì¶”ê°€ API
    Body: { "language_code": "fr", "language_name": "FranÃ§ais" }
    """
    data = request.get_json() or {}
    lang_code = data.get('language_code', '').strip().lower()
    lang_name = data.get('language_name', '').strip()
    
    if not lang_code or not lang_name:
        return jsonify({'error': 'language_codeì™€ language_nameì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    if lang_code in SUPPORTED_LANGUAGES:
        return jsonify({'error': f'ì–¸ì–´ ì½”ë“œ {lang_code}ëŠ” ì´ë¯¸ ì§€ì›ë©ë‹ˆë‹¤.'}), 400
    
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        thread = threading.Thread(
            target=add_language_to_existing_videos, 
            args=(lang_code, lang_name)
        )
        thread.daemon = True
        thread.start()
        
        # ì „ì—­ ì–¸ì–´ ëª©ë¡ì— ì¶”ê°€
        SUPPORTED_LANGUAGES[lang_code] = lang_name
        
        return jsonify({
            'message': f'{lang_name}({lang_code}) ì–¸ì–´ ì¶”ê°€ ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'language_code': lang_code,
            'language_name': lang_name
        }), 200
        
    except Exception as e:
        app.logger.error(f"ì–¸ì–´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì–¸ì–´ ì¶”ê°€ ì‘ì—… ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/languages', methods=['GET'])
def get_supported_languages():
    """
    ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ì¡°íšŒ API
    """
    return jsonify({
        'languages': SUPPORTED_LANGUAGES,
        'total': len(SUPPORTED_LANGUAGES)
    })

# ===================================================================
# ê¸°ì¡´ ZIP ìƒì„± ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/generate_weekly_zip', methods=['GET'])
@admin_required
def generate_weekly_zip():
    """
    ê´€ë¦¬ì(JWT) ì¸ì¦ í›„ íŠ¹ì • ì£¼ì°¨ ì „ì²´ ìˆ˜ë£Œì¦ ZIP ìƒì„±/ì¡°íšŒ
    - query param: week (ì˜ˆ: "2025-W23")
    """
    week_param = request.args.get('week')
    if not week_param:
        today = datetime.utcnow().date()
        y, w, _ = today.isocalendar()
        week_param = f"{y}-W{str(w).zfill(2)}"

    zip_key = f"full/{week_param}.zip"

    # 1) S3ì— ZIP ì¡´ì¬í•˜ë©´ presigned URL ë°˜í™˜
    try:
        s3.head_object(Bucket=BUCKET_NAME, Key=zip_key)
        presigned = generate_presigned_url(zip_key, expires_in=3600)
        return jsonify({
            'zipUrl': presigned,
            'generated': False,
            'week': week_param
        })
    except s3.exceptions.ClientError as e:
        if e.response['Error']['Code'] != '404':
            return abort(500, description=f"S3 ì˜¤ë¥˜: {e}")

    # 2) ZIP ì—†ìœ¼ë©´ Firestoreì—ì„œ ì£¼ì°¨ë³„ ìˆ˜ë£Œì¦ ì¡°íšŒ
    try:
        week_start_dt, week_end_dt = parse_iso_week(week_param)
    except ValueError as ex:
        return abort(400, description=str(ex))

    start_ts = firestore.Timestamp.from_datetime(week_start_dt)
    end_ts   = firestore.Timestamp.from_datetime(week_end_dt)

    cert_docs = db.collection_group('completedCertificates') \
                  .where('issuedAt', '>=', start_ts) \
                  .where('issuedAt', '<=', end_ts) \
                  .stream()

    tmp_zip_path = f"/tmp/{week_param}.zip"
    with zipfile.ZipFile(tmp_zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:
        found_any = False
        for cert_doc in cert_docs:
            data          = cert_doc.to_dict()
            pdf_url       = data.get('pdfUrl', '')
            lecture_title = data.get('lectureTitle') or cert_doc.id
            user_uid      = cert_doc.reference.parent.parent.id

            if not pdf_url:
                continue

            found_any = True
            safe_title = re.sub(r'[^\wê°€-í£_-]', '_', lecture_title)
            entry_name = f"{user_uid}_{safe_title}.pdf"

            try:
                resp = requests.get(pdf_url, timeout=30)
                if resp.status_code == 200:
                    zf.writestr(entry_name, resp.content)
                else:
                    app.logger.warning(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({resp.status_code}): {pdf_url}")
            except Exception as fetch_ex:
                app.logger.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {pdf_url} -> {fetch_ex}")

        if not found_any:
            zf.close()
            try:
                os.remove(tmp_zip_path)
            except OSError:
                pass
            return abort(404, description=f"{week_param}ì— ë°œê¸‰ëœ ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤.")

    try:
        s3.upload_file(
            Filename=tmp_zip_path,
            Bucket=BUCKET_NAME,
            Key=zip_key,
            Config=config
        )
    except Exception as upload_ex:
        app.logger.error(f"ZIP ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_ex}")
        return abort(500, description="ZIP ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    try:
        os.remove(tmp_zip_path)
    except OSError:
        pass

    try:
        presigned = generate_presigned_url(zip_key, expires_in=3600)
    except Exception as pre_ex:
        app.logger.error(f"Presigned URL ìƒì„± ì‹¤íŒ¨: {pre_ex}")
        return abort(500, description="Presigned URL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return jsonify({
        'zipUrl': presigned,
        'generated': True,
        'week': week_param
    })

@app.route('/api/admin/users/certs/zip', methods=['GET'])
@admin_required
def generate_selected_zip():
    """
    Flutter í˜¸ì¶œìš©: ì„ íƒí•œ UIDì˜ ìˆ˜ë£Œì¦ ZIP ìƒì„±/ì¡°íšŒ
    - query param: uids=uid1,uid2,...  (ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ UID ëª©ë¡)
                   type=recent|all      ('recent': ì´ë²ˆ ì£¼ì°¨ë§Œ, 'all': ì „ì²´)
    """
    uids_param = request.args.get('uids')
    type_param = request.args.get('type')
    if not uids_param or type_param not in ('recent', 'all'):
        return abort(400, "uidsì™€ type(recent ë˜ëŠ” all) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    uid_list = uids_param.split(',')

    if type_param == 'recent':
        today = datetime.utcnow().date()
        y, w, _ = today.isocalendar()
        week_str = f"{y}-W{str(w).zfill(2)}"
        try:
            week_start_dt, week_end_dt = parse_iso_week(week_str)
        except ValueError as ex:
            return abort(400, description=str(ex))

        start_ts = firestore.Timestamp.from_datetime(week_start_dt)
        end_ts   = firestore.Timestamp.from_datetime(week_end_dt)

    tmp_zip_path = f"/tmp/selected_{uuid.uuid4().hex}.zip"
    with zipfile.ZipFile(tmp_zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:
        found_any = False

        for uid in uid_list:
            coll_ref = db.collection('users').document(uid).collection('completedCertificates')
            if type_param == 'recent':
                docs = coll_ref \
                    .where('issuedAt', '>=', start_ts) \
                    .where('issuedAt', '<=', end_ts) \
                    .stream()
            else:  # 'all'
                docs = coll_ref.stream()

            for cert_doc in docs:
                data          = cert_doc.to_dict()
                pdf_url       = data.get('pdfUrl', '')
                lecture_title = data.get('lectureTitle') or cert_doc.id

                if not pdf_url:
                    continue

                found_any = True
                safe_title = re.sub(r'[^\wê°€-í£_-]', '_', lecture_title)
                entry_name = f"{uid}_{safe_title}.pdf"

                try:
                    resp = requests.get(pdf_url, timeout=30)
                    if resp.status_code == 200:
                        zf.writestr(entry_name, resp.content)
                    else:
                        app.logger.warning(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({resp.status_code}): {pdf_url}")
                except Exception as fetch_ex:
                    app.logger.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {pdf_url} -> {fetch_ex}")

        if not found_any:
            zf.close()
            try:
                os.remove(tmp_zip_path)
            except OSError:
                pass
            return abort(404, description="ì„ íƒëœ ì‚¬ìš©ìì˜ ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤.")

    zip_key = f"selected/{uuid.uuid4().hex}.zip"
    try:
        s3.upload_file(
            Filename=tmp_zip_path,
            Bucket=BUCKET_NAME,
            Key=zip_key,
            Config=config
        )
    except Exception as upload_ex:
        app.logger.error(f"ZIP ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_ex}")
        return abort(500, description="ZIP ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    try:
        os.remove(tmp_zip_path)
    except OSError:
        pass

    try:
        presigned = generate_presigned_url(zip_key, expires_in=3600)
    except Exception as pre_ex:
        app.logger.error(f"Presigned URL ìƒì„± ì‹¤íŒ¨: {pre_ex}")
        return abort(500, description="Presigned URL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return jsonify({
        'zipUrl': presigned,
        'generated': True
    })

# ===================================================================
# ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´ êµ¬ì¡° â†’ ìƒˆ êµ¬ì¡°)
# ===================================================================

@app.route('/api/admin/migrate-to-subcollections', methods=['POST'])
@admin_required
def migrate_to_subcollections():
    """
    ê´€ë¦¬ììš©: ê¸°ì¡´ translations í•„ë“œë¥¼ ì„œë¸Œì»¬ë ‰ì…˜ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
    """
    try:
        # ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads = db.collection('uploads').stream()
        migrated_count = 0
        error_count = 0
        
        for doc in uploads:
            try:
                data = doc.to_dict()
                group_id = doc.id
                
                # ê¸°ì¡´ translations í•„ë“œ í™•ì¸
                old_translations = data.get('translations', {})
                if not old_translations:
                    app.logger.info(f"ë¬¸ì„œ {group_id}: translations í•„ë“œ ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue
                
                # ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ìƒì„±
                translations_ref = doc.reference.collection('translations')
                
                # ì–¸ì–´ë³„ë¡œ ë¬¸ì„œ ìƒì„±
                for lang_code in SUPPORTED_LANGUAGES.keys():
                    translation_data = {
                        'title': old_translations.get('title', {}).get(lang_code, data.get('group_name', '')),
                        'main_category': old_translations.get('main_category', {}).get(lang_code, data.get('main_category', '')),
                        'sub_category': old_translations.get('sub_category', {}).get(lang_code, data.get('sub_category', '')),
                        'sub_sub_category': old_translations.get('sub_sub_category', {}).get(lang_code, data.get('sub_sub_category', '')),
                        'language_code': lang_code,
                        'language_name': SUPPORTED_LANGUAGES[lang_code],
                        'is_original': (lang_code == 'ko'),
                        'migrated_at': datetime.utcnow().isoformat(),
                        'migration_source': 'legacy_translations_field'
                    }
                    
                    translations_ref.document(lang_code).set(translation_data)
                
                # ê¸°ì¡´ translations í•„ë“œ ì œê±°
                doc.reference.update({
                    'translations': firestore.DELETE_FIELD,
                    'migrated_to_subcollections': True,
                    'migration_completed_at': datetime.utcnow().isoformat()
                })
                
                migrated_count += 1
                app.logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {group_id}")
                
            except Exception as doc_error:
                error_count += 1
                app.logger.error(f"âŒ ë¬¸ì„œ {group_id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {doc_error}")
        
        return jsonify({
            'message': 'ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'migrated_count': migrated_count,
            'error_count': error_count,
            'total_processed': migrated_count + error_count
        }), 200
        
    except Exception as e:
        app.logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/admin/cleanup-old-translations', methods=['POST'])
@admin_required
def cleanup_old_translations():
    """
    ê´€ë¦¬ììš©: ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì •ë¦¬ ì‘ì—…
    - migrated_to_subcollections í”Œë˜ê·¸ê°€ ìˆëŠ” ë¬¸ì„œë“¤ì˜ ë‚¨ì€ translations í•„ë“œ ì œê±°
    """
    try:
        uploads = db.collection('uploads') \
                   .where('migrated_to_subcollections', '==', True) \
                   .stream()
        
        cleaned_count = 0
        
        for doc in uploads:
            data = doc.to_dict()
            if 'translations' in data:
                doc.reference.update({
                    'translations': firestore.DELETE_FIELD,
                    'cleaned_up_at': datetime.utcnow().isoformat()
                })
                cleaned_count += 1
                app.logger.info(f"âœ… ì •ë¦¬ ì™„ë£Œ: {doc.id}")
        
        return jsonify({
            'message': 'ì •ë¦¬ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'cleaned_count': cleaned_count
        }), 200
        
    except Exception as e:
        app.logger.error(f"ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# í†µê³„ ë° ëª¨ë‹ˆí„°ë§ API
# ===================================================================

@app.route('/api/admin/stats', methods=['GET'])
@admin_required
def get_admin_stats():
    """
    ê´€ë¦¬ììš© í†µê³„ ëŒ€ì‹œë³´ë“œ API
    """
    try:
        # ì „ì²´ ë¹„ë””ì˜¤ ìˆ˜
        total_videos = len(list(db.collection('uploads').stream()))
        
        # ì–¸ì–´ë³„ ë²ˆì—­ ì™„ì„±ë„
        language_stats = {}
        for lang_code, lang_name in SUPPORTED_LANGUAGES.items():
            translation_count = 0
            uploads = db.collection('uploads').stream()
            
            for doc in uploads:
                translation_doc = doc.reference.collection('translations').document(lang_code).get()
                if translation_doc.exists:
                    translation_count += 1
            
            language_stats[lang_code] = {
                'name': lang_name,
                'translated_count': translation_count,
                'completion_rate': (translation_count / total_videos * 100) if total_videos > 0 else 0
            }
        
        # ìµœê·¼ ì—…ë¡œë“œ (7ì¼)
        week_ago = datetime.utcnow() - timedelta(days=7)
        recent_uploads = 0
        uploads = db.collection('uploads').where('created_at', '>=', week_ago.isoformat()).stream()
        recent_uploads = len(list(uploads))
        
        return jsonify({
            'total_videos': total_videos,
            'supported_languages': len(SUPPORTED_LANGUAGES),
            'language_stats': language_stats,
            'recent_uploads_7days': recent_uploads,
            'scheduler_running': scheduler.running if 'scheduler' in globals() else False
        }), 200
        
    except Exception as e:
        app.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'í†µê³„ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
# ===================================================================

@app.route('/health', methods=['GET'])
def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # Firestore ì—°ê²° í™•ì¸
        db.collection('uploads').limit(1).get()
        firestore_status = 'healthy'
    except Exception:
        firestore_status = 'unhealthy'
    
    try:
        # S3 ì—°ê²° í™•ì¸
        s3.head_bucket(Bucket=BUCKET_NAME)
        s3_status = 'healthy'
    except Exception:
        s3_status = 'unhealthy'
    
    overall_status = 'healthy' if (firestore_status == 'healthy' and s3_status == 'healthy') else 'unhealthy'
    
    return jsonify({
        'status': overall_status,
        'timestamp': datetime.utcnow().isoformat(),
        'services': {
            'firestore': firestore_status,
            's3': s3_status,
            'scheduler': scheduler.running if 'scheduler' in globals() else False
        },
        'supported_languages': list(SUPPORTED_LANGUAGES.keys()),
        'version': '2.1.0-fixed'
    }), 200 if overall_status == 'healthy' else 503

# ===================================================================
# Railway í™˜ê²½ ì´ˆê¸°í™”
# ===================================================================

def initialize_railway_environment():
    """Railway ë°°í¬ í™˜ê²½ ì´ˆê¸°í™”"""
    try:
        # í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™”
        initialize_korean_fonts()
        
        # ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸
        os.makedirs('static', exist_ok=True)
        os.makedirs('fonts', exist_ok=True)
        
        # í™˜ê²½ë³„ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
        if os.environ.get('RAILWAY_ENVIRONMENT'):
            import logging
            app.logger.setLevel(logging.INFO)
        
        app.logger.info("ğŸš‚ Railway í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ (ì•ˆì „ ëª¨ë“œ)")
        return True
        
    except Exception as e:
        app.logger.error(f"âŒ Railway í™˜ê²½ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# ===================================================================
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (ìš´ì˜ì—ì„œëŠ” ì œê±° ê¶Œì¥)
# ===================================================================

@app.route('/api/dev/test-translation', methods=['POST'])
def test_translation():
    """
    ê°œë°œìš©: ë²ˆì—­ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    Body: { "text": "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸", "target_lang": "en" }
    """
    if not app.debug:  # ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
        return jsonify({'error': 'ê°œë°œ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.'}), 403
    
    data = request.get_json() or {}
    text = data.get('text', '')
    target_lang = data.get('target_lang', 'en')
    
    if not text:
        return jsonify({'error': 'textê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    try:
        translated = translate_text(text, target_lang)
        return jsonify({
            'original': text,
            'translated': translated,
            'target_language': target_lang,
            'target_language_name': SUPPORTED_LANGUAGES.get(target_lang, target_lang)
        })
    except Exception as e:
        return jsonify({'error': f'ë²ˆì—­ ì‹¤íŒ¨: {e}'}), 500

@app.route('/api/dev/test-qr', methods=['POST'])
def test_qr_generation():
    """
    ê°œë°œìš©: QR ì½”ë“œ ìƒì„± í…ŒìŠ¤íŠ¸
    Body: { "url": "https://example.com", "title": "í…ŒìŠ¤íŠ¸ ê°•ì˜" }
    """
    if not app.debug:
        return jsonify({'error': 'ê°œë°œ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.'}), 403
    
    data = request.get_json() or {}
    url = data.get('url', 'https://example.com')
    title = data.get('title', 'í…ŒìŠ¤íŠ¸ ê°•ì˜')
    
    try:
        # ì„ì‹œ íŒŒì¼ ìƒì„±
        test_qr_path = f"/tmp/test_qr_{uuid.uuid4().hex}.png"
        create_qr_with_logo(url, test_qr_path, lecture_title=title)
        
        # S3ì— ì—…ë¡œë“œ
        test_key = f"test/qr_{uuid.uuid4().hex}.png"
        s3.upload_file(test_qr_path, BUCKET_NAME, test_key)
        
        # Presigned URL ìƒì„±
        presigned_url = generate_presigned_url(test_key, expires_in=3600)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(test_qr_path)
        
        return jsonify({
            'message': 'QR ì½”ë“œ ìƒì„± ì„±ê³µ',
            'qr_url': presigned_url,
            'expires_in': '1ì‹œê°„'
        })
        
    except Exception as e:
        return jsonify({'error': f'QR ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {e}'}), 500

# ===================================================================
# ì¸ë„¤ì¼ ê´€ë¦¬ API
# ===================================================================

@app.route('/api/videos/<group_id>/thumbnail', methods=['POST'])
@admin_required
def update_thumbnail(group_id):
    """
    ê¸°ì¡´ ë¹„ë””ì˜¤ì˜ ì¸ë„¤ì¼ ì—…ë°ì´íŠ¸
    """
    # ë¹„ë””ì˜¤ ì¡´ì¬ í™•ì¸
    doc_ref = db.collection('uploads').document(group_id)
    doc = doc_ref.get()
    
    if not doc.exists:
        return jsonify({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
    
    thumbnail = request.files.get('thumbnail')
    if not thumbnail:
        return jsonify({'error': 'ì¸ë„¤ì¼ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    try:
        data = doc.to_dict()
        
        # ê¸°ì¡´ ì¸ë„¤ì¼ ì‚­ì œ (ìˆëŠ” ê²½ìš°)
        old_thumbnail_key = data.get('thumbnail_key')
        if old_thumbnail_key:
            try:
                s3.delete_object(Bucket=BUCKET_NAME, Key=old_thumbnail_key)
            except Exception as e:
                app.logger.warning(f"ê¸°ì¡´ ì¸ë„¤ì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # ìƒˆ ì¸ë„¤ì¼ ì—…ë¡œë“œ
        thumb_ext = Path(thumbnail.filename).suffix.lower() or '.jpg'
        date_str = data.get('upload_date', datetime.now().strftime('%Y%m%d'))
        safe_name = re.sub(r'[^\w]', '_', data.get('group_name', 'default'))
        folder = f"videos/{group_id}_{safe_name}_{date_str}"
        thumbnail_key = f"{folder}/thumbnail_{uuid.uuid4().hex}{thumb_ext}"
        
        # ì„ì‹œ ì €ì¥
        thumb_tmp_path = Path(tempfile.gettempdir()) / f"{group_id}_new_thumb{thumb_ext}"
        thumbnail.save(thumb_tmp_path)
        
        # S3 ì—…ë¡œë“œ
        s3.upload_file(str(thumb_tmp_path), BUCKET_NAME, thumbnail_key, Config=config)
        thumb_tmp_path.unlink(missing_ok=True)
        
        # Presigned URL ìƒì„±
        thumbnail_presigned_url = generate_presigned_url(thumbnail_key, expires_in=604800)
        
        # Firestore ì—…ë°ì´íŠ¸
        doc_ref.update({
            'thumbnail_key': thumbnail_key,
            'thumbnail_presigned_url': thumbnail_presigned_url,
            'thumbnail_updated_at': datetime.utcnow().isoformat()
        })
        
        return jsonify({
            'message': 'ì¸ë„¤ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'thumbnail_url': thumbnail_presigned_url
        }), 200
        
    except Exception as e:
        app.logger.error(f"ì¸ë„¤ì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì¸ë„¤ì¼ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/videos/<group_id>/thumbnail', methods=['DELETE'])
@admin_required
def delete_thumbnail(group_id):
    """
    ë¹„ë””ì˜¤ì˜ ì¸ë„¤ì¼ ì‚­ì œ
    """
    # ë¹„ë””ì˜¤ ì¡´ì¬ í™•ì¸
    doc_ref = db.collection('uploads').document(group_id)
    doc = doc_ref.get()
    
    if not doc.exists:
        return jsonify({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
    
    try:
        data = doc.to_dict()
        thumbnail_key = data.get('thumbnail_key')
        
        if not thumbnail_key:
            return jsonify({'error': 'ì‚­ì œí•  ì¸ë„¤ì¼ì´ ì—†ìŠµë‹ˆë‹¤.'}), 404
        
        # S3ì—ì„œ ì‚­ì œ
        try:
            s3.delete_object(Bucket=BUCKET_NAME, Key=thumbnail_key)
        except Exception as e:
            app.logger.warning(f"S3 ì¸ë„¤ì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        
        # Firestore ì—…ë°ì´íŠ¸
        doc_ref.update({
            'thumbnail_key': firestore.DELETE_FIELD,
            'thumbnail_presigned_url': firestore.DELETE_FIELD,
            'thumbnail_deleted_at': datetime.utcnow().isoformat()
        })
        
        return jsonify({'message': 'ì¸ë„¤ì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'}), 200
        
    except Exception as e:
        app.logger.error(f"ì¸ë„¤ì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì¸ë„¤ì¼ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# ì´ˆê¸°í™” í•¨ìˆ˜ë“¤
# ===================================================================

def initialize_certificate_system():
    """ìˆ˜ë£Œì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        # ReportLab í°íŠ¸ ë“±ë¡
        register_korean_font_for_reportlab()
        
        # í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs('static', exist_ok=True)
        
        # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
        required_images = [
            CERTIFICATE_CONFIG['background_image'],
            CERTIFICATE_CONFIG['profile_image'],
            CERTIFICATE_CONFIG['default_profile']
        ]
        
        for img_path in required_images:
            if not os.path.exists(img_path):
                app.logger.warning(f"âš ï¸  ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {img_path}")
                # ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± (ì„ íƒì‚¬í•­)
                _create_placeholder_image(img_path)
        
        app.logger.info("âœ… ìˆ˜ë£Œì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
        
    except Exception as e:
        app.logger.error(f"âŒ ìˆ˜ë£Œì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def _create_placeholder_image(path):
    """í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„±"""
    try:
        # ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
        filename = os.path.basename(path)
        
        if 'background' in filename:
            # A4 ê°€ë¡œ í¬ê¸° ë°°ê²½
            img = Image.new('RGB', (2480, 1754), color='white')
            draw = ImageDraw.Draw(img)
            # í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
            draw.rectangle([10, 10, 2470, 1744], outline='gray', width=3)
        else:
            # í”„ë¡œí•„ ì´ë¯¸ì§€ (ì •ì‚¬ê°í˜•)
            img = Image.new('RGB', (400, 400), color='lightgray')
            draw = ImageDraw.Draw(img)
            # ì› ê·¸ë¦¬ê¸°
            draw.ellipse([50, 50, 350, 350], outline='gray', width=3)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(path), exist_ok=True)
        # ì´ë¯¸ì§€ ì €ì¥
        img.save(path)
        app.logger.info(f"âœ… í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„±: {path}")
        
    except Exception as e:
        app.logger.error(f"í”Œë ˆì´ìŠ¤í™€ë” ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")

# ===================================================================
# ì•± ì‹œì‘ ì‹œ ì‹¤í–‰
# ===================================================================

if __name__ == "__main__":
    # Railway í™˜ê²½ ì´ˆê¸°í™”
    initialize_railway_environment()
    
    # ìˆ˜ë£Œì¦ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ì¶”ê°€)
    initialize_certificate_system()
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    start_background_scheduler()
    
    port = int(os.environ.get("PORT", 8080))
    
    # Railway í™˜ê²½ì—ì„œëŠ” gunicorn ì‚¬ìš© ê¶Œì¥
    if os.environ.get('RAILWAY_ENVIRONMENT'):
        # Railwayì—ì„œëŠ” gunicornì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        app.run(host="0.0.0.0", port=port, debug=False)
    else:
        # ë¡œì»¬ ê°œë°œ í™˜ê²½
        app.run(host="0.0.0.0", port=port, debug=True)