# backend/app.py

import os
import uuid
import re
import io
import tempfile
import urllib.request
from pathlib import Path
from datetime import datetime, timedelta, date

from flask import (
    Flask, request, render_template,
    redirect, url_for, session, abort, jsonify
)
import boto3
from boto3.s3.transfer import TransferConfig
import qrcode
from PIL import Image, ImageDraw, ImageFont
from urllib.parse import urlparse, parse_qs
import requests
import zipfile
import jwt  # PyJWT
from functools import wraps

import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage

# â”€â”€ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì¶”ê°€ â”€â”€
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.interval import IntervalTrigger
import atexit
import threading

# â”€â”€ ë³€ê²½ëœ ë¶€ë¶„: video íŒŒì¼ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•œ import (MoviePy ìµœì‹  ê²½ë¡œ) â”€â”€
from moviepy.video.io.VideoFileClip import VideoFileClip

# â”€â”€ ë²ˆì—­ ê´€ë ¨ import ì¶”ê°€ â”€â”€
from googletrans import Translator
import time

# ==== í™˜ê²½ë³€ìˆ˜ ì„¤ì • ====
ADMIN_EMAIL       = os.environ.get('ADMIN_EMAIL', '')
ADMIN_PASSWORD    = os.environ.get('ADMIN_PASSWORD', 'changeme')
JWT_SECRET        = os.environ.get('JWT_SECRET', 'supersecretjwt')
JWT_ALGORITHM     = 'HS256'
JWT_EXPIRES_HOURS = 4

AWS_ACCESS_KEY    = os.environ['AWS_ACCESS_KEY']
AWS_SECRET_KEY    = os.environ['AWS_SECRET_KEY']
REGION_NAME       = os.environ['REGION_NAME']
BUCKET_NAME       = os.environ['BUCKET_NAME']
APP_BASE_URL      = os.environ.get('APP_BASE_URL', 'http://localhost:5000/watch/')
SECRET_KEY        = os.environ.get('FLASK_SECRET_KEY', 'supersecret')

# ==== ë²ˆì—­ ê´€ë ¨ ì„¤ì • ====
# ì „ì—­ ë²ˆì—­ê¸° ì¸ìŠ¤í„´ìŠ¤
translator = Translator()

# ì§€ì› ì–¸ì–´ ì½”ë“œ ë§¤í•‘
SUPPORTED_LANGUAGES = {
    'ko': 'í•œêµ­ì–´',
    'en': 'English',
    'zh': 'ä¸­æ–‡',
    'vi': 'Tiáº¿ng Viá»‡t',
    'th': 'à¹„à¸—à¸¢',
    'uz': 'O\'zbek',
    'ja': 'æ—¥æœ¬èª'
}

# ==== Firebase Admin + Firestore + Storage ì´ˆê¸°í™” ====
if not firebase_admin._apps:
    firebase_creds = {
        "type":                        os.environ["type"],
        "project_id":                  os.environ["project_id"],
        "private_key_id":              os.environ["private_key_id"],
        "private_key":                 os.environ["private_key"].replace('\\n','\n'),
        "client_email":                os.environ["client_email"],
        "client_id":                   os.environ["client_id"],
        "auth_uri":                    os.environ["auth_uri"],
        "token_uri":                   os.environ["token_uri"],
        "auth_provider_x509_cert_url": os.environ["auth_provider_x509_cert_url"],
        "client_x509_cert_url":        os.environ["client_x509_cert_url"]
    }
    cred = credentials.Certificate(firebase_creds)
    firebase_admin.initialize_app(cred, {
        'storageBucket': f"{os.environ['project_id']}.appspot.com"
    })

db     = firestore.client()
bucket = storage.bucket()  # Firebase Storage ê¸°ë³¸ ë²„í‚·

# ==== Flask ì•± ì„¤ì • ====
app = Flask(__name__)
app.secret_key                   = SECRET_KEY
app.config['UPLOAD_FOLDER']      = 'static'
app.config['MAX_CONTENT_LENGTH'] = 2 * 1024 * 1024 * 1024  # 2GB ìƒí•œ
os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)

# ==== Wasabi S3 í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ====
s3 = boto3.client(
    's3',
    aws_access_key_id     = AWS_ACCESS_KEY,
    aws_secret_access_key = AWS_SECRET_KEY,
    region_name           = REGION_NAME,
    endpoint_url          = f'https://s3.{REGION_NAME}.wasabisys.com'
)
config = TransferConfig(
    multipart_threshold = 1024 * 1024 * 25,
    multipart_chunksize = 1024 * 1024 * 50,
    max_concurrency     = 5,
    use_threads         = True
)

# ==== ë²ˆì—­ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====

def translate_text(text, target_language):
    """
    Google Translate APIë¥¼ ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ ë²ˆì—­
    
    Args:
        text: ë²ˆì—­í•  í…ìŠ¤íŠ¸ (í•œêµ­ì–´)
        target_language: ëŒ€ìƒ ì–¸ì–´ ì½”ë“œ
    
    Returns:
        ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” ì›ë³¸ í…ìŠ¤íŠ¸ (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        if target_language == 'ko' or not text.strip():
            return text  # í•œêµ­ì–´ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ, ë¹ˆ í…ìŠ¤íŠ¸ë„ ê·¸ëŒ€ë¡œ
        
        # ë²ˆì—­ ìš”ì²­ (í•œêµ­ì–´ â†’ ëŒ€ìƒ ì–¸ì–´)
        result = translator.translate(text, src='ko', dest=target_language)
        translated_text = result.text
        
        app.logger.info(f"ë²ˆì—­ ì™„ë£Œ: '{text}' â†’ '{translated_text}' ({target_language})")
        return translated_text
        
    except Exception as e:
        app.logger.warning(f"ë²ˆì—­ ì‹¤íŒ¨ ({target_language}): {e}, ì›ë³¸ í…ìŠ¤íŠ¸ ì‚¬ìš©")
        return text

def create_multilingual_metadata(korean_text):
    """
    í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë“  ì§€ì› ì–¸ì–´ë¡œ ë²ˆì—­
    
    Args:
        korean_text: ë²ˆì—­í•  í•œêµ­ì–´ í…ìŠ¤íŠ¸
    
    Returns:
        Dict: ì–¸ì–´ë³„ ë²ˆì—­ ê²°ê³¼
    """
    translations = {}
    
    if not korean_text.strip():
        # ë¹ˆ í…ìŠ¤íŠ¸ë©´ ëª¨ë“  ì–¸ì–´ì— ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
        return {lang: '' for lang in SUPPORTED_LANGUAGES.keys()}
    
    for lang_code in SUPPORTED_LANGUAGES.keys():
        try:
            translated = translate_text(korean_text, lang_code)
            translations[lang_code] = translated
            
            # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ì§§ì€ ëŒ€ê¸°
            if lang_code != 'ko':
                time.sleep(0.2)
                
        except Exception as e:
            app.logger.error(f"ì–¸ì–´ {lang_code} ë²ˆì—­ ì¤‘ ì˜¤ë¥˜: {e}")
            translations[lang_code] = korean_text
    
    return translations

# ==== ê¸°ì¡´ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====

def generate_presigned_url(key, expires_in=86400):
    """
    S3 ê°ì²´ì— ëŒ€í•´ presigned URL ìƒì„±
    expires_in: URL ìœ íš¨ ê¸°ê°„(ì´ˆ)
    """
    return s3.generate_presigned_url(
        ClientMethod='get_object',
        Params={'Bucket': BUCKET_NAME, 'Key': key},
        ExpiresIn=expires_in
    )

def download_korean_font():
    """
    Railway í™˜ê²½ì—ì„œ í•œêµ­ì–´ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ë° ì„¤ì •
    """
    font_dir = Path("fonts")
    font_dir.mkdir(exist_ok=True)
    
    font_path = font_dir / "NotoSansKR-Regular.ttf"
    
    if font_path.exists():
        return str(font_path)
    
    try:
        font_url = "https://fonts.gstatic.com/s/notosanskr/v27/PbykFmXiEBPT4ITbgNA5Cgm20xz64px_1hVWr0wuPNGmlQNMEfD4.ttf"
        app.logger.info("ğŸ“¥ í•œêµ­ì–´ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        urllib.request.urlretrieve(font_url, font_path)
        app.logger.info(f"âœ… í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {font_path}")
        return str(font_path)
    except Exception as e:
        app.logger.error(f"âŒ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def get_korean_font(size=24):
    """
    Railway í™˜ê²½ì—ì„œ í•œêµ­ì–´ í°íŠ¸ ë¡œë“œ
    """
    try:
        # 1. ë‹¤ìš´ë¡œë“œëœ í•œêµ­ì–´ í°íŠ¸ ì‹œë„
        korean_font_path = download_korean_font()
        if korean_font_path and os.path.exists(korean_font_path):
            return ImageFont.truetype(korean_font_path, size)
        
        # 2. Railway/Linux í™˜ê²½ í°íŠ¸ ê²½ë¡œë“¤
        linux_korean_fonts = [
            '/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',
            '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf'
        ]
        
        for font_path in linux_korean_fonts:
            if os.path.exists(font_path):
                try:
                    return ImageFont.truetype(font_path, size)
                except Exception:
                    continue
        
        app.logger.warning("âš ï¸ í•œêµ­ì–´ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return ImageFont.load_default()
        
    except Exception as e:
        app.logger.error(f"í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return ImageFont.load_default()

def get_text_dimensions(text, font, draw):
    """í…ìŠ¤íŠ¸ í¬ê¸° ê³„ì‚° (Pillow ë²„ì „ í˜¸í™˜ì„±)"""
    try:
        bbox = draw.textbbox((0, 0), text, font=font)
        return bbox[2] - bbox[0], bbox[3] - bbox[1]
    except AttributeError:
        return draw.textsize(text, font=font)

def split_korean_text(text, font, max_width, draw):
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ í­ì— ë§ê²Œ ë¶„í• """
    words = text.split()
    lines = []
    current_line = ""
    
    for word in words:
        test_line = current_line + (" " if current_line else "") + word
        test_width, _ = get_text_dimensions(test_line, font, draw)
        
        if test_width <= max_width:
            current_line = test_line
        else:
            if current_line:
                lines.append(current_line)
                current_line = word
            else:
                # ë‹¨ì–´ê°€ ë„ˆë¬´ ê¸´ ê²½ìš° ê°•ì œ ë¶„í• 
                while word:
                    test_width, _ = get_text_dimensions(word, font, draw)
                    if test_width <= max_width:
                        lines.append(word)
                        break
                    # ê¸€ì ë‹¨ìœ„ë¡œ ë¶„í• 
                    for i in range(len(word), 0, -1):
                        substr = word[:i]
                        test_width, _ = get_text_dimensions(substr, font, draw)
                        if test_width <= max_width:
                            lines.append(substr)
                            word = word[i:]
                            break
                current_line = ""
    
    if current_line:
        lines.append(current_line)
    
    return lines

def create_qr_with_logo(link_url, output_path, logo_path='static/logo.png', size_ratio=0.25, lecture_title=""):
    """
    ê°œì„ ëœ QR ì½”ë“œ ìƒì„± - Railway í™˜ê²½ ìµœì í™” (í•œêµ­ì–´ í°íŠ¸ ì§€ì›)
    
    Args:
        link_url: QR ì½”ë“œì— ë‹´ì„ URL
        output_path: ì €ì¥í•  ê²½ë¡œ
        logo_path: ë¡œê³  ì´ë¯¸ì§€ ê²½ë¡œ
        size_ratio: ë¡œê³  í¬ê¸° ë¹„ìœ¨
        lecture_title: í•˜ë‹¨ì— í‘œì‹œí•  ê°•ì˜ëª…
    """
    from PIL import ImageDraw, ImageFont
    
    # QR ì½”ë“œ ìƒì„± (ë” í° í¬ê¸°ì™€ ë†’ì€ ì˜¤ë¥˜ ë³µêµ¬)
    qr = qrcode.QRCode(
        version=1,
        error_correction=qrcode.constants.ERROR_CORRECT_H,
        box_size=12,  # ë°•ìŠ¤ í¬ê¸° ì¦ê°€
        border=4,
    )
    qr.add_data(link_url)
    qr.make(fit=True)
    
    # QR ì´ë¯¸ì§€ ìƒì„± ë° í¬ê¸° ì¡°ì •
    qr_img = qr.make_image(fill_color="black", back_color="white").convert("RGB")
    qr_size = 500  # ê³ ì • í¬ê¸°ë¡œ ë” í¬ê²Œ
    qr_img = qr_img.resize((qr_size, qr_size), Image.LANCZOS)
    qr_w, qr_h = qr_img.size

    # ë¡œê³  ì‚½ì…
    if os.path.exists(logo_path):
        try:
            logo = Image.open(logo_path)
            logo_size = int(qr_w * size_ratio)
            logo = logo.resize((logo_size, logo_size), Image.LANCZOS)
            pos = ((qr_w - logo_size) // 2, (qr_h - logo_size) // 2)
            qr_img.paste(logo, pos, mask=(logo if logo.mode == 'RGBA' else None))
        except Exception as e:
            app.logger.warning(f"ë¡œê³  ì‚½ì… ì‹¤íŒ¨: {e}")

    # ê°•ì˜ëª… í…ìŠ¤íŠ¸ ì¶”ê°€ (ê°œì„ ëœ í•œêµ­ì–´ ì§€ì›)
    if lecture_title.strip():
        # í…ìŠ¤íŠ¸ ì˜ì—­ì„ ì¶©ë¶„íˆ í¬ê²Œ ì„¤ì •
        text_height = int(qr_h * 0.3)  # QR ì½”ë“œ ë†’ì´ì˜ 30%
        margin = int(qr_h * 0.04)      # ì—¬ë°± 4%
        
        # ìƒˆ ì´ë¯¸ì§€ ìƒì„±
        total_height = qr_h + text_height + margin
        final_img = Image.new('RGB', (qr_w, total_height), 'white')
        final_img.paste(qr_img, (0, 0))
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° ì¤€ë¹„
        draw = ImageDraw.Draw(final_img)
        
        # í•œêµ­ì–´ í°íŠ¸ ë¡œë“œ (ì¶©ë¶„íˆ í° í¬ê¸°)
        base_font_size = max(28, int(text_height * 0.18))  # ìµœì†Œ 28px
        font = get_korean_font(base_font_size)
        
        # í…ìŠ¤íŠ¸ ì˜ì—­ ê³„ì‚°
        max_width = qr_w - 60  # ì¢Œìš° ì—¬ë°± 30pxì”©
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë¶„í• 
        lines = split_korean_text(lecture_title, font, max_width, draw)
        
        # 3ì¤„ ì´ìƒì´ë©´ í°íŠ¸ í¬ê¸° ì¡°ì •
        if len(lines) > 3:
            font_size = max(22, int(base_font_size * 0.75))
            font = get_korean_font(font_size)
            lines = split_korean_text(lecture_title, font, max_width, draw)
            
            # ì—¬ì „íˆ 3ì¤„ ì´ìƒì´ë©´ ìë¥´ê¸°
            if len(lines) > 3:
                lines = lines[:2]
                last_line = lines[1]
                while True:
                    test_text = last_line + "..."
                    test_width, _ = get_text_dimensions(test_text, font, draw)
                    if test_width <= max_width or len(last_line) <= 3:
                        lines[1] = test_text
                        break
                    last_line = last_line[:-1]
        
        # ìµœëŒ€ 3ì¤„ë¡œ ì œí•œ
        lines = lines[:3]
        
        # í…ìŠ¤íŠ¸ ë°°ì¹˜ ê³„ì‚°
        _, line_height = get_text_dimensions("í•œê¸€Ag", font, draw)
        total_text_height = len(lines) * line_height + (len(lines) - 1) * 8  # ì¤„ê°„ê²© 8px
        text_y_start = qr_h + margin + (text_height - total_text_height) // 2
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
        for i, line in enumerate(lines):
            if not line.strip():
                continue
                
            text_width, _ = get_text_dimensions(line, font, draw)
            text_x = (qr_w - text_width) // 2  # ì¤‘ì•™ ì •ë ¬
            text_y = text_y_start + (i * (line_height + 8))
            
            # ê°€ë…ì„±ì„ ìœ„í•œ í°ìƒ‰ ì™¸ê³½ì„  (ì„ íƒì‚¬í•­)
            outline_offset = 2
            for dx in [-outline_offset, 0, outline_offset]:
                for dy in [-outline_offset, 0, outline_offset]:
                    if dx != 0 or dy != 0:
                        draw.text((text_x + dx, text_y + dy), line, font=font, fill='white')
            
            # ë©”ì¸ í…ìŠ¤íŠ¸ (ê²€ì€ìƒ‰)
            draw.text((text_x, text_y), line, font=font, fill='black')
        
        # ê³ í’ˆì§ˆë¡œ ì €ì¥
        final_img.save(output_path, quality=95, optimize=True, dpi=(300, 300))
        app.logger.info(f"âœ… ê°œì„ ëœ QR ì½”ë“œ ìƒì„± ì™„ë£Œ: {lecture_title} (í¬ê¸°: {qr_w}x{total_height})")
        
    else:
        # ê°•ì˜ëª…ì´ ì—†ìœ¼ë©´ QR ì½”ë“œë§Œ ì €ì¥
        qr_img.save(output_path, quality=95, optimize=True)
        app.logger.info("âœ… QR ì½”ë“œ ìƒì„± ì™„ë£Œ (ê°•ì˜ëª… ì—†ìŒ)")

def initialize_korean_fonts():
    """ì•± ì‹œì‘ ì‹œ í•œêµ­ì–´ í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™”"""
    try:
        font_dir = Path("fonts")
        font_dir.mkdir(exist_ok=True)
        
        # í•œêµ­ì–´ í°íŠ¸ ë¯¸ë¦¬ ë‹¤ìš´ë¡œë“œ
        download_korean_font()
        
        app.logger.info("âœ… í•œêµ­ì–´ í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        app.logger.error(f"âŒ í•œêµ­ì–´ í°íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

def is_presigned_url_expired(url, safety_margin_minutes=60):
    """
    presigned URL ë§Œë£Œ ì—¬ë¶€ í™•ì¸
    safety_margin_minutes: ë§Œë£Œ ì „ì— ì•ˆì „ ì—¬ìœ  ì‹œê°„(ë¶„)
    """
    try:
        parsed      = urlparse(url)
        query       = parse_qs(parsed.query)
        if 'X-Amz-Date' not in query or 'X-Amz-Expires' not in query:
            return True
        issued_str  = query['X-Amz-Date'][0]
        expires_in  = int(query['X-Amz-Expires'][0])
        issued_time = datetime.strptime(issued_str, '%Y%m%dT%H%M%SZ')
        expiry_time = issued_time + timedelta(seconds=expires_in)
        margin_time = datetime.utcnow() + timedelta(minutes=safety_margin_minutes)
        return margin_time >= expiry_time
    except Exception as e:
        app.logger.warning(f"URL ê²€ì‚¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return True

def parse_iso_week(week_str: str):
    """
    week_str í˜•ì‹: "YYYY-Www" (ì˜ˆ: "2025-W23")
    â†’ í•´ë‹¹ ISO ì£¼ì˜ ì›”ìš”ì¼ 00:00:00 ~ ì¼ìš”ì¼ 23:59:59 (UTC) ë°˜í™˜
    """
    try:
        year_part, week_part = week_str.split('-W')
        year     = int(year_part)
        week_num = int(week_part)
        week_start_date = date.fromisocalendar(year, week_num, 1)  # ì›”ìš”ì¼
        week_end_date   = week_start_date + timedelta(days=6)      # ì¼ìš”ì¼

        week_start_dt = datetime.combine(week_start_date, datetime.min.time())
        week_end_dt   = datetime.combine(week_end_date,   datetime.max.time())
        return week_start_dt, week_end_dt
    except Exception as e:
        raise ValueError(f"ì˜ëª»ëœ week_str í˜•ì‹: {week_str} ({e})")

def create_jwt_for_admin():
    """
    ê´€ë¦¬ì ë¡œê·¸ì¸ ì‹œ JWT ë°œê¸‰
    - payloadì— ë°œê¸‰ ì‹œê°„, ë§Œë£Œ ì‹œê°„, ì‹ë³„ìë¡œ admin_email í¬í•¨
    """
    now      = datetime.utcnow()
    payload  = {
        'sub': ADMIN_EMAIL,
        'iat': now,
        'exp': now + timedelta(hours=JWT_EXPIRES_HOURS)
    }
    token = jwt.encode(payload, JWT_SECRET, algorithm=JWT_ALGORITHM)
    return token

def verify_jwt_token(token: str) -> bool:
    """
    JWT í† í° ê²€ì¦
    """
    try:
        payload = jwt.decode(token, JWT_SECRET, algorithms=[JWT_ALGORITHM])
        return payload.get('sub') == ADMIN_EMAIL
    except jwt.ExpiredSignatureError:
        return False
    except Exception:
        return False

def admin_required(f):
    """
    ë°ì½”ë ˆì´í„°: ìš”ì²­ í—¤ë”ì— 'Authorization: Bearer <JWT>'ê°€ ìˆì–´ì•¼ ì ‘ê·¼ í—ˆìš©
    """
    @wraps(f)
    def decorated(*args, **kwargs):
        auth_header = request.headers.get('Authorization', None)
        if not auth_header or not auth_header.startswith('Bearer '):
            return jsonify({'error': 'ê´€ë¦¬ì ì¸ì¦ í•„ìš”'}), 401

        token = auth_header.split(' ', 1)[1]
        if not verify_jwt_token(token):
            return jsonify({'error': 'ìœ íš¨í•˜ì§€ ì•Šì€ ë˜ëŠ” ë§Œë£Œëœ í† í°'}), 401

        return f(*args, **kwargs)
    return decorated

# ===================================================================
# ê°œì„ ëœ ë‹¤êµ­ì–´ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ===================================================================

def get_video_with_translation(group_id, lang_code='ko'):
    """
    íŠ¹ì • ì–¸ì–´ë¡œ ë¹„ë””ì˜¤ ì •ë³´ ì¡°íšŒ
    
    Args:
        group_id: ë¹„ë””ì˜¤ ê·¸ë£¹ ID
        lang_code: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: 'ko')
    
    Returns:
        dict: ë£¨íŠ¸ ë°ì´í„° + í•´ë‹¹ ì–¸ì–´ ë²ˆì—­ ë°ì´í„°
    """
    try:
        # 1) ë£¨íŠ¸ ë¬¸ì„œ ì¡°íšŒ
        root_doc = db.collection('uploads').document(group_id).get()
        if not root_doc.exists:
            return None
        
        root_data = root_doc.to_dict()
        
        # 2) ë²ˆì—­ ë¬¸ì„œ ì¡°íšŒ
        translation_doc = db.collection('uploads').document(group_id) \
                           .collection('translations').document(lang_code).get()
        
        if translation_doc.exists:
            translation_data = translation_doc.to_dict()
            # ë²ˆì—­ ë°ì´í„°ë¥¼ ë£¨íŠ¸ ë°ì´í„°ì— ì˜¤ë²„ë¼ì´ë“œ
            root_data.update({
                'display_title': translation_data.get('title', root_data.get('group_name')),
                'display_main_category': translation_data.get('main_category', root_data.get('main_category')),
                'display_sub_category': translation_data.get('sub_category', root_data.get('sub_category')),
                'display_sub_sub_category': translation_data.get('sub_sub_category', root_data.get('sub_sub_category')),
                'current_language': lang_code,
                'language_name': translation_data.get('language_name', SUPPORTED_LANGUAGES.get(lang_code, lang_code))
            })
        else:
            # ë²ˆì—­ì´ ì—†ìœ¼ë©´ í•œêµ­ì–´(ì›ë³¸) ì‚¬ìš©
            root_data.update({
                'display_title': root_data.get('group_name'),
                'display_main_category': root_data.get('main_category'),
                'display_sub_category': root_data.get('sub_category'),
                'display_sub_sub_category': root_data.get('sub_sub_category'),
                'current_language': 'ko',
                'language_name': 'í•œêµ­ì–´'
            })
        
        return root_data
        
    except Exception as e:
        app.logger.error(f"ë¹„ë””ì˜¤ ì¡°íšŒ ì‹¤íŒ¨ ({group_id}, {lang_code}): {e}")
        return None

def add_language_to_existing_videos(new_lang_code, new_lang_name):
    """
    ê¸°ì¡´ ë¹„ë””ì˜¤ë“¤ì— ìƒˆë¡œìš´ ì–¸ì–´ ë²ˆì—­ ì¶”ê°€
    
    Args:
        new_lang_code: ìƒˆ ì–¸ì–´ ì½”ë“œ (ì˜ˆ: 'fr')
        new_lang_name: ìƒˆ ì–¸ì–´ ì´ë¦„ (ì˜ˆ: 'FranÃ§ais')
    """
    try:
        # ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads = db.collection('uploads').stream()
        
        for doc in uploads:
            root_data = doc.to_dict()
            group_id = doc.id
            
            # í•œêµ­ì–´ ì›ë³¸ í…ìŠ¤íŠ¸ë“¤
            korean_title = root_data.get('group_name', '')
            korean_main_cat = root_data.get('main_category', '')
            korean_sub_cat = root_data.get('sub_category', '')
            korean_leaf_cat = root_data.get('sub_sub_category', '')
            
            # ìƒˆ ì–¸ì–´ë¡œ ë²ˆì—­
            translated_title = translate_text(korean_title, new_lang_code)
            translated_main = translate_text(korean_main_cat, new_lang_code)
            translated_sub = translate_text(korean_sub_cat, new_lang_code)
            translated_leaf = translate_text(korean_leaf_cat, new_lang_code)
            
            # ìƒˆ ë²ˆì—­ ë¬¸ì„œ ìƒì„±
            translation_data = {
                'title': translated_title,
                'main_category': translated_main,
                'sub_category': translated_sub,
                'sub_sub_category': translated_leaf,
                'language_code': new_lang_code,
                'language_name': new_lang_name,
                'is_original': False,
                'translated_at': datetime.utcnow().isoformat()
            }
            
            # ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ì— ì¶”ê°€
            db.collection('uploads').document(group_id) \
              .collection('translations').document(new_lang_code) \
              .set(translation_data)
            
            app.logger.info(f"ì–¸ì–´ ì¶”ê°€ ì™„ë£Œ: {group_id} -> {new_lang_code}")
            
            # API ì œí•œ ë°©ì§€
            time.sleep(0.3)
        
        app.logger.info(f"âœ… ëª¨ë“  ë¹„ë””ì˜¤ì— {new_lang_name}({new_lang_code}) ì–¸ì–´ ì¶”ê°€ ì™„ë£Œ")
        
    except Exception as e:
        app.logger.error(f"ì–¸ì–´ ì¶”ê°€ ì‹¤íŒ¨: {e}")

# ===================================================================
# ë°±ê·¸ë¼ìš´ë“œ ìë™ ê°±ì‹  ì‹œìŠ¤í…œ
# ===================================================================

def refresh_expiring_urls():
    """
    ë§Œë£Œ ì„ë°•í•œ presigned URLë“¤ì„ ì¼ê´„ ê°±ì‹ í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…
    - 2ì‹œê°„(120ë¶„) ì—¬ìœ ë¥¼ ë‘ê³  ë¯¸ë¦¬ ê°±ì‹ 
    """
    try:
        app.logger.info("ğŸ”„ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì‘ì—… ì‹œì‘...")
        
        # Firestoreì—ì„œ ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        updated_count = 0
        total_count = 0
        
        for doc in docs:
            total_count += 1
            data = doc.to_dict()
            
            current_url = data.get('presigned_url', '')
            video_key = data.get('video_key', '')
            
            if not video_key:
                app.logger.warning(f"âš ï¸  ë¬¸ì„œ {doc.id}ì— video_keyê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            # URLì´ ì—†ê±°ë‚˜ ë§Œë£Œ ì„ë°•(2ì‹œê°„ ì—¬ìœ ) ì‹œ ê°±ì‹ 
            if not current_url or is_presigned_url_expired(current_url, safety_margin_minutes=120):
                try:
                    # ìƒˆ presigned URL ìƒì„± (7ì¼ ìœ íš¨)
                    new_presigned_url = generate_presigned_url(video_key, expires_in=604800)
                    
                    # Firestore ì—…ë°ì´íŠ¸
                    update_data = {
                        'presigned_url': new_presigned_url,
                        'auto_updated_at': datetime.utcnow().isoformat(),
                        'auto_update_reason': 'background_refresh'
                    }
                    
                    # QR URLë„ ê°±ì‹ 
                    qr_key = data.get('qr_key', '')
                    if qr_key:
                        new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
                        update_data['qr_presigned_url'] = new_qr_url
                    
                    doc.reference.update(update_data)
                    
                    updated_count += 1
                    app.logger.info(f"âœ… ë¬¸ì„œ {doc.id} URL ê°±ì‹  ì™„ë£Œ")
                    
                except Exception as update_error:
                    app.logger.error(f"âŒ ë¬¸ì„œ {doc.id} URL ê°±ì‹  ì‹¤íŒ¨: {update_error}")
        
        app.logger.info(f"ğŸ‰ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì™„ë£Œ: {updated_count}/{total_count} ê°œ ê°±ì‹ ë¨")
        
    except Exception as e:
        app.logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ URL ê°±ì‹  ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

def refresh_qr_presigned_urls():
    """
    QR ì´ë¯¸ì§€ì˜ presigned URLë„ ê°±ì‹  (ë‹¨ì¼ QR ì´ë¯¸ì§€)
    """
    try:
        app.logger.info("ğŸ”„ QR ì´ë¯¸ì§€ URL ê°±ì‹  ì‘ì—… ì‹œì‘...")
        
        uploads_ref = db.collection('uploads')
        docs = uploads_ref.stream()
        
        updated_count = 0
        
        for doc in docs:
            data = doc.to_dict()
            qr_key = data.get('qr_key', '')
            
            if not qr_key:
                continue
                
            try:
                # QR ì´ë¯¸ì§€ìš© ìƒˆ presigned URL ìƒì„± (7ì¼ ìœ íš¨)
                new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
                
                doc.reference.update({
                    'qr_presigned_url': new_qr_url,
                    'qr_updated_at': datetime.utcnow().isoformat()
                })
                
                updated_count += 1
                
            except Exception as qr_error:
                app.logger.error(f"âŒ QR URL ê°±ì‹  ì‹¤íŒ¨ {doc.id}: {qr_error}")
        
        app.logger.info(f"ğŸ‰ QR URL ê°±ì‹  ì™„ë£Œ: {updated_count}ê°œ")
        
    except Exception as e:
        app.logger.error(f"âŒ QR URL ê°±ì‹  ì‘ì—… ì¤‘ ì˜¤ë¥˜: {e}")

# ===================================================================
# ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì • ë° ì‹œì‘
# ===================================================================

# ìŠ¤ì¼€ì¤„ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
scheduler = BackgroundScheduler(
    timezone='UTC',
    job_defaults={
        'coalesce': True,  # ê°™ì€ ì‘ì—…ì´ ì¤‘ë³µ ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡
        'max_instances': 1  # ìµœëŒ€ 1ê°œ ì¸ìŠ¤í„´ìŠ¤ë§Œ ì‹¤í–‰
    }
)

def start_background_scheduler():
    """
    ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    """
    try:
        # 1. ë™ì˜ìƒ URL ê°±ì‹  ì‘ì—… (3ì‹œê°„ë§ˆë‹¤)
        scheduler.add_job(
            func=refresh_expiring_urls,
            trigger=IntervalTrigger(hours=3),
            id='refresh_video_urls',
            name='ë™ì˜ìƒ URL ìë™ ê°±ì‹ ',
            replace_existing=True
        )
        
        # 2. QR ì´ë¯¸ì§€ URL ê°±ì‹  ì‘ì—… (6ì‹œê°„ë§ˆë‹¤)
        scheduler.add_job(
            func=refresh_qr_presigned_urls,
            trigger=IntervalTrigger(hours=6),
            id='refresh_qr_urls',
            name='QR ì´ë¯¸ì§€ URL ìë™ ê°±ì‹ ',
            replace_existing=True
        )
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
        scheduler.start()
        app.logger.info("ğŸš€ ë°±ê·¸ë¼ìš´ë“œ URL ìë™ ê°±ì‹  ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")
        app.logger.info("   - ë™ì˜ìƒ URL: 3ì‹œê°„ë§ˆë‹¤ ê°±ì‹ ")
        app.logger.info("   - QR ì´ë¯¸ì§€ URL: 6ì‹œê°„ë§ˆë‹¤ ê°±ì‹ ")
        
        # ì•± ì¢…ë£Œ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ë„ í•¨ê»˜ ì¢…ë£Œ
        atexit.register(lambda: scheduler.shutdown())
        
    except Exception as e:
        app.logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

# ===================================================================
# ìˆ˜ë™ ê°±ì‹  API (ê´€ë¦¬ììš©)
# ===================================================================

@app.route('/api/admin/refresh-urls', methods=['POST'])
@admin_required
def manual_refresh_urls():
    """
    ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ URL ê°±ì‹ ì„ íŠ¸ë¦¬ê±°í•  ìˆ˜ ìˆëŠ” ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰í•˜ì—¬ ì‘ë‹µ ì§€ì—° ë°©ì§€
        thread = threading.Thread(target=refresh_expiring_urls)
        thread.daemon = True
        thread.start()
        
        return jsonify({
            'message': 'URL ê°±ì‹  ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'status': 'started'
        }), 200
        
    except Exception as e:
        app.logger.error(f"ìˆ˜ë™ URL ê°±ì‹  ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ê°±ì‹  ì‘ì—… ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/admin/scheduler-status', methods=['GET'])
@admin_required
def get_scheduler_status():
    """
    ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ í™•ì¸ìš© ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        jobs = []
        for job in scheduler.get_jobs():
            jobs.append({
                'id': job.id,
                'name': job.name,
                'next_run': job.next_run_time.isoformat() if job.next_run_time else None,
                'trigger': str(job.trigger)
            })
        
        return jsonify({
            'running': scheduler.running,
            'jobs': jobs
        }), 200
        
    except Exception as e:
        app.logger.error(f"ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ìŠ¤ì¼€ì¤„ëŸ¬ ìƒíƒœë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# ê°œì„ ëœ ì—…ë¡œë“œ í•¸ë“¤ëŸ¬: ì„œë¸Œì»¬ë ‰ì…˜ ë²ˆì—­ êµ¬ì¡°
# ===================================================================
@app.route('/upload', methods=['POST'])
def upload_video():
    """
    ê°œì„ ëœ ì—…ë¡œë“œ ì²˜ë¦¬: ë£¨íŠ¸ ë¬¸ì„œì™€ ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ë¶„ë¦¬
    1) í´ë¼ì´ì–¸íŠ¸ì—ì„œ íŒŒì¼ê³¼ ê¸°íƒ€ ë©”íƒ€ë°ì´í„° ìˆ˜ì‹ 
    2) í•œêµ­ì–´ ê°•ì˜ëª…ì„ 7ê°œ ì–¸ì–´ë¡œ ìë™ ë²ˆì—­
    3) íŒŒì¼ì„ ì„ì‹œë¡œ ì €ì¥ â†’ S3 ì—…ë¡œë“œ
    4) moviepyë¡œ ë™ì˜ìƒ ê¸¸ì´(ì´ˆ ë‹¨ìœ„) ê³„ì‚° â†’ "ë¶„:ì´ˆ" ë¬¸ìì—´ë¡œ ë³€í™˜
    5) ë£¨íŠ¸ ë¬¸ì„œì— í•µì‹¬ ë©”íƒ€ë°ì´í„° ì €ì¥
    6) ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ì— ì–¸ì–´ë³„ ë²ˆì—­ ì €ì¥
    """
    # ì„¸ì…˜ ì¸ì¦(ê¸°ì¡´ ë¡œì§)
    if not session.get('logged_in'):
        return redirect(url_for('login_page'))

    file          = request.files.get('file')
    group_name    = request.form.get('group_name', 'default')  # í•œêµ­ì–´ ê°•ì˜ëª…
    main_cat      = request.form.get('main_category', '')
    sub_cat       = request.form.get('sub_category', '')
    leaf_cat      = request.form.get('sub_sub_category', '')
    lecture_level = request.form.get('level', '')
    lecture_tag   = request.form.get('tag', '')

    if not file:
        return "íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.", 400

    # ğŸŒ 1) í•œêµ­ì–´ ê°•ì˜ëª…ì„ 7ê°œ ì–¸ì–´ë¡œ ë²ˆì—­
    app.logger.info(f"ë‹¤êµ­ì–´ ë²ˆì—­ ì‹œì‘: '{group_name}'")
    translated_titles = create_multilingual_metadata(group_name)
    
    # ì¹´í…Œê³ ë¦¬ë“¤ë„ ë²ˆì—­ (ì„ íƒì‚¬í•­)
    translated_main_cat = create_multilingual_metadata(main_cat) if main_cat else {}
    translated_sub_cat = create_multilingual_metadata(sub_cat) if sub_cat else {}
    translated_leaf_cat = create_multilingual_metadata(leaf_cat) if leaf_cat else {}

    # 2) ê·¸ë£¹ ID ìƒì„± ë° S3 í‚¤ êµ¬ì„±
    group_id = uuid.uuid4().hex
    date_str = datetime.now().strftime('%Y%m%d')
    safe_name = re.sub(r'[^\w]', '_', group_name)
    folder = f"videos/{group_id}_{safe_name}_{date_str}"
    ext = Path(file.filename).suffix or '.mp4'
    video_key = f"{folder}/video{ext}"

    # 3) ì„ì‹œ ì €ì¥ ë° S3 ì—…ë¡œë“œ
    tmp_path = Path(tempfile.gettempdir()) / f"{group_id}{ext}"
    file.save(tmp_path)

    # 4) moviepyë¥¼ ì‚¬ìš©í•´ ë™ì˜ìƒ ê¸¸ì´ ê³„ì‚°
    try:
        with VideoFileClip(str(tmp_path)) as clip:
            duration_sec = int(clip.duration)
    except Exception as e:
        duration_sec = 0
        app.logger.warning(f"moviepyë¡œ ë™ì˜ìƒ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    # "ë¶„:ì´ˆ" í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    minutes = duration_sec // 60
    seconds = duration_sec % 60
    lecture_time = f"{minutes}:{seconds:02d}"
    app.logger.info(f"ê³„ì‚°ëœ ë™ì˜ìƒ ê¸¸ì´: {lecture_time} (ì´ {duration_sec}ì´ˆ)")

    # S3 ì—…ë¡œë“œ
    s3.upload_file(str(tmp_path), BUCKET_NAME, video_key, Config=config)
    tmp_path.unlink(missing_ok=True)

    # 5) Presigned URL ìƒì„±
    presigned_url = generate_presigned_url(video_key, expires_in=604800)

    # 6) ë‹¨ì¼ QR ì½”ë“œ ìƒì„± (í•œêµ­ì–´ ê¸°ë³¸)
    qr_link = f"{APP_BASE_URL}{group_id}"  # ì–¸ì–´ íŒŒë¼ë¯¸í„° ì—†ì´
    qr_filename = f"{uuid.uuid4().hex}.png"
    local_qr = os.path.join(app.config['UPLOAD_FOLDER'], qr_filename)
    
    # í•œêµ­ì–´ ê°•ì˜ëª…ìœ¼ë¡œ QR ì½”ë“œ ìƒì„±
    display_title = group_name
    if main_cat or sub_cat or leaf_cat:
        categories = [cat for cat in [main_cat, sub_cat, leaf_cat] if cat]
        if categories:
            display_title = f"{group_name}\n({' > '.join(categories)})"
    
    create_qr_with_logo(qr_link, local_qr, lecture_title=display_title)
    
    qr_key = f"{folder}/{qr_filename}"
    s3.upload_file(local_qr, BUCKET_NAME, qr_key)
    
    # QR ì´ë¯¸ì§€ URL ìƒì„±
    qr_presigned_url = generate_presigned_url(qr_key, expires_in=604800)
    
    # ë¡œì»¬ íŒŒì¼ ì‚­ì œ
    try:
        os.remove(local_qr)
    except OSError:
        pass

    # ğŸ“ 7) ë£¨íŠ¸ ë¬¸ì„œ ì €ì¥ (í•µì‹¬ ë©”íƒ€ë°ì´í„°ë§Œ)
    root_doc_data = {
        'group_id': group_id,
        'group_name': group_name,           # ê¸°ë³¸ ì–¸ì–´(í•œêµ­ì–´)
        'main_category': main_cat,
        'sub_category': sub_cat,
        'sub_sub_category': leaf_cat,
        'time': lecture_time,
        'level': lecture_level,
        'tag': lecture_tag,
        'video_key': video_key,
        'presigned_url': presigned_url,
        'qr_link': qr_link,
        'qr_key': qr_key,
        'qr_presigned_url': qr_presigned_url,
        'upload_date': date_str,
        'created_at': datetime.utcnow().isoformat(),
        'updated_at': datetime.utcnow().isoformat()
    }

    # ë£¨íŠ¸ ë¬¸ì„œ ì €ì¥
    root_doc_ref = db.collection('uploads').document(group_id)
    root_doc_ref.set(root_doc_data)

    # ğŸ“ 8) ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ì €ì¥ (ì–¸ì–´ë³„ë¡œ ë¶„ë¦¬)
    translations_ref = root_doc_ref.collection('translations')
    
    for lang_code in SUPPORTED_LANGUAGES.keys():
        if lang_code == 'ko':
            # í•œêµ­ì–´ëŠ” ì›ë³¸ ê·¸ëŒ€ë¡œ
            translation_data = {
                'title': group_name,
                'main_category': main_cat,
                'sub_category': sub_cat,
                'sub_sub_category': leaf_cat,
                'language_code': lang_code,
                'language_name': SUPPORTED_LANGUAGES[lang_code],
                'is_original': True,
                'translated_at': datetime.utcnow().isoformat()
            }
        else:
            # ë²ˆì—­ëœ ì–¸ì–´ë“¤
            translation_data = {
                'title': translated_titles.get(lang_code, group_name),
                'main_category': translated_main_cat.get(lang_code, main_cat),
                'sub_category': translated_sub_cat.get(lang_code, sub_cat),
                'sub_sub_category': translated_leaf_cat.get(lang_code, leaf_cat),
                'language_code': lang_code,
                'language_name': SUPPORTED_LANGUAGES[lang_code],
                'is_original': False,
                'translated_at': datetime.utcnow().isoformat()
            }
        
        # ê° ì–¸ì–´ë³„ ë¬¸ì„œ ì €ì¥
        translations_ref.document(lang_code).set(translation_data)
        app.logger.info(f"ë²ˆì—­ ì €ì¥ ì™„ë£Œ: {lang_code} - {translation_data.get('title')}")

    app.logger.info(f"âœ… ê°œì„ ëœ êµ¬ì¡°ë¡œ ì—…ë¡œë“œ ì™„ë£Œ: {group_id}")
    app.logger.info(f"ë²ˆì—­ëœ ì–¸ì–´: {list(translated_titles.keys())}")

    return render_template(
        'success.html',
        group_id=group_id,
        translations=translated_titles,
        time=lecture_time,
        level=lecture_level,
        tag=lecture_tag,
        presigned_url=presigned_url,
        qr_url=qr_presigned_url
    )

# ===================================================================
# ìˆ˜ë£Œì¦ ì •ë³´ ìƒì„± ì‹œ Firestoreì— readyForExcel & excelUpdated í”Œë˜ê·¸ ì¶”ê°€
# ===================================================================
@app.route('/create_certificate', methods=['POST'])
def create_certificate():
    """
    í´ë¼ì´ì–¸íŠ¸(Flutter ë“±)ì—ì„œ ìˆ˜ë£Œì¦ì„ ë°œê¸‰í•  ë•Œ í˜¸ì¶œ.
    1) user_uid, cert_id, lectureTitle, pdfUrl ë“±ì„ JSON ë°”ë””ë¡œ ì „ë‹¬
    2) Firestoreì— ìƒˆ ë¬¸ì„œë¥¼ ìƒì„±í•˜ë©´ì„œ
       excelUpdated: False, readyForExcel: True í”Œë˜ê·¸ë¥¼ í•¨ê»˜ ì„¤ì •
    """
    data = request.get_json() or {}
    user_uid      = data.get('user_uid')
    cert_id       = data.get('cert_id')
    lecture_title = data.get('lectureTitle', '')
    pdf_url       = data.get('pdfUrl', '')

    if not user_uid or not cert_id or not pdf_url:
        return jsonify({'error': 'user_uid, cert_id, lectureTitle, pdfUrlì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    # Firestore Timestampë¡œ ìë™ ì €ì¥
    cert_ref = db.collection('users').document(user_uid) \
                 .collection('completedCertificates').document(cert_id)
    cert_ref.set({
        'lectureTitle':    lecture_title,
        'issuedAt':        firestore.SERVER_TIMESTAMP,
        'pdfUrl':          pdf_url,
        'excelUpdated':    False,
        'readyForExcel':   True
    }, merge=True)

    return jsonify({'message': 'ìˆ˜ë£Œì¦ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ì›Œì»¤ê°€ ì—‘ì…€ ì—…ë°ì´íŠ¸ ëŒ€ìƒì— ì¶”ê°€ë©ë‹ˆë‹¤.'}), 200

# ===================================================================
# ìˆ˜ë£Œì¦ì´ ë“¤ì–´ì˜¬ ë•Œë§ˆë‹¤ Master ì—‘ì…€ì— ìë™ìœ¼ë¡œ ì¶”ê°€í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
# ===================================================================
@app.route('/add_certificate_to_master', methods=['POST'])
def add_certificate_to_master():
    """
    ì‚¬ìš©ìê°€ ìˆ˜ë£Œì¦ì„ ë°œê¸‰(ì €ì¥)í•œ í›„, í•„ìš”ì— ë”°ë¼ í˜¸ì¶œ.
    1) Firestoreì—ì„œ user_uid, cert_idë¡œ ìˆ˜ë£Œì¦ ì •ë³´ ì¡°íšŒ
    2) Firebase Storageì— ì €ì¥ëœ master_certificates.xlsx ë‹¤ìš´ë¡œë“œ (ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)
    3) Pandasë¡œ DataFrame ë¡œë“œ â†’ ìƒˆë¡œìš´ í–‰ ì¶”ê°€
    4) ìˆ˜ì •ëœ ì—‘ì…€ì„ Firebase Storageì— ì—…ë¡œë“œ(ë®ì–´ì“°ê¸°)
    5) Firestore ë¬¸ì„œì— excelUpdated=True, readyForExcel=Falseë¡œ ì—…ë°ì´íŠ¸
    """
    data = request.get_json() or {}
    user_uid = data.get('user_uid')
    cert_id  = data.get('cert_id')

    if not user_uid or not cert_id:
        return jsonify({'error': 'user_uidì™€ cert_idê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    # 1) Firestoreì—ì„œ í•´ë‹¹ ìˆ˜ë£Œì¦ ë¬¸ì„œ ì¡°íšŒ
    cert_ref = db.collection('users').document(user_uid) \
                 .collection('completedCertificates').document(cert_id)
    cert_doc = cert_ref.get()
    if not cert_doc.exists:
        return jsonify({'error': 'í•´ë‹¹ ìˆ˜ë£Œì¦ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.'}), 404

    cert_info = cert_doc.to_dict()
    # PDF URL í•„ìˆ˜ í™•ì¸
    pdf_url       = cert_info.get('pdfUrl', '')
    if not pdf_url:
        return jsonify({'error': 'PDF URLì´ ì—†ìŠµë‹ˆë‹¤.'}), 400

    lecture_title = cert_info.get('lectureTitle', cert_id)
    issued_at     = cert_info.get('issuedAt')  # Firestore Timestamp

    # Firestore Timestamp â†’ datetime ë³€í™˜
    if hasattr(issued_at, 'to_datetime'):
        issued_dt = issued_at.to_datetime()
    else:
        issued_dt = datetime.utcnow()

    # 2) Firebase Storageì—ì„œ master_certificates.xlsx ë‹¤ìš´ë¡œë“œ (ì—†ìœ¼ë©´ ë¹ˆ DataFrame ìƒì„±)
    master_blob_name = 'master_certificates.xlsx'
    master_blob = bucket.blob(master_blob_name)

    try:
        existing_bytes = master_blob.download_as_bytes()
        excel_buffer   = io.BytesIO(existing_bytes)
        df_master      = pd.read_excel(excel_buffer, engine='openpyxl')
    except Exception:
        # íŒŒì¼ì´ ì—†ê±°ë‚˜ ì½ê¸° ì‹¤íŒ¨ ì‹œ: ë¹ˆ DataFrame ìƒì„±
        df_master = pd.DataFrame(columns=[
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼',
            'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL'
        ])

    # 3) DataFrameì— ìƒˆë¡œìš´ í–‰ ì¶”ê°€ (append ëŒ€ì‹  concat ì‚¬ìš©)
    # ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ (ì´ë¦„/ì „í™”/ì´ë©”ì¼), í•„ìš”ì‹œ ë¹ˆ ë¬¸ìì—´ ì²˜ë¦¬
    user_ref = db.collection("users").document(user_uid)
    user_snapshot = user_ref.get()
    if user_snapshot.exists:
        user_data  = user_snapshot.to_dict()
        user_name  = user_data.get("name", "")
        user_phone = user_data.get("phone", "")
        user_email = user_data.get("email", "")
    else:
        user_name  = ""
        user_phone = ""
        user_email = ""

    updated_date = datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S")
    issued_str   = issued_dt.strftime("%Y-%m-%d %H:%M:%S")

    new_row = pd.DataFrame([{
        'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
        'ì‚¬ìš©ì UID':    user_uid,
        'ì „í™”ë²ˆí˜¸':      user_phone,
        'ì´ë©”ì¼':        user_email,
        'ì‚¬ìš©ì ì´ë¦„':   user_name,
        'ê°•ì˜ ì œëª©':     lecture_title,
        'ë°œê¸‰ ì¼ì‹œ':     issued_str,
        'PDF URL':       pdf_url
    }])
    df_master = pd.concat([df_master, new_row], ignore_index=True)

    # 4) ìˆ˜ì •ëœ DataFrameì„ BytesIO ë²„í¼ì— ì—‘ì…€ë¡œ ì“°ê¸°
    out_buffer = io.BytesIO()
    with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
        df_master.to_excel(writer, index=False, sheet_name="Certificates")
    out_buffer.seek(0)

    # Firebase Storageì— ë®ì–´ì“°ê¸°
    try:
        master_blob.upload_from_file(
            out_buffer,
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
    except Exception as e:
        app.logger.error(f"ë§ˆìŠ¤í„° ì—‘ì…€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ìˆ˜ì •ëœ ì—‘ì…€ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

    # 5) Firestore ë¬¸ì„œì— excelUpdated=True, readyForExcel=Falseë¡œ ì—…ë°ì´íŠ¸
    cert_ref.update({
        "excelUpdated": True,
        "readyForExcel": False
    })

    return jsonify({'message': 'ë§ˆìŠ¤í„° ì—‘ì…€ì— ìˆ˜ë£Œì¦ ì •ë³´ê°€ ì„±ê³µì ìœ¼ë¡œ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.'}), 200

# ===================================================================
# ê°œì„ ëœ ë¼ìš°íŒ… ì„¤ì •
# ===================================================================

@app.route('/', methods=['GET'])
def login_page():
    """ë¡œê·¸ì¸ í˜ì´ì§€ ë Œë”ë§ (ê´€ë¦¬ììš©)"""
    return render_template('login.html')

@app.route('/login', methods=['POST'])
def login():
    """
    (ê¸°ì¡´ ì„¸ì…˜ ê¸°ë°˜) ê´€ë¦¬ì í˜ì´ì§€ ë¡œê·¸ì¸.
    ê·¸ëŸ¬ë‚˜ í”ŒëŸ¬í„° ì•±ì—ì„œëŠ” ì´ ì—”ë“œí¬ì¸íŠ¸ ëŒ€ì‹  ì•„ë˜ /api/admin/login ì„ ì‚¬ìš©í•˜ì—¬ JWTë¥¼ ë°œê¸‰ë°›ìŠµë‹ˆë‹¤.
    """
    pw = request.form.get('password', '')
    email = request.form.get('email', '')

    if email == ADMIN_EMAIL and pw == ADMIN_PASSWORD:
        session['logged_in'] = True
        return redirect(url_for('upload_form'))
    return render_template('login.html', error="ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

@app.route('/api/admin/login', methods=['POST'])
def api_admin_login():
    """
    Flutter ê´€ë¦¬ì ë¡œê·¸ì¸(JWT ë°œê¸‰ìš©).
    Body: { "email": "...", "password": "..." }
    """
    data = request.get_json() or {}
    email    = data.get('email', '').strip()
    password = data.get('password', '')

    if email == ADMIN_EMAIL and password == ADMIN_PASSWORD:
        token = create_jwt_for_admin()
        return jsonify({'token': token}), 200
    else:
        return jsonify({'error': 'ê´€ë¦¬ì ì¸ì¦ ì‹¤íŒ¨'}), 401

@app.route('/upload_form', methods=['GET'])
def upload_form():
    """
    (ê¸°ì¡´) ê´€ë¦¬ìê°€ ì›¹ì—ì„œ ì—…ë¡œë“œ í˜ì´ì§€ ì ‘ê·¼ ì‹œ ì„¸ì…˜ ê¸°ë°˜ ì¸ì¦
    """
    if not session.get('logged_in'):
        return redirect(url_for('login_page'))

    main_cats = ['ê¸°ê³„', 'ê³µêµ¬', 'ì¥ë¹„']
    sub_map = {
        'ê¸°ê³„': ['ê³µì‘ê¸°ê³„', 'ì œì¡°ê¸°ê³„', 'ì‚°ì—…ê¸°ê³„'],
        'ê³µêµ¬': ['ìˆ˜ê³µêµ¬', 'ì „ë™ê³µêµ¬', 'ì ˆì‚­ê³µêµ¬'],
        'ì¥ë¹„': ['ì•ˆì „ì¥ë¹„', 'ìš´ì†¡ì¥ë¹„', 'ì‘ì—…ì¥ë¹„']
    }
    leaf_map = {
        'ê³µì‘ê¸°ê³„': ['ë¶ˆë„ì €', 'í¬ë ˆì¸', 'êµ´ì°©ê¸°'],
        'ì œì¡°ê¸°ê³„': ['ì‚¬ì¶œ ì„±í˜•ê¸°', 'í”„ë ˆìŠ¤ê¸°', 'ì—´ì„±í˜•ê¸°'],
        'ì‚°ì—…ê¸°ê³„': ['CNC ì„ ë°˜', 'ì ˆì‚­ê¸°', 'ì—°ì‚­ê¸°'],
        'ìˆ˜ê³µêµ¬':   ['ë“œë¦´', 'í•´ë¨¸', 'í”Œë¼ì´ì–´'],
        'ì „ë™ê³µêµ¬': ['ê·¸ë¼ì¸ë”', 'ì „ë™ ë“œë¦´', 'í•´ë¨¸ë“œë¦´'],
        'ì ˆì‚­ê³µêµ¬': ['ì»¤í„°', 'í”Œë¼ì¦ˆë§ˆ ë…¸ì¦', 'ë“œë¦´ ë¹„íŠ¸'],
        'ì•ˆì „ì¥ë¹„': ['í—¬ë©§', 'ë°©ì§„ ë§ˆìŠ¤í¬', 'ë‚™í•˜ ë°©ì§€ë²¨íŠ¸'],
        'ìš´ì†¡ì¥ë¹„': ['ë¦¬í”„íŠ¸ ì¥ë¹„', 'ì²´ì¸ ë¸”ë¡', 'í˜¸ì´ìŠ¤íŠ¸'],
        'ì‘ì—…ì¥ë¹„': ['ìŠ¤ìºí´ë”©', 'ì‘ì—…ëŒ€', 'ë¦¬í”„íŠ¸ í…Œì´ë¸”']
    }
    return render_template('upload_form.html', mains=main_cats, subs=sub_map, leafs=leaf_map)

@app.route('/watch/<group_id>', methods=['GET'])
def watch(group_id):
    """
    ê°œì„ ëœ ë™ì˜ìƒ ì‹œì²­ í˜ì´ì§€: ì–¸ì–´ë³„ ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ í™œìš©
    Flutter ì•±ì—ì„œ ì–¸ì–´ë¥¼ ë™ì ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
    """
    # URLì—ì„œ ì–¸ì–´ íŒŒë¼ë¯¸í„° í™•ì¸
    requested_lang = request.args.get('lang', 'ko')
    
    # ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´ë©´ í•œêµ­ì–´ë¡œ í´ë°±
    if requested_lang not in SUPPORTED_LANGUAGES:
        requested_lang = 'ko'
    
    # ë¹„ë””ì˜¤ ë°ì´í„° ì¡°íšŒ (ë²ˆì—­ í¬í•¨)
    video_data = get_video_with_translation(group_id, requested_lang)
    if not video_data:
        abort(404)

    # Presigned URL ê°±ì‹  ë¡œì§ (ê¸°ì¡´ê³¼ ë™ì¼)
    current_presigned = video_data.get('presigned_url', '')
    if not current_presigned or is_presigned_url_expired(current_presigned, 60):
        new_presigned_url = generate_presigned_url(video_data['video_key'], expires_in=604800)
        
        # ë£¨íŠ¸ ë¬¸ì„œë§Œ ì—…ë°ì´íŠ¸
        db.collection('uploads').document(group_id).update({
            'presigned_url': new_presigned_url,
            'updated_at': datetime.utcnow().isoformat()
        })
        video_data['presigned_url'] = new_presigned_url

    # QR URLë„ ê°±ì‹  í™•ì¸
    current_qr_url = video_data.get('qr_presigned_url', '')
    qr_key = video_data.get('qr_key', '')
    if qr_key and (not current_qr_url or is_presigned_url_expired(current_qr_url, 60)):
        new_qr_url = generate_presigned_url(qr_key, expires_in=604800)
        db.collection('uploads').document(group_id).update({
            'qr_presigned_url': new_qr_url,
            'qr_updated_at': datetime.utcnow().isoformat()
        })
        video_data['qr_presigned_url'] = new_qr_url
    
    # í…œí”Œë¦¿ì— ë²ˆì—­ëœ ë°ì´í„° ì „ë‹¬
    return render_template(
        'watch.html',
        video_url=video_data['presigned_url'],
        video_data=video_data,
        available_languages=SUPPORTED_LANGUAGES,
        current_language=requested_lang
    )

# ===================================================================
# ë‹¤êµ­ì–´ API ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/api/videos', methods=['GET'])
def get_videos_list():
    """
    ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ API (ë‹¤êµ­ì–´ ì§€ì›)
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    - category: ì¹´í…Œê³ ë¦¬ í•„í„°
    - level: ë ˆë²¨ í•„í„°
    """
    lang_code = request.args.get('lang', 'ko')
    category_filter = request.args.get('category')
    level_filter = request.args.get('level')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    try:
        # ë£¨íŠ¸ ì»¬ë ‰ì…˜ì—ì„œ ê¸°ë³¸ í•„í„°ë§
        query = db.collection('uploads')
        
        if category_filter:
            query = query.where('main_category', '==', category_filter)
        if level_filter:
            query = query.where('level', '==', level_filter)
        
        docs = query.stream()
        
        videos = []
        for doc in docs:
            video_data = get_video_with_translation(doc.id, lang_code)
            if video_data:
                # í•„ìš”í•œ í•„ë“œë§Œ ì„ íƒí•´ì„œ ì‘ë‹µ í¬ê¸° ìµœì†Œí™”
                videos.append({
                    'group_id': video_data['group_id'],
                    'title': video_data['display_title'],
                    'main_category': video_data['display_main_category'],
                    'sub_category': video_data['display_sub_category'],
                    'sub_sub_category': video_data['display_sub_sub_category'],
                    'time': video_data['time'],
                    'level': video_data['level'],
                    'tag': video_data.get('tag', ''),
                    'upload_date': video_data['upload_date'],
                    'language': lang_code,
                    'qr_url': video_data.get('qr_presigned_url', '')
                })
        
        return jsonify({
            'videos': videos,
            'language': lang_code,
            'language_name': SUPPORTED_LANGUAGES[lang_code],
            'total': len(videos)
        })
        
    except Exception as e:
        app.logger.error(f"ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ë¹„ë””ì˜¤ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/videos/<group_id>', methods=['GET'])
def get_video_detail(group_id):
    """
    íŠ¹ì • ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ API (ë‹¤êµ­ì–´ ì§€ì›)
    Query params:
    - lang: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko)
    """
    lang_code = request.args.get('lang', 'ko')
    
    if lang_code not in SUPPORTED_LANGUAGES:
        lang_code = 'ko'
    
    video_data = get_video_with_translation(group_id, lang_code)
    if not video_data:
        return jsonify({'error': 'ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404
    
    # URL ê°±ì‹  í™•ì¸
    current_presigned = video_data.get('presigned_url', '')
    if not current_presigned or is_presigned_url_expired(current_presigned, 60):
        new_presigned_url = generate_presigned_url(video_data['video_key'], expires_in=604800)
        db.collection('uploads').document(group_id).update({
            'presigned_url': new_presigned_url,
            'updated_at': datetime.utcnow().isoformat()
        })
        video_data['presigned_url'] = new_presigned_url
    
    return jsonify({
        'group_id': video_data['group_id'],
        'title': video_data['display_title'],
        'main_category': video_data['display_main_category'],
        'sub_category': video_data['display_sub_category'],
        'sub_sub_category': video_data['display_sub_sub_category'],
        'time': video_data['time'],
        'level': video_data['level'],
        'tag': video_data.get('tag', ''),
        'video_url': video_data['presigned_url'],
        'qr_url': video_data.get('qr_presigned_url', ''),
        'qr_link': video_data.get('qr_link', ''),
        'language': lang_code,
        'language_name': SUPPORTED_LANGUAGES[lang_code],
        'upload_date': video_data['upload_date']
    })

@app.route('/api/admin/add-language', methods=['POST'])
@admin_required
def api_add_language():
    """
    ê´€ë¦¬ììš©: ìƒˆë¡œìš´ ì–¸ì–´ ì¶”ê°€ API
    Body: { "language_code": "fr", "language_name": "FranÃ§ais" }
    """
    data = request.get_json() or {}
    lang_code = data.get('language_code', '').strip().lower()
    lang_name = data.get('language_name', '').strip()
    
    if not lang_code or not lang_name:
        return jsonify({'error': 'language_codeì™€ language_nameì´ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    if lang_code in SUPPORTED_LANGUAGES:
        return jsonify({'error': f'ì–¸ì–´ ì½”ë“œ {lang_code}ëŠ” ì´ë¯¸ ì§€ì›ë©ë‹ˆë‹¤.'}), 400
    
    try:
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
        thread = threading.Thread(
            target=add_language_to_existing_videos, 
            args=(lang_code, lang_name)
        )
        thread.daemon = True
        thread.start()
        
        # ì „ì—­ ì–¸ì–´ ëª©ë¡ì— ì¶”ê°€
        SUPPORTED_LANGUAGES[lang_code] = lang_name
        
        return jsonify({
            'message': f'{lang_name}({lang_code}) ì–¸ì–´ ì¶”ê°€ ì‘ì—…ì´ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'language_code': lang_code,
            'language_name': lang_name
        }), 200
        
    except Exception as e:
        app.logger.error(f"ì–¸ì–´ ì¶”ê°€ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì–¸ì–´ ì¶”ê°€ ì‘ì—… ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/languages', methods=['GET'])
def get_supported_languages():
    """
    ì§€ì›í•˜ëŠ” ì–¸ì–´ ëª©ë¡ ì¡°íšŒ API
    """
    return jsonify({
        'languages': SUPPORTED_LANGUAGES,
        'total': len(SUPPORTED_LANGUAGES)
    })

# ===================================================================
# ê¸°ì¡´ ZIP ìƒì„± ì—”ë“œí¬ì¸íŠ¸ë“¤
# ===================================================================

@app.route('/generate_weekly_zip', methods=['GET'])
@admin_required
def generate_weekly_zip():
    """
    ê´€ë¦¬ì(JWT) ì¸ì¦ í›„ íŠ¹ì • ì£¼ì°¨ ì „ì²´ ìˆ˜ë£Œì¦ ZIP ìƒì„±/ì¡°íšŒ
    - query param: week (ì˜ˆ: "2025-W23")
    """
    week_param = request.args.get('week')
    if not week_param:
        today = datetime.utcnow().date()
        y, w, _ = today.isocalendar()
        week_param = f"{y}-W{str(w).zfill(2)}"

    zip_key = f"full/{week_param}.zip"

    # 1) S3ì— ZIP ì¡´ì¬í•˜ë©´ presigned URL ë°˜í™˜
    try:
        s3.head_object(Bucket=BUCKET_NAME, Key=zip_key)
        presigned = generate_presigned_url(zip_key, expires_in=3600)
        return jsonify({
            'zipUrl': presigned,
            'generated': False,
            'week': week_param
        })
    except s3.exceptions.ClientError as e:
        if e.response['Error']['Code'] != '404':
            return abort(500, description=f"S3 ì˜¤ë¥˜: {e}")

    # 2) ZIP ì—†ìœ¼ë©´ Firestoreì—ì„œ ì£¼ì°¨ë³„ ìˆ˜ë£Œì¦ ì¡°íšŒ
    try:
        week_start_dt, week_end_dt = parse_iso_week(week_param)
    except ValueError as ex:
        return abort(400, description=str(ex))

    start_ts = firestore.Timestamp.from_datetime(week_start_dt)
    end_ts   = firestore.Timestamp.from_datetime(week_end_dt)

    cert_docs = db.collection_group('completedCertificates') \
                  .where('issuedAt', '>=', start_ts) \
                  .where('issuedAt', '<=', end_ts) \
                  .stream()

    tmp_zip_path = f"/tmp/{week_param}.zip"
    with zipfile.ZipFile(tmp_zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:
        found_any = False
        for cert_doc in cert_docs:
            data          = cert_doc.to_dict()
            pdf_url       = data.get('pdfUrl', '')
            lecture_title = data.get('lectureTitle') or cert_doc.id
            user_uid      = cert_doc.reference.parent.parent.id

            if not pdf_url:
                continue

            found_any = True
            safe_title = re.sub(r'[^\wê°€-í£_-]', '_', lecture_title)
            entry_name = f"{user_uid}_{safe_title}.pdf"

            try:
                resp = requests.get(pdf_url, timeout=30)
                if resp.status_code == 200:
                    zf.writestr(entry_name, resp.content)
                else:
                    app.logger.warning(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({resp.status_code}): {pdf_url}")
            except Exception as fetch_ex:
                app.logger.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {pdf_url} -> {fetch_ex}")

        if not found_any:
            zf.close()
            try:
                os.remove(tmp_zip_path)
            except OSError:
                pass
            return abort(404, description=f"{week_param}ì— ë°œê¸‰ëœ ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤.")

    try:
        s3.upload_file(
            Filename=tmp_zip_path,
            Bucket=BUCKET_NAME,
            Key=zip_key,
            Config=config
        )
    except Exception as upload_ex:
        app.logger.error(f"ZIP ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_ex}")
        return abort(500, description="ZIP ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    try:
        os.remove(tmp_zip_path)
    except OSError:
        pass

    try:
        presigned = generate_presigned_url(zip_key, expires_in=3600)
    except Exception as pre_ex:
        app.logger.error(f"Presigned URL ìƒì„± ì‹¤íŒ¨: {pre_ex}")
        return abort(500, description="Presigned URL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return jsonify({
        'zipUrl': presigned,
        'generated': True,
        'week': week_param
    })

@app.route('/api/admin/users/certs/zip', methods=['GET'])
@admin_required
def generate_selected_zip():
    """
    Flutter í˜¸ì¶œìš©: ì„ íƒí•œ UIDì˜ ìˆ˜ë£Œì¦ ZIP ìƒì„±/ì¡°íšŒ
    - query param: uids=uid1,uid2,...  (ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ UID ëª©ë¡)
                   type=recent|all      ('recent': ì´ë²ˆ ì£¼ì°¨ë§Œ, 'all': ì „ì²´)
    """
    uids_param = request.args.get('uids')
    type_param = request.args.get('type')
    if not uids_param or type_param not in ('recent', 'all'):
        return abort(400, "uidsì™€ type(recent ë˜ëŠ” all) íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    uid_list = uids_param.split(',')

    if type_param == 'recent':
        today = datetime.utcnow().date()
        y, w, _ = today.isocalendar()
        week_str = f"{y}-W{str(w).zfill(2)}"
        try:
            week_start_dt, week_end_dt = parse_iso_week(week_str)
        except ValueError as ex:
            return abort(400, description=str(ex))

        start_ts = firestore.Timestamp.from_datetime(week_start_dt)
        end_ts   = firestore.Timestamp.from_datetime(week_end_dt)

    tmp_zip_path = f"/tmp/selected_{uuid.uuid4().hex}.zip"
    with zipfile.ZipFile(tmp_zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:
        found_any = False

        for uid in uid_list:
            coll_ref = db.collection('users').document(uid).collection('completedCertificates')
            if type_param == 'recent':
                docs = coll_ref \
                    .where('issuedAt', '>=', start_ts) \
                    .where('issuedAt', '<=', end_ts) \
                    .stream()
            else:  # 'all'
                docs = coll_ref.stream()

            for cert_doc in docs:
                data          = cert_doc.to_dict()
                pdf_url       = data.get('pdfUrl', '')
                lecture_title = data.get('lectureTitle') or cert_doc.id

                if not pdf_url:
                    continue

                found_any = True
                safe_title = re.sub(r'[^\wê°€-í£_-]', '_', lecture_title)
                entry_name = f"{uid}_{safe_title}.pdf"

                try:
                    resp = requests.get(pdf_url, timeout=30)
                    if resp.status_code == 200:
                        zf.writestr(entry_name, resp.content)
                    else:
                        app.logger.warning(f"PDF ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({resp.status_code}): {pdf_url}")
                except Exception as fetch_ex:
                    app.logger.error(f"PDF ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {pdf_url} -> {fetch_ex}")

        if not found_any:
            zf.close()
            try:
                os.remove(tmp_zip_path)
            except OSError:
                pass
            return abort(404, description="ì„ íƒëœ ì‚¬ìš©ìì˜ ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤.")

    zip_key = f"selected/{uuid.uuid4().hex}.zip"
    try:
        s3.upload_file(
            Filename=tmp_zip_path,
            Bucket=BUCKET_NAME,
            Key=zip_key,
            Config=config
        )
    except Exception as upload_ex:
        app.logger.error(f"ZIP ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_ex}")
        return abort(500, description="ZIP ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    try:
        os.remove(tmp_zip_path)
    except OSError:
        pass

    try:
        presigned = generate_presigned_url(zip_key, expires_in=3600)
    except Exception as pre_ex:
        app.logger.error(f"Presigned URL ìƒì„± ì‹¤íŒ¨: {pre_ex}")
        return abort(500, description="Presigned URL ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

    return jsonify({
        'zipUrl': presigned,
        'generated': True
    })

# ===================================================================
# ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´ êµ¬ì¡° â†’ ìƒˆ êµ¬ì¡°)
# ===================================================================

@app.route('/api/admin/migrate-to-subcollections', methods=['POST'])
@admin_required
def migrate_to_subcollections():
    """
    ê´€ë¦¬ììš©: ê¸°ì¡´ translations í•„ë“œë¥¼ ì„œë¸Œì»¬ë ‰ì…˜ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
    
    ê¸°ì¡´ êµ¬ì¡°:
    uploads/{group_id} {
        translations: {
            title: { ko: "...", en: "...", ... },
            main_category: { ko: "...", en: "...", ... }
        }
    }
    
    ìƒˆ êµ¬ì¡°:
    uploads/{group_id}/translations/{lang_code} {
        title: "...",
        main_category: "...",
        language_code: "...",
        language_name: "..."
    }
    """
    try:
        # ëª¨ë“  ì—…ë¡œë“œ ë¬¸ì„œ ì¡°íšŒ
        uploads = db.collection('uploads').stream()
        migrated_count = 0
        error_count = 0
        
        for doc in uploads:
            try:
                data = doc.to_dict()
                group_id = doc.id
                
                # ê¸°ì¡´ translations í•„ë“œ í™•ì¸
                old_translations = data.get('translations', {})
                if not old_translations:
                    app.logger.info(f"ë¬¸ì„œ {group_id}: translations í•„ë“œ ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue
                
                # ë²ˆì—­ ì„œë¸Œì»¬ë ‰ì…˜ ìƒì„±
                translations_ref = doc.reference.collection('translations')
                
                # ì–¸ì–´ë³„ë¡œ ë¬¸ì„œ ìƒì„±
                for lang_code in SUPPORTED_LANGUAGES.keys():
                    translation_data = {
                        'title': old_translations.get('title', {}).get(lang_code, data.get('group_name', '')),
                        'main_category': old_translations.get('main_category', {}).get(lang_code, data.get('main_category', '')),
                        'sub_category': old_translations.get('sub_category', {}).get(lang_code, data.get('sub_category', '')),
                        'sub_sub_category': old_translations.get('sub_sub_category', {}).get(lang_code, data.get('sub_sub_category', '')),
                        'language_code': lang_code,
                        'language_name': SUPPORTED_LANGUAGES[lang_code],
                        'is_original': (lang_code == 'ko'),
                        'migrated_at': datetime.utcnow().isoformat(),
                        'migration_source': 'legacy_translations_field'
                    }
                    
                    translations_ref.document(lang_code).set(translation_data)
                
                # ê¸°ì¡´ translations í•„ë“œ ì œê±°
                doc.reference.update({
                    'translations': firestore.DELETE_FIELD,
                    'migrated_to_subcollections': True,
                    'migration_completed_at': datetime.utcnow().isoformat()
                })
                
                migrated_count += 1
                app.logger.info(f"âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ: {group_id}")
                
            except Exception as doc_error:
                error_count += 1
                app.logger.error(f"âŒ ë¬¸ì„œ {group_id} ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {doc_error}")
        
        return jsonify({
            'message': 'ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'migrated_count': migrated_count,
            'error_count': error_count,
            'total_processed': migrated_count + error_count
        }), 200
        
    except Exception as e:
        app.logger.error(f"ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

@app.route('/api/admin/cleanup-old-translations', methods=['POST'])
@admin_required
def cleanup_old_translations():
    """
    ê´€ë¦¬ììš©: ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì •ë¦¬ ì‘ì—…
    - migrated_to_subcollections í”Œë˜ê·¸ê°€ ìˆëŠ” ë¬¸ì„œë“¤ì˜ ë‚¨ì€ translations í•„ë“œ ì œê±°
    """
    try:
        uploads = db.collection('uploads') \
                   .where('migrated_to_subcollections', '==', True) \
                   .stream()
        
        cleaned_count = 0
        
        for doc in uploads:
            data = doc.to_dict()
            if 'translations' in data:
                doc.reference.update({
                    'translations': firestore.DELETE_FIELD,
                    'cleaned_up_at': datetime.utcnow().isoformat()
                })
                cleaned_count += 1
                app.logger.info(f"âœ… ì •ë¦¬ ì™„ë£Œ: {doc.id}")
        
        return jsonify({
            'message': 'ì •ë¦¬ ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.',
            'cleaned_count': cleaned_count
        }), 200
        
    except Exception as e:
        app.logger.error(f"ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'ì •ë¦¬ ì‘ì—… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# í†µê³„ ë° ëª¨ë‹ˆí„°ë§ API
# ===================================================================

@app.route('/api/admin/stats', methods=['GET'])
@admin_required
def get_admin_stats():
    """
    ê´€ë¦¬ììš© í†µê³„ ëŒ€ì‹œë³´ë“œ API
    """
    try:
        # ì „ì²´ ë¹„ë””ì˜¤ ìˆ˜
        total_videos = len(list(db.collection('uploads').stream()))
        
        # ì–¸ì–´ë³„ ë²ˆì—­ ì™„ì„±ë„
        language_stats = {}
        for lang_code, lang_name in SUPPORTED_LANGUAGES.items():
            translation_count = 0
            uploads = db.collection('uploads').stream()
            
            for doc in uploads:
                translation_doc = doc.reference.collection('translations').document(lang_code).get()
                if translation_doc.exists:
                    translation_count += 1
            
            language_stats[lang_code] = {
                'name': lang_name,
                'translated_count': translation_count,
                'completion_rate': (translation_count / total_videos * 100) if total_videos > 0 else 0
            }
        
        # ìµœê·¼ ì—…ë¡œë“œ (7ì¼)
        week_ago = datetime.utcnow() - timedelta(days=7)
        recent_uploads = 0
        uploads = db.collection('uploads').where('created_at', '>=', week_ago.isoformat()).stream()
        recent_uploads = len(list(uploads))
        
        return jsonify({
            'total_videos': total_videos,
            'supported_languages': len(SUPPORTED_LANGUAGES),
            'language_stats': language_stats,
            'recent_uploads_7days': recent_uploads,
            'scheduler_running': scheduler.running if 'scheduler' in globals() else False
        }), 200
        
    except Exception as e:
        app.logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return jsonify({'error': 'í†µê³„ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

# ===================================================================
# í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
# ===================================================================

@app.route('/health', methods=['GET'])
def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
    """
    try:
        # Firestore ì—°ê²° í™•ì¸
        db.collection('uploads').limit(1).get()
        firestore_status = 'healthy'
    except Exception:
        firestore_status = 'unhealthy'
    
    try:
        # S3 ì—°ê²° í™•ì¸
        s3.head_bucket(Bucket=BUCKET_NAME)
        s3_status = 'healthy'
    except Exception:
        s3_status = 'unhealthy'
    
    overall_status = 'healthy' if (firestore_status == 'healthy' and s3_status == 'healthy') else 'unhealthy'
    
    return jsonify({
        'status': overall_status,
        'timestamp': datetime.utcnow().isoformat(),
        'services': {
            'firestore': firestore_status,
            's3': s3_status,
            'scheduler': scheduler.running if 'scheduler' in globals() else False
        },
        'supported_languages': list(SUPPORTED_LANGUAGES.keys()),
        'version': '2.0.0-improved'
    }), 200 if overall_status == 'healthy' else 503

# Railway í™˜ê²½ì„ ìœ„í•œ ì´ˆê¸°í™” í•¨ìˆ˜
def initialize_railway_environment():
    """Railway ë°°í¬ í™˜ê²½ ì´ˆê¸°í™”"""
    try:
        # í°íŠ¸ í™˜ê²½ ì´ˆê¸°í™”
        initialize_korean_fonts()
        
        # ì •ì  íŒŒì¼ ë””ë ‰í† ë¦¬ í™•ì¸
        os.makedirs('static', exist_ok=True)
        os.makedirs('fonts', exist_ok=True)
        
        # í™˜ê²½ë³„ ë¡œê·¸ ë ˆë²¨ ì„¤ì •
        if os.environ.get('RAILWAY_ENVIRONMENT'):
            import logging
            app.logger.setLevel(logging.INFO)
        
        app.logger.info("ğŸš‚ Railway í™˜ê²½ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
        
    except Exception as e:
        app.logger.error(f"âŒ Railway í™˜ê²½ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return False

# ===================================================================
# ì•± ì‹œì‘ ì‹œ ìŠ¤ì¼€ì¤„ëŸ¬ ìë™ ì‹¤í–‰
# ===================================================================

if __name__ == "__main__":
    # Railway í™˜ê²½ ì´ˆê¸°í™”
    initialize_railway_environment()
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘
    start_background_scheduler()
    
    port = int(os.environ.get("PORT", 8080))
    
    # Railway í™˜ê²½ì—ì„œëŠ” gunicorn ì‚¬ìš© ê¶Œì¥
    if os.environ.get('RAILWAY_ENVIRONMENT'):
        # Railwayì—ì„œëŠ” gunicornì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬
        app.run(host="0.0.0.0", port=port, debug=False)
    else:
        # ë¡œì»¬ ê°œë°œ í™˜ê²½
        app.run(host="0.0.0.0", port=port, debug=True)

# ===================================================================
# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ===================================================================

def batch_update_translations(updates_list):
    """
    ë²ˆì—­ ì¼ê´„ ì—…ë°ì´íŠ¸ ìœ í‹¸ë¦¬í‹°
    
    Args:
        updates_list: [
            {
                'group_id': 'abc123',
                'lang_code': 'en', 
                'updates': {'title': 'New Title', 'main_category': 'New Category'}
            },
            ...
        ]
    """
    try:
        batch = db.batch()
        
        for update_item in updates_list:
            group_id = update_item['group_id']
            lang_code = update_item['lang_code']
            updates = update_item['updates']
            
            translation_ref = db.collection('uploads').document(group_id) \
                               .collection('translations').document(lang_code)
            
            updates['updated_at'] = datetime.utcnow().isoformat()
            batch.update(translation_ref, updates)
        
        batch.commit()
        app.logger.info(f"âœ… ì¼ê´„ ë²ˆì—­ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(updates_list)}ê°œ")
        return True
        
    except Exception as e:
        app.logger.error(f"ì¼ê´„ ë²ˆì—­ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def verify_translation_integrity():
    """
    ë²ˆì—­ ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦
    - ëª¨ë“  ë¹„ë””ì˜¤ì— í•„ìš”í•œ ì–¸ì–´ ë²ˆì—­ì´ ìˆëŠ”ì§€ í™•ì¸
    - ëˆ„ë½ëœ ë²ˆì—­ ìë™ ìƒì„±
    """
    try:
        uploads = db.collection('uploads').stream()
        missing_translations = []
        
        for doc in uploads:
            root_data = doc.to_dict()
            group_id = doc.id
            
            # ê° ì–¸ì–´ë³„ ë²ˆì—­ ë¬¸ì„œ í™•ì¸
            for lang_code in SUPPORTED_LANGUAGES.keys():
                translation_doc = doc.reference.collection('translations').document(lang_code).get()
                
                if not translation_doc.exists:
                    missing_translations.append({
                        'group_id': group_id,
                        'lang_code': lang_code,
                        'korean_title': root_data.get('group_name', ''),
                        'korean_main_cat': root_data.get('main_category', ''),
                        'korean_sub_cat': root_data.get('sub_category', ''),
                        'korean_leaf_cat': root_data.get('sub_sub_category', '')
                    })
        
        app.logger.info(f"ë²ˆì—­ ë¬´ê²°ì„± ê²€ì¦ ì™„ë£Œ: {len(missing_translations)}ê°œ ëˆ„ë½ ë°œê²¬")
        return missing_translations
        
    except Exception as e:
        app.logger.error(f"ë²ˆì—­ ë¬´ê²°ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
        return None

# ===================================================================
# ê°œë°œ/í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (ìš´ì˜ì—ì„œëŠ” ì œê±° ê¶Œì¥)
# ===================================================================

@app.route('/api/dev/test-translation', methods=['POST'])
def test_translation():
    """
    ê°œë°œìš©: ë²ˆì—­ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸
    Body: { "text": "í…ŒìŠ¤íŠ¸í•  í…ìŠ¤íŠ¸", "target_lang": "en" }
    """
    if not app.debug:  # ë””ë²„ê·¸ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
        return jsonify({'error': 'ê°œë°œ ëª¨ë“œì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.'}), 403
    
    data = request.get_json() or {}
    text = data.get('text', '')
    target_lang = data.get('target_lang', 'en')
    
    if not text:
        return jsonify({'error': 'textê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400
    
    try:
        translated = translate_text(text, target_lang)
        return jsonify({
            'original': text,
            'translated': translated,
            'target_language': target_lang,
            'target_language_name': SUPPORTED_LANGUAGES.get(target_lang, target_lang)
        })
    except Exception as e:
        return jsonify({'error': f'ë²ˆì—­ ì‹¤íŒ¨: {e}'}), 500