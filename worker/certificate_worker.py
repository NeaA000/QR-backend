# worker/certificate_worker.py - ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì „ìš© ì›Œì»¤ (ë³´ì•ˆ ë° ì„±ëŠ¥ ìµœì í™”)

import os
import io
import time
import logging
import signal
import sys
from datetime import datetime, timedelta, timezone
import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage
from concurrent.futures import ThreadPoolExecutor
import threading
from pathlib import Path

# ===================================================================
# ë¡œê¹… ì„¤ì • (ë³´ì•ˆ ê°•í™”)
# ===================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('CertificateWorker')

# ë¯¼ê°í•œ ì •ë³´ ë¡œê¹… ë°©ì§€
class SecurityFilter(logging.Filter):
    """ë¯¼ê°í•œ ì •ë³´ë¥¼ í•„í„°ë§í•˜ëŠ” ë¡œê·¸ í•„í„°"""
    def filter(self, record):
        # ë¯¼ê°í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¡œê·¸ ë©”ì‹œì§€ í•„í„°ë§
        sensitive_keywords = ['password', 'secret', 'key', 'token', 'credential']
        message = record.getMessage().lower()
        return not any(keyword in message for keyword in sensitive_keywords)

logger.addFilter(SecurityFilter())

# ===================================================================
# í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì • (ê²€ì¦ ê°•í™”)
# ===================================================================
POLL_INTERVAL_SECONDS = int(os.getenv('POLL_INTERVAL_SECONDS', '60'))
BATCH_SIZE = int(os.getenv('BATCH_SIZE', '30'))  # ë°°ì¹˜ í¬ê¸° ê°ì†Œë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í–¥ìƒ
MASTER_FILENAME = "master_certificates.xlsx"
MAX_RETRY_COUNT = 3
HEALTH_CHECK_INTERVAL = 300  # 5ë¶„

# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
required_env_vars = [
    'type', 'project_id', 'private_key', 'client_email'
]

for var in required_env_vars:
    if not os.environ.get(var):
        logger.error(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ {var}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

# ===================================================================
# Firebase ì´ˆê¸°í™” (ë³´ì•ˆ ê°•í™”)
# ===================================================================
def initialize_firebase():
    """Firebase Admin SDK ì•ˆì „ ì´ˆê¸°í™”"""
    try:
        if firebase_admin._apps:
            return db, bucket
            
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìê²©ì¦ëª… ìƒì„±
        firebase_creds = {
            "type": os.environ.get("type", "service_account"),
            "project_id": os.environ["project_id"],
            "private_key_id": os.environ.get("private_key_id", ""),
            "private_key": os.environ["private_key"].replace('\\n', '\n'),
            "client_email": os.environ["client_email"],
            "client_id": os.environ.get("client_id", ""),
            "auth_uri": os.environ.get("auth_uri", "https://accounts.google.com/o/oauth2/auth"),
            "token_uri": os.environ.get("token_uri", "https://oauth2.googleapis.com/token"),
            "auth_provider_x509_cert_url": os.environ.get("auth_provider_x509_cert_url", "https://www.googleapis.com/oauth2/v1/certs"),
            "client_x509_cert_url": os.environ.get("client_x509_cert_url", "")
        }
        
        cred = credentials.Certificate(firebase_creds)
        firebase_admin.initialize_app(cred, {
            'storageBucket': f"{os.environ['project_id']}.firebasestorage.app"
        })
        
        db = firestore.client()
        bucket = storage.bucket()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        test_doc = db.collection('_health_check').document('test')
        test_doc.set({'timestamp': firestore.SERVER_TIMESTAMP})
        test_doc.delete()
        
        logger.info(f"âœ… Firebase ì´ˆê¸°í™” ë° ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        return db, bucket
        
    except Exception as e:
        logger.error(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

# Firebase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
db, bucket = initialize_firebase()

# ===================================================================
# ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬ (ì•ˆì „í•œ ì¢…ë£Œ)
# ===================================================================
shutdown_flag = False
current_operations = set()
operations_lock = threading.Lock()

def signal_handler(signum, frame):
    """SIGINT/SIGTERM ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
    global shutdown_flag
    logger.info(f"ğŸ›‘ ì¢…ë£Œ ì‹œê·¸ë„ ë°›ìŒ ({signum}). í˜„ì¬ ì‘ì—… ì™„ë£Œ í›„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    shutdown_flag = True
    
    # í˜„ì¬ ì§„í–‰ ì¤‘ì¸ ì‘ì—… ëŒ€ê¸°
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ“‹ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸° ì¤‘...")

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ===================================================================
# í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§
# ===================================================================
def update_health_status():
    """í—¬ìŠ¤ì²´í¬ íŒŒì¼ ì—…ë°ì´íŠ¸"""
    try:
        health_file = Path('/tmp/worker_healthy')
        health_data = {
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'active_operations': len(current_operations),
            'last_batch_time': getattr(update_health_status, 'last_batch_time', None)
        }
        
        with open(health_file, 'w') as f:
            f.write(f"healthy at {health_data['timestamp']}")
            
    except Exception as e:
        logger.warning(f"í—¬ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def log_operation_start(operation_id):
    """ì‘ì—… ì‹œì‘ ë¡œê¹…"""
    with operations_lock:
        current_operations.add(operation_id)

def log_operation_end(operation_id):
    """ì‘ì—… ì¢…ë£Œ ë¡œê¹…"""
    with operations_lock:
        current_operations.discard(operation_id)

# ===================================================================
# ìˆ˜ë£Œì¦ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ì„±ëŠ¥ ìµœì í™”)
# ===================================================================
def get_pending_certificates(limit=50):
    """
    ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ìˆ˜ë£Œì¦ ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
    """
    operation_id = f"get_pending_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        # ì¸ë±ìŠ¤ ìµœì í™”ëœ ì¿¼ë¦¬ - pdfUrl ì¡´ì¬ ì—¬ë¶€ë„ í™•ì¸
        query = db.collection_group('completedCertificates') \
                  .where('excelUpdated', '==', False) \
                  .limit(limit)
        
        results = []
        processed_count = 0
        
        for doc in query.stream():
            if shutdown_flag:
                break
                
            try:
                data = doc.to_dict()
                
                # PDF URL í•„ìˆ˜ í™•ì¸
                pdf_url = data.get('pdfUrl', '')
                if not pdf_url or pdf_url.strip() == '':
                    continue
                
                # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸ (ë¬´í•œ ì¬ì‹œë„ ë°©ì§€)
                retry_count = data.get('retryCount', 0)
                if retry_count >= MAX_RETRY_COUNT:
                    logger.debug(f"âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {doc.id}")
                    continue
                
                # ë¬¸ì„œ ê²½ë¡œì—ì„œ user_uid ì¶”ì¶œ
                path_parts = doc.reference.path.split('/')
                if len(path_parts) >= 4:
                    user_uid = path_parts[1]
                    cert_id = doc.id
                    results.append((user_uid, cert_id, data))
                    processed_count += 1
                    
                    # ë¡œê·¸ ìµœì†Œí™” (ì„±ëŠ¥ í–¥ìƒ)
                    if processed_count <= 3:
                        lecture_title = data.get('lectureTitle', 'ì œëª©ì—†ìŒ')
                        logger.debug(f"ğŸ“‹ ë°œê²¬: {user_uid[:8]}.../{cert_id[:8]}... - {lecture_title[:20]}...")
                else:
                    logger.warning(f"âš ï¸ ì˜ëª»ëœ ë¬¸ì„œ ê²½ë¡œ: {doc.reference.path}")
                    
            except Exception as e:
                logger.error(f"âŒ ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜ {doc.id}: {e}")
                
        if results:
            logger.info(f"ğŸ“‹ {len(results)}ê°œì˜ ì²˜ë¦¬ ëŒ€ê¸° ìˆ˜ë£Œì¦ ë°œê²¬")
            if len(results) > 3:
                logger.info(f"  ... ê·¸ ì™¸ {len(results) - 3}ê°œ ë”")
        else:
            logger.debug("ğŸ˜´ ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        log_operation_end(operation_id)

def get_user_info_safe(user_uid):
    """ì‚¬ìš©ì ì •ë³´ ì•ˆì „ ì¡°íšŒ (ìºì‹± í¬í•¨)"""
    try:
        # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ (ì›Œì»¤ ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)
        if not hasattr(get_user_info_safe, 'cache'):
            get_user_info_safe.cache = {}
        
        if user_uid in get_user_info_safe.cache:
            return get_user_info_safe.cache[user_uid]
        
        user_doc = db.collection('users').document(user_uid).get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            user_info = {
                'name': user_data.get('name', ''),
                'phone': user_data.get('phone', ''),
                'email': user_data.get('email', '')
            }
            
            # ìºì‹œ ì €ì¥ (ìµœëŒ€ 1000ê°œ, LRU ë°©ì‹)
            if len(get_user_info_safe.cache) < 1000:
                get_user_info_safe.cache[user_uid] = user_info
            
            logger.debug(f"ğŸ‘¤ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ: {user_uid[:8]}... - {user_info['name']}")
            return user_info
        else:
            empty_info = {'name': '', 'phone': '', 'email': ''}
            get_user_info_safe.cache[user_uid] = empty_info  # ë¹ˆ ì •ë³´ë„ ìºì‹œ
            logger.warning(f"âš ï¸ ì‚¬ìš©ì ë¬¸ì„œ ì—†ìŒ: {user_uid[:8]}...")
            return empty_info
            
    except Exception as e:
        logger.error(f"âŒ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({user_uid[:8]}...): {e}")
        return {'name': '', 'phone': '', 'email': ''}

def get_or_create_master_excel():
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„± (ë°±ì—… ì‹œìŠ¤í…œ í¬í•¨)"""
    operation_id = f"excel_load_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        # 1) Firebase Storage ì‹œë„
        try:
            master_blob = bucket.blob(MASTER_FILENAME)
            existing_bytes = master_blob.download_as_bytes()
            excel_buffer = io.BytesIO(existing_bytes)
            df = pd.read_excel(excel_buffer, engine='openpyxl')
            
            # ë°ì´í„° ê²€ì¦
            expected_columns = ['ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼', 'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL']
            if all(col in df.columns for col in expected_columns):
                logger.info(f"ğŸ“¥ Firebase Storageì—ì„œ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
                return df
            else:
                logger.warning("âš ï¸ ì—‘ì…€ íŒŒì¼ì˜ ì»¬ëŸ¼ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦„, ìƒˆë¡œ ìƒì„±")
                
        except Exception as firebase_error:
            logger.warning(f"âš ï¸ Firebase Storage ë¡œë“œ ì‹¤íŒ¨: {firebase_error}")
        
        # 2) ë¡œì»¬ ë°±ì—… íŒŒì¼ í™•ì¸
        local_backup_path = Path(f'/tmp/{MASTER_FILENAME}')
        if local_backup_path.exists():
            try:
                df = pd.read_excel(local_backup_path, engine='openpyxl')
                logger.info(f"ğŸ“¥ ë¡œì»¬ ë°±ì—…ì—ì„œ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
                return df
            except Exception as local_error:
                logger.warning(f"âš ï¸ ë¡œì»¬ ë°±ì—… ë¡œë“œ ì‹¤íŒ¨: {local_error}")
        
        # 3) ìƒˆ DataFrame ìƒì„±
        logger.info("ğŸ“„ ìƒˆ ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ìƒì„±")
        df = pd.DataFrame(columns=[
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ',
            'ì‚¬ìš©ì UID',
            'ì „í™”ë²ˆí˜¸',
            'ì´ë©”ì¼',
            'ì‚¬ìš©ì ì´ë¦„',
            'ê°•ì˜ ì œëª©',
            'ë°œê¸‰ ì¼ì‹œ',
            'PDF URL'
        ])
        return df
        
    except Exception as e:
        logger.error(f"âŒ ë§ˆìŠ¤í„° ì—‘ì…€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise
    finally:
        log_operation_end(operation_id)

def save_master_excel_safe(df):
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ì•ˆì „ ì €ì¥ (ë°±ì—… ë° ì¬ì‹œë„ í¬í•¨)"""
    operation_id = f"excel_save_{int(time.time())}"
    log_operation_start(operation_id)
    
    max_retries = 3
    retry_delay = 5
    
    try:
        # DataFrameì„ ì—‘ì…€ë¡œ ë³€í™˜
        out_buffer = io.BytesIO()
        with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Certificates')
        out_buffer.seek(0)
        
        # ë¡œì»¬ ë°±ì—… ë¨¼ì € ì €ì¥
        local_backup_path = Path(f'/tmp/{MASTER_FILENAME}')
        try:
            with open(local_backup_path, 'wb') as f:
                f.write(out_buffer.getvalue())
            logger.debug(f"ğŸ’¾ ë¡œì»¬ ë°±ì—… ì €ì¥ ì™„ë£Œ: {local_backup_path}")
        except Exception as backup_error:
            logger.warning(f"âš ï¸ ë¡œì»¬ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {backup_error}")
        
        # Firebase Storage ì—…ë¡œë“œ (ì¬ì‹œë„ ë¡œì§)
        for attempt in range(max_retries):
            try:
                out_buffer.seek(0)  # ë²„í¼ ìœ„ì¹˜ ì´ˆê¸°í™”
                master_blob = bucket.blob(MASTER_FILENAME)
                master_blob.upload_from_file(
                    out_buffer,
                    content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
                
                logger.info(f"âœ… Firebase Storageì— ë§ˆìŠ¤í„° ì—‘ì…€ ì €ì¥ ì™„ë£Œ (ì´ {len(df)}í–‰, ì‹œë„: {attempt + 1}/{max_retries})")
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ Excel ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                
                if attempt < max_retries - 1:
                    logger.info(f"ğŸ”„ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. Firebase Storage ì €ì¥ ì‹¤íŒ¨")
                    logger.info("ğŸ’¾ ë¡œì»¬ ë°±ì—…ì€ ë³´ì¡´ë¨. ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                    return False
        
        return False
        
    except Exception as e:
        logger.error(f"âŒ Excel ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        return False
    finally:
        log_operation_end(operation_id)

def process_certificate_safe(user_uid, cert_id, cert_data, df):
    """
    ë‹¨ì¼ ìˆ˜ë£Œì¦ ì•ˆì „ ì²˜ë¦¬
    """
    operation_id = f"cert_process_{cert_id[:8]}"
    log_operation_start(operation_id)
    
    try:
        # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        user_info = get_user_info_safe(user_uid)
        
        # ìˆ˜ë£Œì¦ ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦
        lecture_title = cert_data.get('lectureTitle', cert_id)
        pdf_url = cert_data.get('pdfUrl', '')
        
        # PDF URL ì¬ê²€ì¦
        if not pdf_url or pdf_url.strip() == '':
            raise ValueError("PDF URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ë°œê¸‰ ì‹œê°„ ì²˜ë¦¬
        issued_at = cert_data.get('issuedAt')
        if hasattr(issued_at, 'to_datetime'):
            issued_str = issued_at.to_datetime().strftime('%Y-%m-%d %H:%M:%S')
        else:
            issued_str = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
            logger.debug(f"âš ï¸ issuedAt í•„ë“œ ì—†ìŒ, í˜„ì¬ ì‹œê°„ ì‚¬ìš©: {cert_id[:8]}...")
        
        # ì¤‘ë³µ í™•ì¸ (optional)
        existing_mask = (df['ì‚¬ìš©ì UID'] == user_uid) & (df['ê°•ì˜ ì œëª©'] == lecture_title)
        if existing_mask.any():
            logger.warning(f"âš ï¸ ì¤‘ë³µ ìˆ˜ë£Œì¦ ë°œê²¬, ì—…ë°ì´íŠ¸: {user_uid[:8]}.../{lecture_title[:20]}...")
            # ê¸°ì¡´ í–‰ ì—…ë°ì´íŠ¸ ëŒ€ì‹  ìƒˆ í–‰ ì¶”ê°€ (ì´ë ¥ ë³´ì¡´)
        
        # ìƒˆ í–‰ ìƒì„±
        updated_date = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
        new_row = pd.DataFrame([{
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
            'ì‚¬ìš©ì UID': user_uid,
            'ì „í™”ë²ˆí˜¸': user_info['phone'],
            'ì´ë©”ì¼': user_info['email'],
            'ì‚¬ìš©ì ì´ë¦„': user_info['name'],
            'ê°•ì˜ ì œëª©': lecture_title,
            'ë°œê¸‰ ì¼ì‹œ': issued_str,
            'PDF URL': pdf_url
        }])
        
        # DataFrameì— ì¶”ê°€
        df = pd.concat([df, new_row], ignore_index=True)
        
        logger.info(f"âœ… ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì™„ë£Œ: {user_uid[:8]}.../{cert_id[:8]}... - {lecture_title[:30]}...")
        return True, df
        
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì‹¤íŒ¨ ({user_uid[:8]}.../{cert_id[:8]}...): {e}")
        
        # ì—ëŸ¬ ê¸°ë¡ (í”Œë˜ê·¸ ë³€ê²½ ì—†ì´)
        try:
            cert_ref = db.collection('users').document(user_uid) \
                         .collection('completedCertificates').document(cert_id)
            cert_ref.update({
                'processingError': str(e)[:500],  # ì—ëŸ¬ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ
                'errorOccurredAt': firestore.SERVER_TIMESTAMP,
                'retryCount': firestore.Increment(1)
            })
        except Exception as update_error:
            logger.error(f"âŒ ì—ëŸ¬ ê¸°ë¡ ì‹¤íŒ¨: {update_error}")
            
        return False, df
    finally:
        log_operation_end(operation_id)

def update_certificate_flags_batch(processed_certs, success=True):
    """
    ì²˜ë¦¬ëœ ìˆ˜ë£Œì¦ë“¤ì˜ í”Œë˜ê·¸ë¥¼ ë°°ì¹˜ë¡œ ì—…ë°ì´íŠ¸ (ì„±ëŠ¥ ìµœì í™”)
    """
    operation_id = f"flag_update_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        # ThreadPoolExecutorë¡œ ë³‘ë ¬ ì²˜ë¦¬
        def update_single_flag(cert_info):
            user_uid, cert_id, cert_data = cert_info
            try:
                cert_ref = db.collection('users').document(user_uid) \
                             .collection('completedCertificates').document(cert_id)
                
                if success:
                    update_data = {
                        'excelUpdated': True,
                        'processedAt': firestore.SERVER_TIMESTAMP,
                        'processedBy': 'certificate_worker_v2'
                    }
                    
                    if 'readyForExcel' in cert_data:
                        update_data['readyForExcel'] = False
                    
                    # ì—ëŸ¬ í•„ë“œ ì •ë¦¬
                    if 'processingError' in cert_data:
                        update_data['processingError'] = firestore.DELETE_FIELD
                    
                    cert_ref.update(update_data)
                    return f"âœ… {user_uid[:8]}.../{cert_id[:8]}..."
                    
                else:
                    cert_ref.update({
                        'excelSaveError': 'Excel ì €ì¥ ì‹¤íŒ¨ - ì¬ì‹œë„ ì˜ˆì •',
                        'excelSaveErrorAt': firestore.SERVER_TIMESTAMP,
                        'retryCount': firestore.Increment(1)
                    })
                    return f"âš ï¸ {user_uid[:8]}.../{cert_id[:8]}..."
                    
            except Exception as e:
                logger.error(f"âŒ ê°œë³„ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({user_uid[:8]}...): {e}")
                return f"âŒ {user_uid[:8]}.../{cert_id[:8]}..."
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 5ê°œ ìŠ¤ë ˆë“œ)
        with ThreadPoolExecutor(max_workers=5) as executor:
            results = list(executor.map(update_single_flag, processed_certs))
        
        success_count = sum(1 for r in results if r.startswith('âœ…'))
        total_count = len(results)
        
        if success:
            logger.info(f"âœ… í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {success_count}/{total_count}")
        else:
            logger.warning(f"âš ï¸ ì¬ì‹œë„ ëŒ€ìƒ ì„¤ì • ì™„ë£Œ: {success_count}/{total_count}")
            
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        log_operation_end(operation_id)

def process_batch():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰ (ì„±ëŠ¥ ë° ì•ˆì •ì„± ìµœì í™”)"""
    operation_id = f"batch_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        batch_start_time = datetime.now(timezone.utc)
        
        # ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ ì¡°íšŒ
        pending_certs = get_pending_certificates(limit=BATCH_SIZE)
        
        if not pending_certs:
            logger.debug("ğŸ˜´ ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"ğŸš€ {len(pending_certs)}ê°œ ìˆ˜ë£Œì¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ
        df = get_or_create_master_excel()
        original_row_count = len(df)
        
        # ì²˜ë¦¬ í†µê³„
        success_count = 0
        error_count = 0
        processed_certs = []
        
        # ê° ìˆ˜ë£Œì¦ ì²˜ë¦¬
        for i, (user_uid, cert_id, cert_data) in enumerate(pending_certs, 1):
            if shutdown_flag:
                logger.info("ğŸ›‘ ì¢…ë£Œ í”Œë˜ê·¸ ê°ì§€, ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨")
                break
            
            # ì§„í–‰ë¥  ë¡œê¹… (10% ë‹¨ìœ„)
            if i % max(1, len(pending_certs) // 10) == 0:
                progress = (i / len(pending_certs)) * 100
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ì§„í–‰ë¥ : {progress:.0f}% ({i}/{len(pending_certs)})")
            
            success, df = process_certificate_safe(user_uid, cert_id, cert_data, df)
            
            if success:
                success_count += 1
                processed_certs.append((user_uid, cert_id, cert_data))
            else:
                error_count += 1
        
        # Excel ì €ì¥ ë° í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
        if success_count > 0:
            new_row_count = len(df)
            logger.info(f"ğŸ“Š Excel ì €ì¥ ì‹œë„: {original_row_count}í–‰ â†’ {new_row_count}í–‰ (+{new_row_count - original_row_count})")
            
            excel_save_success = save_master_excel_safe(df)
            update_certificate_flags_batch(processed_certs, success=excel_save_success)
            
            if excel_save_success:
                processing_time = (datetime.now(timezone.utc) - batch_start_time).total_seconds()
                logger.info(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - âœ…ì„±ê³µ: {success_count}, âŒì‹¤íŒ¨: {error_count}, â±ï¸ì‹œê°„: {processing_time:.1f}ì´ˆ")
            else:
                logger.error(f"âŒ Excel ì €ì¥ ì‹¤íŒ¨ - ìˆ˜ë£Œì¦ë“¤ì´ ì¬ì‹œë„ë©ë‹ˆë‹¤")
                
            # í—¬ìŠ¤ì²´í¬ ì—…ë°ì´íŠ¸
            update_health_status.last_batch_time = batch_start_time.isoformat()
        else:
            logger.info(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ í•­ëª© ì—†ìŒ (âŒì‹¤íŒ¨: {error_count})")
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        log_operation_end(operation_id)

def get_statistics():
    """í˜„ì¬ í†µê³„ ì •ë³´ ì¡°íšŒ (ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)"""
    try:
        # ê°„ë‹¨í•œ ìºì‹± (30ì´ˆ)
        current_time = time.time()
        if hasattr(get_statistics, 'cache_time') and (current_time - get_statistics.cache_time) < 30:
            return get_statistics.cached_stats
        
        # ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ (ì „ì²´ê°€ ì•„ë‹Œ ì¼ë¶€ë§Œ í™•ì¸)
        sample_size = 500
        
        # ì²˜ë¦¬ ëŒ€ê¸° ì¤‘ì¸ ìˆ˜ë£Œì¦ ìˆ˜ (ìƒ˜í”Œ)
        pending_query = db.collection_group('completedCertificates') \
                         .where('excelUpdated', '==', False).limit(sample_size)
        pending_count = len(list(pending_query.stream()))
        
        # ì²˜ë¦¬ ì™„ë£Œëœ ìˆ˜ë£Œì¦ ìˆ˜ (ìƒ˜í”Œ)
        processed_query = db.collection_group('completedCertificates') \
                           .where('excelUpdated', '==', True).limit(sample_size)
        processed_count = len(list(processed_query.stream()))
        
        stats = {
            'pending': pending_count,
            'processed': processed_count,
            'total': pending_count + processed_count,
            'is_sample': True,
            'sample_size': sample_size
        }
        
        # ìºì‹œ ì €ì¥
        get_statistics.cached_stats = stats
        get_statistics.cache_time = current_time
        
        return stats
        
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'pending': -1, 'processed': -1, 'total': -1, 'error': str(e)}

# ===================================================================
# ë©”ì¸ ë£¨í”„ (ì•ˆì •ì„± ë° ëª¨ë‹ˆí„°ë§ ê°•í™”)
# ===================================================================
def run_worker():
    """ë©”ì¸ ì›Œì»¤ ë£¨í”„"""
    logger.info(f"ğŸš€ Certificate Worker v2.0 ì‹œì‘ (í”Œë ˆì´ìŠ¤í† ì–´ ì¤€ìˆ˜)")
    logger.info(f"â±ï¸ í´ë§ ê°„ê²©: {POLL_INTERVAL_SECONDS}ì´ˆ")
    logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
    logger.info(f"ğŸ”„ ìµœëŒ€ ì¬ì‹œë„: {MAX_RETRY_COUNT}")
    
    # ì´ˆê¸° ì„¤ì •
    update_health_status()
    
    # ì‹œì‘ ì‹œ í†µê³„
    initial_stats = get_statistics()
    logger.info(f"ğŸ“Š ì´ˆê¸° í†µê³„ - ëŒ€ê¸°: {initial_stats['pending']}, ì²˜ë¦¬ì™„ë£Œ: {initial_stats['processed']}")
    
    iteration = 0
    last_activity_time = None
    consecutive_empty_batches = 0
    
    while not shutdown_flag:
        try:
            iteration += 1
            
            # í—¬ìŠ¤ì²´í¬ ì—…ë°ì´íŠ¸
            update_health_status()
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            batch_start_time = datetime.now(timezone.utc)
            
            # í˜„ì¬ ì‘ì—… ì¤‘ì¸ í•­ëª© ìˆ˜ ì²´í¬
            if len(current_operations) > 10:
                logger.warning(f"âš ï¸ ë„ˆë¬´ ë§ì€ ë™ì‹œ ì‘ì—…: {len(current_operations)}ê°œ")
                time.sleep(5)
                continue
            
            # ì´ì „ í†µê³„ ì €ì¥
            prev_stats = get_statistics()
            
            # ë°°ì¹˜ ì²˜ë¦¬
            process_batch()
            
            # ì²˜ë¦¬ í›„ í†µê³„ í™•ì¸
            current_stats = get_statistics()
            
            # í™œë™ ê°ì§€
            if current_stats['pending'] != prev_stats['pending']:
                last_activity_time = batch_start_time
                consecutive_empty_batches = 0
            else:
                consecutive_empty_batches += 1
            
            # ìƒíƒœ ë¡œê¹… (ì ì‘ì  ì£¼ê¸°)
            log_interval = 5 if consecutive_empty_batches > 5 else 10
            if iteration % log_interval == 0:
                stats = current_stats
                logger.info(f"ğŸ“ˆ ìƒíƒœ - ë°˜ë³µ: {iteration}, ëŒ€ê¸°: {stats['pending']}, ì²˜ë¦¬ì™„ë£Œ: {stats['processed']}")
                logger.info(f"ğŸ”§ í™œì„± ì‘ì—…: {len(current_operations)}ê°œ")
                
                if last_activity_time:
                    idle_time = (datetime.now(timezone.utc) - last_activity_time).total_seconds()
                    logger.info(f"ğŸ• ë§ˆì§€ë§‰ í™œë™: {idle_time:.0f}ì´ˆ ì „")
                else:
                    logger.info("ğŸ• ë§ˆì§€ë§‰ í™œë™: ì—†ìŒ")
            
            # ë™ì  ëŒ€ê¸° ì‹œê°„ (ë¹ˆ ë°°ì¹˜ê°€ ì—°ì†ìœ¼ë¡œ ë°œìƒí•˜ë©´ ëŒ€ê¸° ì‹œê°„ ì¦ê°€)
            if consecutive_empty_batches > 3:
                sleep_time = min(POLL_INTERVAL_SECONDS * 2, 300)  # ìµœëŒ€ 5ë¶„
                logger.debug(f"ğŸ˜´ ì—°ì† ë¹ˆ ë°°ì¹˜ ê°ì§€, ëŒ€ê¸° ì‹œê°„ ì—°ì¥: {sleep_time}ì´ˆ")
            else:
                sleep_time = POLL_INTERVAL_SECONDS
            
            # ì¸í„°ëŸ½íŠ¸ ê°€ëŠ¥í•œ ëŒ€ê¸°
            for _ in range(sleep_time):
                if shutdown_flag:
                    break
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("âŒ¨ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸")
            break
        except Exception as e:
            logger.error(f"âŒ ì›Œì»¤ ë£¨í”„ ì˜¤ë¥˜: {e}")
            error_sleep = min(POLL_INTERVAL_SECONDS, 60)
            logger.info(f"ğŸ”„ {error_sleep}ì´ˆ í›„ ì¬ì‹œì‘...")
            time.sleep(error_sleep)
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ”„ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°...")
            # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
            for _ in range(30):
                if not current_operations:
                    break
                time.sleep(1)
    
    logger.info("ğŸ‘‹ Certificate Worker ì•ˆì „ ì¢…ë£Œ ì™„ë£Œ")

# ===================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ===================================================================
if __name__ == "__main__":
    try:
        # í™˜ê²½ ê²€ì¦
        logger.info("ğŸ” í™˜ê²½ ê²€ì¦ ì¤‘...")
        
        # Firebase ì—°ê²° ì¬í™•ì¸
        test_collection = db.collection('_worker_health_check')
        test_doc = test_collection.document('test')
        test_doc.set({'timestamp': firestore.SERVER_TIMESTAMP, 'worker': 'certificate_worker_v2'})
        test_doc.delete()
        
        logger.info("âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
        
        # ì›Œì»¤ ì‹œì‘
        run_worker()
        
    except Exception as e:
        logger.error(f"âŒ ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)