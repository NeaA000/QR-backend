# worker/certificate_worker.py - ì¸ë±ìŠ¤ ì—†ì´ ì‘ë™í•˜ëŠ” ë²„ì „

import os
import io
import time
import logging
import signal
import sys
from datetime import datetime, timedelta, timezone
from typing import Optional, Dict, List, Tuple, Any
import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from pathlib import Path
import json

# ===================================================================
# ë¡œê¹… ì„¤ì •
# ===================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger('CertificateWorker')

# ===================================================================
# í™˜ê²½ë³€ìˆ˜ ê²€ì¦
# ===================================================================
required_env_vars = ['type', 'project_id', 'private_key', 'client_email']
for var in required_env_vars:
    if not os.environ.get(var):
        logger.error(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ëˆ„ë½: {var}")
        sys.exit(1)

# ì„¤ì •ê°’
POLL_INTERVAL_SECONDS = max(30, int(os.getenv('POLL_INTERVAL_SECONDS', '45')))
BATCH_SIZE = min(20, int(os.getenv('BATCH_SIZE', '10')))  # ì¸ë±ìŠ¤ ì—†ì´ëŠ” ì‘ê²Œ
MASTER_FILENAME = "master_certificates.xlsx"
MAX_RETRY_COUNT = 5
HEALTH_CHECK_INTERVAL = 300

logger.info(f"ğŸš€ ì„¤ì • ì™„ë£Œ - í´ë§:{POLL_INTERVAL_SECONDS}ì´ˆ, ë°°ì¹˜:{BATCH_SIZE}ê°œ")

# ===================================================================
# Firebase ì´ˆê¸°í™”
# ===================================================================
def initialize_firebase():
    """Firebase ì´ˆê¸°í™”"""
    try:
        if firebase_admin._apps:
            return
        
        firebase_creds = {
            "type": os.environ["type"],
            "project_id": os.environ["project_id"],
            "private_key_id": os.environ.get("private_key_id", ""),
            "private_key": os.environ["private_key"].replace('\\n', '\n'),
            "client_email": os.environ["client_email"],
            "client_id": os.environ.get("client_id", ""),
            "auth_uri": "https://accounts.google.com/o/oauth2/auth",
            "token_uri": "https://oauth2.googleapis.com/token",
            "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
            "client_x509_cert_url": os.environ.get("client_x509_cert_url", "")
        }
        
        cred = credentials.Certificate(firebase_creds)
        app = firebase_admin.initialize_app(cred, {
            'storageBucket': f"{os.environ['project_id']}.appspot.com"
        })
        
        logger.info("âœ… Firebase ì´ˆê¸°í™” ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        sys.exit(1)

# Firebase ì´ˆê¸°í™”
initialize_firebase()
db = firestore.client()
bucket = storage.bucket()

# ===================================================================
# ì•ˆì „í•œ ì¢…ë£Œ ê´€ë¦¬
# ===================================================================
shutdown_flag = False
current_operations = set()
operations_lock = threading.Lock()

def signal_handler(signum, frame):
    global shutdown_flag
    logger.info(f"ğŸ›‘ ì¢…ë£Œ ì‹œê·¸ë„ ìˆ˜ì‹  - ì•ˆì „í•œ ì¢…ë£Œ ì‹œì‘")
    shutdown_flag = True
    
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ“‹ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°")

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

def log_operation_start(operation_id):
    with operations_lock:
        current_operations.add(operation_id)

def log_operation_end(operation_id):
    with operations_lock:
        current_operations.discard(operation_id)

# ===================================================================
# ì¸ë±ìŠ¤ ì—†ì´ ì‘ë™í•˜ëŠ” ìˆ˜ë£Œì¦ ì¡°íšŒ
# ===================================================================
def get_pending_certificates_no_index(limit=20):
    """
    ì¸ë±ìŠ¤ ì—†ì´ ì‘ë™í•˜ëŠ” ìˆ˜ë£Œì¦ ì¡°íšŒ - ê°œë³„ ì‚¬ìš©ì ê²€ìƒ‰
    """
    operation_id = f"get_pending_no_index_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        logger.info("ğŸ” ì¸ë±ìŠ¤ ì—†ì´ ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹œì‘ (ê°œë³„ ì‚¬ìš©ì ê²€ìƒ‰)")
        
        # 1ë‹¨ê³„: í™œì„± ì‚¬ìš©ìë“¤ ì¡°íšŒ
        try:
            # ìµœê·¼ 30ì¼ ë‚´ í™œë™í•œ ì‚¬ìš©ìë“¤ ì¡°íšŒ
            recent_time = datetime.now(timezone.utc) - timedelta(days=30)
            
            # users ì»¬ë ‰ì…˜ì—ì„œ ìµœê·¼ ë¡œê·¸ì¸ ì‚¬ìš©ì ì¡°íšŒ
            users_query = db.collection('users') \
                           .where('lastLogin', '>=', recent_time) \
                           .limit(100)  # ìµœëŒ€ 100ëª…
            
            active_users = list(users_query.stream())
            logger.info(f"ğŸ“Š ìµœê·¼ 30ì¼ ë‚´ í™œì„± ì‚¬ìš©ì: {len(active_users)}ëª…")
            
        except Exception as e:
            logger.warning(f"âš ï¸ í™œì„± ì‚¬ìš©ì ì¡°íšŒ ì‹¤íŒ¨, ì „ì²´ ì‚¬ìš©ì ì¡°íšŒ: {e}")
            # í´ë°±: ì „ì²´ ì‚¬ìš©ìì—ì„œ ëœë¤ ìƒ˜í”Œë§
            all_users_query = db.collection('users').limit(50)
            active_users = list(all_users_query.stream())
            logger.info(f"ğŸ“Š ì „ì²´ ì‚¬ìš©ì ìƒ˜í”Œ: {len(active_users)}ëª…")
        
        if not active_users:
            logger.info("ğŸ˜´ í™œì„± ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤")
            return []
        
        # 2ë‹¨ê³„: ê° ì‚¬ìš©ìë³„ë¡œ ìˆ˜ë£Œì¦ ê²€ìƒ‰
        results = []
        checked_users = 0
        found_certs = 0
        
        for user_doc in active_users:
            if shutdown_flag or len(results) >= limit:
                break
                
            user_uid = user_doc.id
            checked_users += 1
            
            try:
                # í•´ë‹¹ ì‚¬ìš©ìì˜ ìˆ˜ë£Œì¦ ì„œë¸Œì»¬ë ‰ì…˜ ì¡°íšŒ
                user_certs_ref = db.collection('users').document(user_uid) \
                                  .collection('completedCertificates')
                
                # ë‹¨ìˆœ ì¿¼ë¦¬ (ì¸ë±ìŠ¤ ë¶ˆí•„ìš”)
                # excelUpdated=false ì¡°ê±´ë§Œ ë¨¼ì € ì ìš©
                cert_docs = list(user_certs_ref.where('excelUpdated', '==', False).limit(5).stream())
                
                for cert_doc in cert_docs:
                    if len(results) >= limit:
                        break
                    
                    try:
                        cert_data = cert_doc.to_dict()
                        
                        # ë©”ëª¨ë¦¬ì—ì„œ ì¶”ê°€ í•„í„°ë§
                        # 1. PDF URL ì²´í¬
                        pdf_url = cert_data.get('pdfUrl', '').strip()
                        if not pdf_url:
                            continue
                        
                        # 2. sentToAdmin ì²´í¬
                        sent_to_admin = cert_data.get('sentToAdmin', False)
                        if not sent_to_admin:
                            continue
                        
                        # 3. ì¬ì‹œë„ íšŸìˆ˜ ì²´í¬
                        retry_count = cert_data.get('retryCount', 0)
                        if retry_count >= MAX_RETRY_COUNT:
                            # ì¬ì‹œë„ ë¦¬ì…‹ ì˜µì…˜
                            reset_enabled = os.getenv('RESET_HIGH_RETRY_COUNT', 'false').lower() == 'true'
                            if reset_enabled and retry_count <= 10:
                                logger.info(f"ğŸ”„ ì¬ì‹œë„ ì¹´ìš´í„° ë¦¬ì…‹: {user_uid[:8]}.../{cert_doc.id[:8]}...")
                                try:
                                    cert_doc.reference.update({
                                        'retryCount': 0,
                                        'resetAt': firestore.SERVER_TIMESTAMP,
                                        'resetReason': 'no_index_worker_reset'
                                    })
                                except Exception:
                                    continue
                            else:
                                continue
                        
                        # ëª¨ë“  ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ìˆ˜ë£Œì¦ ë°œê²¬
                        results.append((user_uid, cert_doc.id, cert_data))
                        found_certs += 1
                        
                        if len(results) <= 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                            lecture_title = cert_data.get('lectureTitle', 'ì œëª©ì—†ìŒ')
                            logger.info(f"âœ… ì²˜ë¦¬ ëŒ€ìƒ ë°œê²¬: {user_uid[:8]}.../{cert_doc.id[:8]}... - {lecture_title[:30]}...")
                        
                    except Exception as e:
                        logger.debug(f"ìˆ˜ë£Œì¦ ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        continue
                        
            except Exception as e:
                logger.debug(f"ì‚¬ìš©ì {user_uid[:8]}... ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                continue
            
            # ì§„í–‰ ìƒí™© ë¡œê¹…
            if checked_users % 10 == 0:
                logger.info(f"ğŸ“Š ì§„í–‰ ìƒí™©: {checked_users}/{len(active_users)}ëª… í™•ì¸, {found_certs}ê°œ ìˆ˜ë£Œì¦ ë°œê²¬")
        
        logger.info(f"ğŸ¯ ìµœì¢… ê²°ê³¼:")
        logger.info(f"  ğŸ‘¥ í™•ì¸í•œ ì‚¬ìš©ì: {checked_users}ëª…")
        logger.info(f"  ğŸ“‹ ë°œê²¬í•œ ìˆ˜ë£Œì¦: {found_certs}ê°œ")
        logger.info(f"  âœ… ì²˜ë¦¬ ê°€ëŠ¥: {len(results)}ê°œ")
        
        if len(results) == 0:
            logger.info("ğŸ’¡ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤")
            logger.info("   - ì‚¬ìš©ìë“¤ì´ 'ê´€ë¦¬ì ì „ì†¡' ë²„íŠ¼ì„ í´ë¦­í–ˆëŠ”ì§€ í™•ì¸")
            logger.info("   - sentToAdmin=true, pdfUrl ì¡´ì¬, excelUpdated=false ì¡°ê±´ í™•ì¸")
        
        return results
        
    except Exception as e:
        logger.error(f"âŒ ì¸ë±ìŠ¤ ì—†ëŠ” ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    finally:
        log_operation_end(operation_id)

def get_user_info(user_uid):
    """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ (ìºì‹±)"""
    if not hasattr(get_user_info, 'cache'):
        get_user_info.cache = {}
    
    if user_uid in get_user_info.cache:
        return get_user_info.cache[user_uid]
    
    try:
        user_doc = db.collection('users').document(user_uid).get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            user_info = {
                'name': user_data.get('name', ''),
                'phone': user_data.get('phone', ''),
                'email': user_data.get('email', '')
            }
            
            if len(get_user_info.cache) < 1000:
                get_user_info.cache[user_uid] = user_info
            
            return user_info
        else:
            empty_info = {'name': '', 'phone': '', 'email': ''}
            get_user_info.cache[user_uid] = empty_info
            return empty_info
            
    except Exception as e:
        logger.debug(f"ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'name': '', 'phone': '', 'email': ''}

# ===================================================================
# Excel ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ===================================================================
def load_master_excel():
    """ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ"""
    operation_id = f"load_excel_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        try:
            master_blob = bucket.blob(MASTER_FILENAME)
            existing_bytes = master_blob.download_as_bytes()
            
            excel_buffer = io.BytesIO(existing_bytes)
            df = pd.read_excel(excel_buffer, engine='openpyxl')
            
            expected_columns = [
                'ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼', 
                'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL'
            ]
            
            if not all(col in df.columns for col in expected_columns):
                logger.warning("âš ï¸ ì—‘ì…€ ì»¬ëŸ¼ êµ¬ì¡° ì´ìƒ, ìƒˆë¡œ ìƒì„±")
                return create_empty_dataframe()
            
            if len(df) > 15000:
                logger.warning("âš ï¸ ë°ì´í„° í¬ê¸° ì œí•œìœ¼ë¡œ ìµœê·¼ 10,000í–‰ë§Œ ìœ ì§€")
                df = df.tail(10000).reset_index(drop=True)
            
            logger.info(f"âœ… ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
            return df
            
        except Exception:
            logger.info("âš ï¸ Firebase Storage ë¡œë“œ ì‹¤íŒ¨, ìƒˆ íŒŒì¼ ìƒì„±")
            return create_empty_dataframe()
            
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return create_empty_dataframe()
    finally:
        log_operation_end(operation_id)

def create_empty_dataframe():
    """ë¹ˆ DataFrame ìƒì„±"""
    return pd.DataFrame(columns=[
        'ì—…ë°ì´íŠ¸ ë‚ ì§œ',
        'ì‚¬ìš©ì UID',
        'ì „í™”ë²ˆí˜¸',
        'ì´ë©”ì¼',
        'ì‚¬ìš©ì ì´ë¦„',
        'ê°•ì˜ ì œëª©',
        'ë°œê¸‰ ì¼ì‹œ',
        'PDF URL'
    ])

def save_master_excel(df):
    """ë§ˆìŠ¤í„° ì—‘ì…€ ì €ì¥"""
    operation_id = f"save_excel_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        if len(df) > 20000:
            logger.warning("âš ï¸ ì €ì¥ í¬ê¸° ì œí•œìœ¼ë¡œ ìµœê·¼ 15,000í–‰ë§Œ ì €ì¥")
            df = df.tail(15000).reset_index(drop=True)
        
        out_buffer = io.BytesIO()
        with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Certificates')
        out_buffer.seek(0)
        
        backup_path = Path(f'/tmp/backup_{int(time.time())}.xlsx')
        try:
            with open(backup_path, 'wb') as f:
                f.write(out_buffer.getvalue())
            logger.info("ğŸ’¾ ë¡œì»¬ ë°±ì—… ì™„ë£Œ")
        except Exception:
            logger.debug("ë¡œì»¬ ë°±ì—… ì‹¤íŒ¨")
        
        max_retries = 3
        for attempt in range(max_retries):
            try:
                out_buffer.seek(0)
                master_blob = bucket.blob(MASTER_FILENAME)
                
                master_blob.upload_from_file(
                    out_buffer,
                    content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
                
                logger.info(f"âœ… ì—‘ì…€ ì €ì¥ ì™„ë£Œ (ì´ {len(df)}í–‰)")
                
                try:
                    backup_path.unlink()
                except Exception:
                    pass
                
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return False
        
        return False
        
    except Exception as e:
        logger.error(f"âŒ ì—‘ì…€ ì €ì¥ ì¤‘ ì˜ˆì™¸: {e}")
        return False
    finally:
        log_operation_end(operation_id)

# ===================================================================
# ìˆ˜ë£Œì¦ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ===================================================================
def process_certificate(user_uid, cert_id, cert_data, df):
    """ë‹¨ì¼ ìˆ˜ë£Œì¦ ì²˜ë¦¬"""
    try:
        user_info = get_user_info(user_uid)
        
        lecture_title = cert_data.get('lectureTitle', cert_id)
        pdf_url = cert_data.get('pdfUrl', '')
        
        if not pdf_url.strip():
            raise ValueError("PDF URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        issued_at = cert_data.get('issuedAt')
        if hasattr(issued_at, 'to_datetime'):
            issued_str = issued_at.to_datetime().strftime('%Y-%m-%d %H:%M:%S')
        else:
            issued_str = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
        
        # ì¤‘ë³µ í™•ì¸
        existing_mask = (
            (df['ì‚¬ìš©ì UID'] == user_uid) & 
            (df['ê°•ì˜ ì œëª©'] == lecture_title) & 
            (df['PDF URL'] == pdf_url)
        )
        
        if existing_mask.any():
            logger.info(f"âš ï¸ ì¤‘ë³µ ìˆ˜ë£Œì¦ ìŠ¤í‚µ: {user_uid[:8]}.../{lecture_title[:20]}...")
            return True, df
        
        updated_date = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
        new_row = pd.DataFrame([{
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
            'ì‚¬ìš©ì UID': user_uid,
            'ì „í™”ë²ˆí˜¸': user_info['phone'],
            'ì´ë©”ì¼': user_info['email'],
            'ì‚¬ìš©ì ì´ë¦„': user_info['name'],
            'ê°•ì˜ ì œëª©': lecture_title,
            'ë°œê¸‰ ì¼ì‹œ': issued_str,
            'PDF URL': pdf_url
        }])
        
        df = pd.concat([df, new_row], ignore_index=True)
        
        logger.info(f"âœ… ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì™„ë£Œ: {user_uid[:8]}.../{cert_id[:8]}... - {lecture_title[:30]}...")
        return True, df
        
    except Exception as e:
        logger.warning(f"âš ï¸ ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì‹¤íŒ¨ ({user_uid[:8]}.../{cert_id[:8]}...): {e}")
        
        try:
            cert_ref = db.collection('users').document(user_uid) \
                         .collection('completedCertificates').document(cert_id)
            cert_ref.update({
                'processingError': str(e)[:200],
                'errorOccurredAt': firestore.SERVER_TIMESTAMP,
                'retryCount': firestore.Increment(1)
            })
        except Exception:
            pass
        
        return False, df

def update_certificate_flags_batch(processed_certs, success=True):
    """ë°°ì¹˜ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸"""
    operation_id = f"update_flags_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        def update_single_flag(cert_info):
            user_uid, cert_id, cert_data = cert_info
            try:
                cert_ref = db.collection('users').document(user_uid) \
                             .collection('completedCertificates').document(cert_id)
                
                if success:
                    update_data = {
                        'excelUpdated': True,
                        'processedAt': firestore.SERVER_TIMESTAMP,
                        'processedBy': 'no_index_worker_v1',
                        'workerProcessed': True
                    }
                    
                    if 'processingError' in cert_data:
                        update_data['processingError'] = firestore.DELETE_FIELD
                    if 'readyForExcel' in cert_data:
                        update_data['readyForExcel'] = False
                    
                    cert_ref.update(update_data)
                    return "âœ…"
                    
                else:
                    cert_ref.update({
                        'excelSaveError': True,
                        'excelSaveErrorAt': firestore.SERVER_TIMESTAMP,
                        'retryCount': firestore.Increment(1)
                    })
                    return "âš ï¸"
                    
            except Exception as e:
                logger.debug(f"í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
                return "âŒ"
        
        with ThreadPoolExecutor(max_workers=3) as executor:
            results = list(executor.map(update_single_flag, processed_certs))
        
        success_count = sum(1 for r in results if r == 'âœ…')
        logger.info(f"âœ… í”Œë˜ê·¸ ì—…ë°ì´íŠ¸: {success_count}/{len(results)}")
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        log_operation_end(operation_id)

# ===================================================================
# ë°°ì¹˜ ì²˜ë¦¬
# ===================================================================
def process_batch():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰"""
    operation_id = f"batch_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        batch_start_time = datetime.now(timezone.utc)
        
        # ì¸ë±ìŠ¤ ì—†ì´ ìˆ˜ë£Œì¦ ì¡°íšŒ
        pending_certs = get_pending_certificates_no_index(limit=BATCH_SIZE)
        
        if not pending_certs:
            logger.info("ğŸ˜´ ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"ğŸš€ {len(pending_certs)}ê°œ ìˆ˜ë£Œì¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        df = load_master_excel()
        original_row_count = len(df)
        
        success_count = 0
        error_count = 0
        processed_certs = []
        
        for i, (user_uid, cert_id, cert_data) in enumerate(pending_certs, 1):
            if shutdown_flag:
                logger.info("ğŸ›‘ ì¢…ë£Œ í”Œë˜ê·¸ ê°ì§€, ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨")
                break
            
            if len(pending_certs) > 5 and i % max(1, len(pending_certs) // 5) == 0:
                progress = (i / len(pending_certs)) * 100
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ì§„í–‰ë¥ : {progress:.0f}% ({i}/{len(pending_certs)})")
            
            success, df = process_certificate(user_uid, cert_id, cert_data, df)
            
            if success:
                success_count += 1
                processed_certs.append((user_uid, cert_id, cert_data))
            else:
                error_count += 1
        
        if success_count > 0:
            new_row_count = len(df)
            logger.info(f"ğŸ“Š Excel ì €ì¥: {original_row_count}í–‰ â†’ {new_row_count}í–‰ (+{new_row_count - original_row_count})")
            
            excel_save_success = save_master_excel(df)
            update_certificate_flags_batch(processed_certs, success=excel_save_success)
            
            processing_time = (datetime.now(timezone.utc) - batch_start_time).total_seconds()
            
            if excel_save_success:
                logger.info(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - âœ…ì„±ê³µ: {success_count}, âŒì‹¤íŒ¨: {error_count}, â±ï¸ì‹œê°„: {processing_time:.1f}ì´ˆ")
            else:
                logger.error(f"âŒ Excel ì €ì¥ ì‹¤íŒ¨ - ì¬ì‹œë„ ì˜ˆì •")
        else:
            logger.info(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ í•­ëª© ì—†ìŒ (âŒì‹¤íŒ¨: {error_count})")
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        log_operation_end(operation_id)

def update_health_status():
    """í—¬ìŠ¤ì²´í¬ íŒŒì¼ ì—…ë°ì´íŠ¸"""
    try:
        health_file = Path('/tmp/worker_healthy')
        health_data = {
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'active_operations': len(current_operations),
            'poll_interval': POLL_INTERVAL_SECONDS,
            'batch_size': BATCH_SIZE,
            'mode': 'no_index'
        }
        
        with open(health_file, 'w') as f:
            json.dump(health_data, f)
            
    except Exception as e:
        logger.debug(f"í—¬ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

# ===================================================================
# ë©”ì¸ ì›Œì»¤ ë£¨í”„
# ===================================================================
def run_worker():
    """ë©”ì¸ ì›Œì»¤ ë£¨í”„"""
    logger.info(f"ğŸš€ Certificate Worker v3.2 ì‹œì‘ (ì¸ë±ìŠ¤ ì—†ì´ ì‘ë™)")
    logger.info(f"â±ï¸ í´ë§ ê°„ê²©: {POLL_INTERVAL_SECONDS}ì´ˆ")
    logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
    logger.info(f"ğŸ”„ ìµœëŒ€ ì¬ì‹œë„: {MAX_RETRY_COUNT}")
    logger.info(f"ğŸ”§ ì¬ì‹œë„ ë¦¬ì…‹: {os.getenv('RESET_HIGH_RETRY_COUNT', 'false')}")
    logger.info(f"ğŸ” ëª¨ë“œ: ì¸ë±ìŠ¤ ì—†ì´ ê°œë³„ ì‚¬ìš©ì ê²€ìƒ‰")
    
    update_health_status()
    
    iteration = 0
    last_activity_time = None
    consecutive_empty_batches = 0
    
    while not shutdown_flag:
        try:
            iteration += 1
            
            if iteration % 10 == 0:
                update_health_status()
            
            batch_start_time = datetime.now(timezone.utc)
            
            if len(current_operations) > 5:
                logger.warning(f"âš ï¸ ë„ˆë¬´ ë§ì€ ë™ì‹œ ì‘ì—…: {len(current_operations)}ê°œ")
                time.sleep(5)
                continue
            
            # ë°°ì¹˜ ì²˜ë¦¬
            process_batch()
            
            # í™œë™ ê°ì§€ (ê°„ì†Œí™”)
            consecutive_empty_batches += 1
            
            # ìƒíƒœ ë¡œê¹…
            if iteration % 10 == 0:
                logger.info(f"ğŸ“ˆ ìƒíƒœ - ë°˜ë³µ: {iteration}, í™œì„±ì‘ì—…: {len(current_operations)}ê°œ, ëª¨ë“œ: ì¸ë±ìŠ¤ì—†ìŒ")
            
            # ë™ì  ëŒ€ê¸° ì‹œê°„
            if consecutive_empty_batches > 10:
                sleep_time = min(POLL_INTERVAL_SECONDS * 2, 120)
            else:
                sleep_time = POLL_INTERVAL_SECONDS
            
            # ì¸í„°ëŸ½íŠ¸ ê°€ëŠ¥í•œ ëŒ€ê¸°
            for _ in range(sleep_time):
                if shutdown_flag:
                    break
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("âŒ¨ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ - ì¢…ë£Œ")
            break
        except Exception as e:
            logger.error(f"âŒ ì›Œì»¤ ë£¨í”„ ì˜¤ë¥˜: {e}")
            time.sleep(min(POLL_INTERVAL_SECONDS, 60))
    
    # ì¢…ë£Œ ì •ë¦¬
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ”„ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°...")
            for _ in range(30):
                if not current_operations:
                    break
                time.sleep(1)
    
    logger.info("ğŸ‘‹ Certificate Worker ì•ˆì „ ì¢…ë£Œ ì™„ë£Œ")

# ===================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ===================================================================
if __name__ == "__main__":
    try:
        logger.info("ğŸ” ìµœì¢… ê²€ì¦ ì¤‘...")
        
        # Firebase ì—°ê²° í…ŒìŠ¤íŠ¸
        test_collection = db.collection('_worker_health')
        test_doc = test_collection.document(f"no_index_test_{int(time.time())}")
        test_doc.set({
            'timestamp': firestore.SERVER_TIMESTAMP,
            'worker': 'no_index_certificate_worker_v1',
            'startup_time': datetime.now(timezone.utc).isoformat(),
            'mode': 'no_index'
        })
        test_doc.delete()
        
        logger.info("âœ… ìµœì¢… ê²€ì¦ ì™„ë£Œ")
        
        # ì›Œì»¤ ì‹œì‘
        run_worker()
        
    except Exception as e:
        logger.error(f"âŒ ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)