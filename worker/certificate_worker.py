# worker/certificate_worker.py - ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì „ìš© ì›Œì»¤ (ì™„ì „ ê°œì„  ë²„ì „)

import os
import io
import time
import logging
import signal
import sys
from datetime import datetime, timedelta, timezone
import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage
from concurrent.futures import ThreadPoolExecutor
import threading
from pathlib import Path

# ===================================================================
# ë¡œê¹… ì„¤ì • (ë³´ì•ˆ ê°•í™”)
# ===================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('CertificateWorker')

# ë¯¼ê°í•œ ì •ë³´ ë¡œê¹… ë°©ì§€
class SecurityFilter(logging.Filter):
    """ë¯¼ê°í•œ ì •ë³´ë¥¼ í•„í„°ë§í•˜ëŠ” ë¡œê·¸ í•„í„°"""
    def filter(self, record):
        sensitive_keywords = ['password', 'secret', 'key', 'token', 'credential']
        message = record.getMessage().lower()
        return not any(keyword in message for keyword in sensitive_keywords)

logger.addFilter(SecurityFilter())

# ===================================================================
# í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì • (ê²€ì¦ ê°•í™”)
# ===================================================================
POLL_INTERVAL_SECONDS = int(os.getenv('POLL_INTERVAL_SECONDS', '30'))  # 30ì´ˆë¡œ ë‹¨ì¶•
BATCH_SIZE = int(os.getenv('BATCH_SIZE', '20'))  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ
MASTER_FILENAME = "master_certificates.xlsx"
MAX_RETRY_COUNT = 3
HEALTH_CHECK_INTERVAL = 300

# í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ ê²€ì¦
required_env_vars = ['type', 'project_id', 'private_key', 'client_email']
for var in required_env_vars:
    if not os.environ.get(var):
        logger.error(f"í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ {var}ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

# ===================================================================
# Firebase ì´ˆê¸°í™” (ë³´ì•ˆ ê°•í™”)
# ===================================================================
def initialize_firebase():
    """Firebase Admin SDK ì•ˆì „ ì´ˆê¸°í™”"""
    try:
        if firebase_admin._apps:
            return firebase_admin.get_app(), firestore.client(), storage.bucket()
            
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìê²©ì¦ëª… ìƒì„±
        firebase_creds = {
            "type": os.environ.get("type", "service_account"),
            "project_id": os.environ["project_id"],
            "private_key_id": os.environ.get("private_key_id", ""),
            "private_key": os.environ["private_key"].replace('\\n', '\n'),
            "client_email": os.environ["client_email"],
            "client_id": os.environ.get("client_id", ""),
            "auth_uri": os.environ.get("auth_uri", "https://accounts.google.com/o/oauth2/auth"),
            "token_uri": os.environ.get("token_uri", "https://oauth2.googleapis.com/token"),
            "auth_provider_x509_cert_url": os.environ.get("auth_provider_x509_cert_url", "https://www.googleapis.com/oauth2/v1/certs"),
            "client_x509_cert_url": os.environ.get("client_x509_cert_url", "")
        }
        
        cred = credentials.Certificate(firebase_creds)
        
        # Storage bucket ì´ë¦„ ìˆ˜ì • (ì¼ë°˜ì ì¸ í˜•ì‹)
        storage_bucket = f"{os.environ['project_id']}.appspot.com"
        
        app = firebase_admin.initialize_app(cred, {
            'storageBucket': storage_bucket
        })
        
        db = firestore.client()
        bucket = storage.bucket()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        test_doc = db.collection('_health_check').document('worker_test')
        test_doc.set({
            'timestamp': firestore.SERVER_TIMESTAMP,
            'worker': 'certificate_worker_v3',
            'status': 'initialized'
        })
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ì‚­ì œ
        test_doc.delete()
        
        logger.info(f"âœ… Firebase ì´ˆê¸°í™” ë° ì—°ê²° í…ŒìŠ¤íŠ¸ ì™„ë£Œ - Project: {os.environ['project_id']}")
        return app, db, bucket
        
    except Exception as e:
        logger.error(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

# Firebase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
app, db, bucket = initialize_firebase()

# ===================================================================
# ì¢…ë£Œ ì‹œê·¸ë„ ì²˜ë¦¬ (ì•ˆì „í•œ ì¢…ë£Œ)
# ===================================================================
shutdown_flag = False
current_operations = set()
operations_lock = threading.Lock()

def signal_handler(signum, frame):
    """SIGINT/SIGTERM ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
    global shutdown_flag
    logger.info(f"ğŸ›‘ ì¢…ë£Œ ì‹œê·¸ë„ ë°›ìŒ ({signum}). í˜„ì¬ ì‘ì—… ì™„ë£Œ í›„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    shutdown_flag = True
    
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ“‹ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸° ì¤‘...")

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ===================================================================
# í—¬ìŠ¤ì²´í¬ ë° ëª¨ë‹ˆí„°ë§
# ===================================================================
def update_health_status():
    """í—¬ìŠ¤ì²´í¬ íŒŒì¼ ì—…ë°ì´íŠ¸"""
    try:
        health_file = Path('/tmp/worker_healthy')
        health_data = {
            'status': 'healthy',
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'active_operations': len(current_operations),
            'poll_interval': POLL_INTERVAL_SECONDS,
            'batch_size': BATCH_SIZE
        }
        
        with open(health_file, 'w') as f:
            f.write(f"healthy at {health_data['timestamp']}")
            
    except Exception as e:
        logger.warning(f"í—¬ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def log_operation_start(operation_id):
    """ì‘ì—… ì‹œì‘ ë¡œê¹…"""
    with operations_lock:
        current_operations.add(operation_id)

def log_operation_end(operation_id):
    """ì‘ì—… ì¢…ë£Œ ë¡œê¹…"""
    with operations_lock:
        current_operations.discard(operation_id)

# ===================================================================
# ìˆ˜ë£Œì¦ ì²˜ë¦¬ í•¨ìˆ˜ë“¤ (ì™„ì „ ê°œì„ )
# ===================================================================
def test_collection_group_query():
    """Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸"""
    try:
        logger.info("ğŸ” Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
        test_query = db.collection_group('completedCertificates').limit(1)
        test_results = list(test_query.stream())
        
        logger.info(f"âœ… Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(test_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
        
        # excelUpdated í•„ë“œê°€ ìˆëŠ” ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        filtered_query = db.collection_group('completedCertificates') \
                          .where('excelUpdated', '==', False).limit(1)
        filtered_results = list(filtered_query.stream())
        
        logger.info(f"âœ… í•„í„°ë§ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {len(filtered_results)}ê°œ ëŒ€ê¸° ë¬¸ì„œ ë°œê²¬")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        if 'index' in str(e).lower():
            logger.error("ğŸš¨ Firestore ì¸ë±ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤!")
            logger.error("ğŸ“ í•´ê²°ë°©ë²•:")
            logger.error("   1. Firebase Console â†’ Firestore â†’ Indexes")
            logger.error("   2. Single Field íƒ­ â†’ Add exemption")
            logger.error("   3. Collection ID: completedCertificates")
            logger.error("   4. Field path: excelUpdated")
            logger.error("   5. Query scopes: Collection group ì„ íƒ")
            logger.error("   6. Ascending/Descending ëª¨ë‘ ì²´í¬")
        return False

def get_pending_certificates_safe(limit=50):
    """
    ì•ˆì „í•œ ìˆ˜ë£Œì¦ ì¡°íšŒ - ì¸ë±ìŠ¤ ë¬¸ì œ í•´ê²° ë° í´ë°± ë¡œì§
    """
    operation_id = f"get_pending_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        # ë°©ë²• 1: Collection Group ì¿¼ë¦¬ ì‹œë„
        try:
            query = db.collection_group('completedCertificates') \
                      .where('excelUpdated', '==', False) \
                      .limit(limit)
            
            results = []
            doc_count = 0
            
            for doc in query.stream():
                if shutdown_flag:
                    break
                    
                doc_count += 1
                try:
                    data = doc.to_dict()
                    
                    # PDF URL í•„ìˆ˜ í™•ì¸
                    pdf_url = data.get('pdfUrl', '')
                    if not pdf_url or pdf_url.strip() == '':
                        continue
                    
                    # ì¬ì‹œë„ íšŸìˆ˜ í™•ì¸
                    retry_count = data.get('retryCount', 0)
                    if retry_count >= MAX_RETRY_COUNT:
                        logger.debug(f"âš ï¸ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼: {doc.id}")
                        continue
                    
                    # ë¬¸ì„œ ê²½ë¡œì—ì„œ user_uid ì¶”ì¶œ
                    path_parts = doc.reference.path.split('/')
                    if len(path_parts) >= 4:
                        user_uid = path_parts[1]
                        cert_id = doc.id
                        results.append((user_uid, cert_id, data))
                        
                        if len(results) <= 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                            lecture_title = data.get('lectureTitle', 'ì œëª©ì—†ìŒ')
                            logger.info(f"ğŸ“‹ ë°œê²¬: {user_uid[:8]}.../{cert_id[:8]}... - {lecture_title[:30]}...")
                    else:
                        logger.warning(f"âš ï¸ ì˜ëª»ëœ ë¬¸ì„œ ê²½ë¡œ: {doc.reference.path}")
                        
                except Exception as e:
                    logger.error(f"âŒ ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜ {doc.id}: {e}")
                    
                # ì²˜ë¦¬ëŸ‰ ì œí•œ
                if doc_count >= limit * 2:  # ìµœëŒ€ ê²€ìƒ‰ëŸ‰ ì œí•œ
                    break
            
            if results:
                logger.info(f"âœ… Collection Group ì¿¼ë¦¬ë¡œ {len(results)}ê°œ ìˆ˜ë£Œì¦ ë°œê²¬ (ê²€ìƒ‰í•œ ë¬¸ì„œ: {doc_count}ê°œ)")
                if len(results) > 3:
                    logger.info(f"  ... ê·¸ ì™¸ {len(results) - 3}ê°œ ë”")
            else:
                logger.info(f"ğŸ˜´ ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤ (ê²€ìƒ‰í•œ ë¬¸ì„œ: {doc_count}ê°œ)")
                
            return results
            
        except Exception as cg_error:
            logger.warning(f"âš ï¸ Collection Group ì¿¼ë¦¬ ì‹¤íŒ¨, í´ë°± ëª¨ë“œë¡œ ì „í™˜: {cg_error}")
            
            # ë°©ë²• 2: ê°œë³„ ì‚¬ìš©ì ì»¬ë ‰ì…˜ ê²€ìƒ‰ (í´ë°±)
            return get_pending_certificates_fallback(limit)
            
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ë£Œì¦ ì¡°íšŒ ì™„ì „ ì‹¤íŒ¨: {e}")
        return []
    finally:
        log_operation_end(operation_id)

def get_pending_certificates_fallback(limit=20):
    """
    í´ë°± ëª¨ë“œ: ê°œë³„ ì‚¬ìš©ì ì»¬ë ‰ì…˜ì—ì„œ ìˆ˜ë£Œì¦ ê²€ìƒ‰
    """
    try:
        logger.info("ğŸ”„ í´ë°± ëª¨ë“œ: ê°œë³„ ì‚¬ìš©ì ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì¤‘...")
        
        # ìµœê·¼ í™œë™í•œ ì‚¬ìš©ìë“¤ ì¡°íšŒ
        users_ref = db.collection('users')
        users = list(users_ref.limit(50).stream())  # ìµœëŒ€ 50ëª…
        
        results = []
        
        for user_doc in users:
            if shutdown_flag or len(results) >= limit:
                break
                
            user_uid = user_doc.id
            
            try:
                # ê° ì‚¬ìš©ìì˜ ìˆ˜ë£Œì¦ ì¡°íšŒ
                certs_ref = db.collection('users').document(user_uid) \
                             .collection('completedCertificates')
                
                # ê°„ë‹¨í•œ ì¿¼ë¦¬ (ì¸ë±ìŠ¤ ë¶ˆí•„ìš”)
                cert_docs = list(certs_ref.where('excelUpdated', '==', False).limit(3).stream())
                
                for cert_doc in cert_docs:
                    if len(results) >= limit:
                        break
                        
                    cert_data = cert_doc.to_dict()
                    
                    # PDF URL í™•ì¸
                    if cert_data.get('pdfUrl', '').strip():
                        results.append((user_uid, cert_doc.id, cert_data))
                        
                        lecture_title = cert_data.get('lectureTitle', 'ì œëª©ì—†ìŒ')
                        logger.info(f"ğŸ“‹ í´ë°±ìœ¼ë¡œ ë°œê²¬: {user_uid[:8]}.../{cert_doc.id[:8]}... - {lecture_title[:20]}...")
                        
            except Exception as e:
                logger.debug(f"âš ï¸ ì‚¬ìš©ì {user_uid[:8]}... ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                
        logger.info(f"ğŸ”„ í´ë°± ëª¨ë“œë¡œ {len(results)}ê°œ ìˆ˜ë£Œì¦ ë°œê²¬")
        return results
        
    except Exception as e:
        logger.error(f"âŒ í´ë°± ëª¨ë“œë„ ì‹¤íŒ¨: {e}")
        return []

def get_user_info_safe(user_uid):
    """ì‚¬ìš©ì ì •ë³´ ì•ˆì „ ì¡°íšŒ (ìºì‹± í¬í•¨)"""
    try:
        # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ìºì‹œ
        if not hasattr(get_user_info_safe, 'cache'):
            get_user_info_safe.cache = {}
        
        if user_uid in get_user_info_safe.cache:
            return get_user_info_safe.cache[user_uid]
        
        user_doc = db.collection('users').document(user_uid).get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            user_info = {
                'name': user_data.get('name', ''),
                'phone': user_data.get('phone', ''),
                'email': user_data.get('email', '')
            }
            
            # ìºì‹œ ì €ì¥ (ìµœëŒ€ 500ê°œ)
            if len(get_user_info_safe.cache) < 500:
                get_user_info_safe.cache[user_uid] = user_info
            
            logger.debug(f"ğŸ‘¤ ì‚¬ìš©ì ì •ë³´: {user_uid[:8]}... - {user_info['name']}")
            return user_info
        else:
            empty_info = {'name': '', 'phone': '', 'email': ''}
            get_user_info_safe.cache[user_uid] = empty_info
            logger.warning(f"âš ï¸ ì‚¬ìš©ì ë¬¸ì„œ ì—†ìŒ: {user_uid[:8]}...")
            return empty_info
            
    except Exception as e:
        logger.error(f"âŒ ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({user_uid[:8]}...): {e}")
        return {'name': '', 'phone': '', 'email': ''}

def get_or_create_master_excel():
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„± (í–¥ìƒëœ ë°±ì—… ì‹œìŠ¤í…œ)"""
    operation_id = f"excel_load_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        # 1) Firebase Storage ì‹œë„
        try:
            master_blob = bucket.blob(MASTER_FILENAME)
            existing_bytes = master_blob.download_as_bytes()
            excel_buffer = io.BytesIO(existing_bytes)
            df = pd.read_excel(excel_buffer, engine='openpyxl')
            
            # ë°ì´í„° ê²€ì¦
            expected_columns = ['ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼', 'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL']
            missing_columns = [col for col in expected_columns if col not in df.columns]
            
            if missing_columns:
                logger.warning(f"âš ï¸ ì—‘ì…€ íŒŒì¼ì— ëˆ„ë½ëœ ì»¬ëŸ¼: {missing_columns}")
                # ëˆ„ë½ëœ ì»¬ëŸ¼ ì¶”ê°€
                for col in missing_columns:
                    df[col] = ''
                df = df[expected_columns]  # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
            
            logger.info(f"ğŸ“¥ Firebase Storageì—ì„œ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
            return df
            
        except Exception as firebase_error:
            logger.warning(f"âš ï¸ Firebase Storage ë¡œë“œ ì‹¤íŒ¨: {firebase_error}")
        
        # 2) ë¡œì»¬ ë°±ì—… íŒŒì¼ í™•ì¸
        local_backup_path = Path(f'/tmp/{MASTER_FILENAME}')
        if local_backup_path.exists():
            try:
                df = pd.read_excel(local_backup_path, engine='openpyxl')
                logger.info(f"ğŸ“¥ ë¡œì»¬ ë°±ì—…ì—ì„œ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
                return df
            except Exception as local_error:
                logger.warning(f"âš ï¸ ë¡œì»¬ ë°±ì—… ë¡œë“œ ì‹¤íŒ¨: {local_error}")
        
        # 3) ìƒˆ DataFrame ìƒì„±
        logger.info("ğŸ“„ ìƒˆ ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ìƒì„±")
        df = pd.DataFrame(columns=[
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ',
            'ì‚¬ìš©ì UID',
            'ì „í™”ë²ˆí˜¸',
            'ì´ë©”ì¼',
            'ì‚¬ìš©ì ì´ë¦„',
            'ê°•ì˜ ì œëª©',
            'ë°œê¸‰ ì¼ì‹œ',
            'PDF URL'
        ])
        return df
        
    except Exception as e:
        logger.error(f"âŒ ë§ˆìŠ¤í„° ì—‘ì…€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        raise
    finally:
        log_operation_end(operation_id)

def save_master_excel_safe(df):
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ì•ˆì „ ì €ì¥ (ì¬ì‹œë„ ë° ë°±ì—… ê°•í™”)"""
    operation_id = f"excel_save_{int(time.time())}"
    log_operation_start(operation_id)
    
    max_retries = 3
    retry_delay = 3
    
    try:
        # DataFrameì„ ì—‘ì…€ë¡œ ë³€í™˜
        out_buffer = io.BytesIO()
        with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='Certificates')
        out_buffer.seek(0)
        
        # ë¡œì»¬ ë°±ì—… ë¨¼ì € ì €ì¥
        local_backup_path = Path(f'/tmp/{MASTER_FILENAME}')
        try:
            with open(local_backup_path, 'wb') as f:
                f.write(out_buffer.getvalue())
            logger.debug(f"ğŸ’¾ ë¡œì»¬ ë°±ì—… ì €ì¥: {local_backup_path}")
        except Exception as backup_error:
            logger.warning(f"âš ï¸ ë¡œì»¬ ë°±ì—… ì €ì¥ ì‹¤íŒ¨: {backup_error}")
        
        # Firebase Storage ì—…ë¡œë“œ (ì¬ì‹œë„)
        for attempt in range(max_retries):
            try:
                out_buffer.seek(0)
                master_blob = bucket.blob(MASTER_FILENAME)
                master_blob.upload_from_file(
                    out_buffer,
                    content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
                )
                
                logger.info(f"âœ… Firebase Storageì— ë§ˆìŠ¤í„° ì—‘ì…€ ì €ì¥ ì™„ë£Œ (ì´ {len(df)}í–‰, ì‹œë„: {attempt + 1})")
                return True
                
            except Exception as e:
                logger.warning(f"âš ï¸ Excel ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)[:100]}")
                
                if attempt < max_retries - 1:
                    logger.info(f"ğŸ”„ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. Firebase Storage ì €ì¥ ì‹¤íŒ¨")
                    return False
        
        return False
        
    except Exception as e:
        logger.error(f"âŒ Excel ì €ì¥ ì¤‘ ì˜ˆì™¸: {e}")
        return False
    finally:
        log_operation_end(operation_id)

def process_certificate_safe(user_uid, cert_id, cert_data, df):
    """ë‹¨ì¼ ìˆ˜ë£Œì¦ ì•ˆì „ ì²˜ë¦¬"""
    operation_id = f"cert_process_{cert_id[:8]}"
    log_operation_start(operation_id)
    
    try:
        # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
        user_info = get_user_info_safe(user_uid)
        
        # ìˆ˜ë£Œì¦ ì •ë³´ ì¶”ì¶œ ë° ê²€ì¦
        lecture_title = cert_data.get('lectureTitle', cert_id)
        pdf_url = cert_data.get('pdfUrl', '')
        
        if not pdf_url.strip():
            raise ValueError("PDF URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        # ë°œê¸‰ ì‹œê°„ ì²˜ë¦¬
        issued_at = cert_data.get('issuedAt')
        if hasattr(issued_at, 'to_datetime'):
            issued_str = issued_at.to_datetime().strftime('%Y-%m-%d %H:%M:%S')
        else:
            issued_str = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
            logger.debug(f"âš ï¸ issuedAt í•„ë“œ ì—†ìŒ, í˜„ì¬ ì‹œê°„ ì‚¬ìš©: {cert_id[:8]}...")
        
        # ì¤‘ë³µ í™•ì¸
        existing_mask = (df['ì‚¬ìš©ì UID'] == user_uid) & (df['ê°•ì˜ ì œëª©'] == lecture_title)
        if existing_mask.any():
            logger.warning(f"âš ï¸ ì¤‘ë³µ ìˆ˜ë£Œì¦ ë°œê²¬, ìƒˆ í–‰ ì¶”ê°€: {user_uid[:8]}.../{lecture_title[:20]}...")
        
        # ìƒˆ í–‰ ìƒì„±
        updated_date = datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')
        new_row = pd.DataFrame([{
            'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
            'ì‚¬ìš©ì UID': user_uid,
            'ì „í™”ë²ˆí˜¸': user_info['phone'],
            'ì´ë©”ì¼': user_info['email'],
            'ì‚¬ìš©ì ì´ë¦„': user_info['name'],
            'ê°•ì˜ ì œëª©': lecture_title,
            'ë°œê¸‰ ì¼ì‹œ': issued_str,
            'PDF URL': pdf_url
        }])
        
        # DataFrameì— ì¶”ê°€
        df = pd.concat([df, new_row], ignore_index=True)
        
        logger.info(f"âœ… ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì™„ë£Œ: {user_uid[:8]}.../{cert_id[:8]}... - {lecture_title[:30]}...")
        return True, df
        
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì‹¤íŒ¨ ({user_uid[:8]}.../{cert_id[:8]}...): {e}")
        
        # ì—ëŸ¬ ê¸°ë¡
        try:
            cert_ref = db.collection('users').document(user_uid) \
                         .collection('completedCertificates').document(cert_id)
            cert_ref.update({
                'processingError': str(e)[:500],
                'errorOccurredAt': firestore.SERVER_TIMESTAMP,
                'retryCount': firestore.Increment(1)
            })
        except Exception as update_error:
            logger.error(f"âŒ ì—ëŸ¬ ê¸°ë¡ ì‹¤íŒ¨: {update_error}")
            
        return False, df
    finally:
        log_operation_end(operation_id)

def update_certificate_flags_batch(processed_certs, success=True):
    """ì²˜ë¦¬ëœ ìˆ˜ë£Œì¦ë“¤ì˜ í”Œë˜ê·¸ë¥¼ ë°°ì¹˜ë¡œ ì—…ë°ì´íŠ¸"""
    operation_id = f"flag_update_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        def update_single_flag(cert_info):
            user_uid, cert_id, cert_data = cert_info
            try:
                cert_ref = db.collection('users').document(user_uid) \
                             .collection('completedCertificates').document(cert_id)
                
                if success:
                    update_data = {
                        'excelUpdated': True,
                        'processedAt': firestore.SERVER_TIMESTAMP,
                        'processedBy': 'certificate_worker_v3'
                    }
                    
                    if 'readyForExcel' in cert_data:
                        update_data['readyForExcel'] = False
                    
                    if 'processingError' in cert_data:
                        update_data['processingError'] = firestore.DELETE_FIELD
                    
                    cert_ref.update(update_data)
                    return f"âœ… {user_uid[:8]}.../{cert_id[:8]}..."
                    
                else:
                    cert_ref.update({
                        'excelSaveError': 'Excel ì €ì¥ ì‹¤íŒ¨ - ì¬ì‹œë„ ì˜ˆì •',
                        'excelSaveErrorAt': firestore.SERVER_TIMESTAMP,
                        'retryCount': firestore.Increment(1)
                    })
                    return f"âš ï¸ {user_uid[:8]}.../{cert_id[:8]}..."
                    
            except Exception as e:
                logger.error(f"âŒ ê°œë³„ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({user_uid[:8]}...): {e}")
                return f"âŒ {user_uid[:8]}.../{cert_id[:8]}..."
        
        # ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ 3ê°œ ìŠ¤ë ˆë“œ)
        with ThreadPoolExecutor(max_workers=3) as executor:
            results = list(executor.map(update_single_flag, processed_certs))
        
        success_count = sum(1 for r in results if r.startswith('âœ…'))
        total_count = len(results)
        
        if success:
            logger.info(f"âœ… í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {success_count}/{total_count}")
        else:
            logger.warning(f"âš ï¸ ì¬ì‹œë„ ëŒ€ìƒ ì„¤ì •: {success_count}/{total_count}")
            
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    finally:
        log_operation_end(operation_id)

def process_batch():
    """ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰ (ì™„ì „ ê°œì„ )"""
    operation_id = f"batch_{int(time.time())}"
    log_operation_start(operation_id)
    
    try:
        batch_start_time = datetime.now(timezone.utc)
        
        # ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ ì¡°íšŒ
        pending_certs = get_pending_certificates_safe(limit=BATCH_SIZE)
        
        if not pending_certs:
            logger.debug("ğŸ˜´ ì²˜ë¦¬í•  ìˆ˜ë£Œì¦ì´ ì—†ìŠµë‹ˆë‹¤")
            return
        
        logger.info(f"ğŸš€ {len(pending_certs)}ê°œ ìˆ˜ë£Œì¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
        
        # ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ
        df = get_or_create_master_excel()
        original_row_count = len(df)
        
        # ì²˜ë¦¬ í†µê³„
        success_count = 0
        error_count = 0
        processed_certs = []
        
        # ê° ìˆ˜ë£Œì¦ ì²˜ë¦¬
        for i, (user_uid, cert_id, cert_data) in enumerate(pending_certs, 1):
            if shutdown_flag:
                logger.info("ğŸ›‘ ì¢…ë£Œ í”Œë˜ê·¸ ê°ì§€, ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ë‹¨")
                break
            
            # ì§„í–‰ë¥  ë¡œê¹…
            if len(pending_certs) > 5 and i % max(1, len(pending_certs) // 5) == 0:
                progress = (i / len(pending_certs)) * 100
                logger.info(f"ğŸ“Š ì²˜ë¦¬ ì§„í–‰ë¥ : {progress:.0f}% ({i}/{len(pending_certs)})")
            
            success, df = process_certificate_safe(user_uid, cert_id, cert_data, df)
            
            if success:
                success_count += 1
                processed_certs.append((user_uid, cert_id, cert_data))
            else:
                error_count += 1
        
        # Excel ì €ì¥ ë° í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
        if success_count > 0:
            new_row_count = len(df)
            logger.info(f"ğŸ“Š Excel ì €ì¥ ì‹œë„: {original_row_count}í–‰ â†’ {new_row_count}í–‰ (+{new_row_count - original_row_count})")
            
            excel_save_success = save_master_excel_safe(df)
            update_certificate_flags_batch(processed_certs, success=excel_save_success)
            
            if excel_save_success:
                processing_time = (datetime.now(timezone.utc) - batch_start_time).total_seconds()
                logger.info(f"ğŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - âœ…ì„±ê³µ: {success_count}, âŒì‹¤íŒ¨: {error_count}, â±ï¸ì‹œê°„: {processing_time:.1f}ì´ˆ")
            else:
                logger.error(f"âŒ Excel ì €ì¥ ì‹¤íŒ¨ - ìˆ˜ë£Œì¦ë“¤ì´ ì¬ì‹œë„ë©ë‹ˆë‹¤")
        else:
            logger.info(f"ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ í•­ëª© ì—†ìŒ (âŒì‹¤íŒ¨: {error_count})")
        
    except Exception as e:
        logger.error(f"âŒ ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
    finally:
        log_operation_end(operation_id)

def get_statistics():
    """í˜„ì¬ í†µê³„ ì •ë³´ ì¡°íšŒ (ìºì‹±ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)"""
    try:
        # 30ì´ˆ ìºì‹±
        current_time = time.time()
        if hasattr(get_statistics, 'cache_time') and (current_time - get_statistics.cache_time) < 30:
            return get_statistics.cached_stats
        
        # ìƒ˜í”Œë§ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ
        sample_size = 100
        
        try:
            # Collection Group ì¿¼ë¦¬ ì‹œë„
            pending_query = db.collection_group('completedCertificates') \
                             .where('excelUpdated', '==', False).limit(sample_size)
            pending_count = len(list(pending_query.stream()))
            
            processed_query = db.collection_group('completedCertificates') \
                               .where('excelUpdated', '==', True).limit(sample_size)
            processed_count = len(list(processed_query.stream()))
            
        except Exception as cg_error:
            logger.debug(f"í†µê³„ Collection Group ì¿¼ë¦¬ ì‹¤íŒ¨, ì¶”ì •ì¹˜ ì‚¬ìš©: {cg_error}")
            pending_count = -1
            processed_count = -1
        
        stats = {
            'pending': pending_count,
            'processed': processed_count,
            'total': pending_count + processed_count if pending_count >= 0 else -1,
            'is_sample': True,
            'sample_size': sample_size
        }
        
        # ìºì‹œ ì €ì¥
        get_statistics.cached_stats = stats
        get_statistics.cache_time = current_time
        
        return stats
        
    except Exception as e:
        logger.error(f"âŒ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return {'pending': -1, 'processed': -1, 'total': -1, 'error': str(e)}

# ===================================================================
# ë©”ì¸ ë£¨í”„ (ì•ˆì •ì„± ë° ëª¨ë‹ˆí„°ë§ ê°•í™”)
# ===================================================================
def run_worker():
    """ë©”ì¸ ì›Œì»¤ ë£¨í”„"""
    logger.info(f"ğŸš€ Certificate Worker v3.0 ì‹œì‘ (ì™„ì „ ê°œì„  ë²„ì „)")
    logger.info(f"â±ï¸ í´ë§ ê°„ê²©: {POLL_INTERVAL_SECONDS}ì´ˆ")
    logger.info(f"ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
    logger.info(f"ğŸ”„ ìµœëŒ€ ì¬ì‹œë„: {MAX_RETRY_COUNT}")
    
    # ì´ˆê¸° ì„¤ì • ë° í…ŒìŠ¤íŠ¸
    update_health_status()
    
    # Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
    if not test_collection_group_query():
        logger.warning("âš ï¸ Collection Group ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨, í´ë°± ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤")
    
    # ì‹œì‘ ì‹œ í†µê³„
    initial_stats = get_statistics()
    logger.info(f"ğŸ“Š ì´ˆê¸° í†µê³„ - ëŒ€ê¸°: {initial_stats['pending']}, ì²˜ë¦¬ì™„ë£Œ: {initial_stats['processed']}")
    
    iteration = 0
    last_activity_time = None
    consecutive_empty_batches = 0
    
    while not shutdown_flag:
        try:
            iteration += 1
            
            # í—¬ìŠ¤ì²´í¬ ì—…ë°ì´íŠ¸
            update_health_status()
            
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            batch_start_time = datetime.now(timezone.utc)
            
            # í˜„ì¬ ì‘ì—… ìˆ˜ ì²´í¬
            if len(current_operations) > 5:
                logger.warning(f"âš ï¸ ë„ˆë¬´ ë§ì€ ë™ì‹œ ì‘ì—…: {len(current_operations)}ê°œ")
                time.sleep(3)
                continue
            
            # ì´ì „ í†µê³„ ì €ì¥
            prev_stats = get_statistics()
            
            # ë°°ì¹˜ ì²˜ë¦¬
            process_batch()
            
            # ì²˜ë¦¬ í›„ í†µê³„ í™•ì¸
            current_stats = get_statistics()
            
            # í™œë™ ê°ì§€
            if current_stats['pending'] != prev_stats['pending']:
                last_activity_time = batch_start_time
                consecutive_empty_batches = 0
            else:
                consecutive_empty_batches += 1
            
            # ìƒíƒœ ë¡œê¹… (ì ì‘ì  ì£¼ê¸°)
            log_interval = 3 if consecutive_empty_batches > 5 else 6
            if iteration % log_interval == 0:
                stats = current_stats
                logger.info(f"ğŸ“ˆ ìƒíƒœ - ë°˜ë³µ: {iteration}, ëŒ€ê¸°: {stats['pending']}, ì²˜ë¦¬ì™„ë£Œ: {stats['processed']}")
                logger.info(f"ğŸ”§ í™œì„± ì‘ì—…: {len(current_operations)}ê°œ")
                
                if last_activity_time:
                    idle_time = (datetime.now(timezone.utc) - last_activity_time).total_seconds()
                    logger.info(f"ğŸ• ë§ˆì§€ë§‰ í™œë™: {idle_time:.0f}ì´ˆ ì „")
            
            # ë™ì  ëŒ€ê¸° ì‹œê°„
            if consecutive_empty_batches > 3:
                sleep_time = min(POLL_INTERVAL_SECONDS * 2, 120)  # ìµœëŒ€ 2ë¶„
                logger.debug(f"ğŸ˜´ ì—°ì† ë¹ˆ ë°°ì¹˜, ëŒ€ê¸° ì‹œê°„ ì—°ì¥: {sleep_time}ì´ˆ")
            else:
                sleep_time = POLL_INTERVAL_SECONDS
            
            # ì¸í„°ëŸ½íŠ¸ ê°€ëŠ¥í•œ ëŒ€ê¸°
            for _ in range(sleep_time):
                if shutdown_flag:
                    break
                time.sleep(1)
                
        except KeyboardInterrupt:
            logger.info("âŒ¨ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸")
            break
        except Exception as e:
            logger.error(f"âŒ ì›Œì»¤ ë£¨í”„ ì˜¤ë¥˜: {e}")
            error_sleep = min(POLL_INTERVAL_SECONDS, 30)
            logger.info(f"ğŸ”„ {error_sleep}ì´ˆ í›„ ì¬ì‹œì‘...")
            time.sleep(error_sleep)
    
    # ì¢…ë£Œ ì‹œ ì •ë¦¬
    with operations_lock:
        if current_operations:
            logger.info(f"ğŸ”„ {len(current_operations)}ê°œ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°...")
            for _ in range(30):
                if not current_operations:
                    break
                time.sleep(1)
    
    logger.info("ğŸ‘‹ Certificate Worker ì•ˆì „ ì¢…ë£Œ ì™„ë£Œ")

# ===================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ===================================================================
if __name__ == "__main__":
    try:
        # í™˜ê²½ ê²€ì¦
        logger.info("ğŸ” í™˜ê²½ ê²€ì¦ ì¤‘...")
        
        # Firebase ì—°ê²° ì¬í™•ì¸
        test_collection = db.collection('_worker_health_check')
        test_doc = test_collection.document('startup_test')
        test_doc.set({
            'timestamp': firestore.SERVER_TIMESTAMP,
            'worker': 'certificate_worker_v3',
            'startup_time': datetime.now(timezone.utc).isoformat()
        })
        test_doc.delete()
        
        logger.info("âœ… í™˜ê²½ ê²€ì¦ ì™„ë£Œ")
        
        # ì›Œì»¤ ì‹œì‘
        run_worker()
        
    except Exception as e:
        logger.error(f"âŒ ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)