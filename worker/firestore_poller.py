# worker/realtime_certificate_worker.py - ë°±ì—”ë“œ ìˆ˜ì • ì—†ì´ ì‹¤ì‹œê°„ ì²˜ë¦¬

import os
import io
import time
import logging
import signal
import sys
import threading
from datetime import datetime, timedelta
import pandas as pd
import firebase_admin
from firebase_admin import credentials, firestore, storage
from concurrent.futures import ThreadPoolExecutor
import queue

# ===================================================================
# ë¡œê¹… ì„¤ì •
# ===================================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger('RealtimeCertificateWorker')

# ===================================================================
# í™˜ê²½ë³€ìˆ˜ ë° ì„¤ì •
# ===================================================================
REALTIME_POLL_INTERVAL = int(os.getenv('REALTIME_POLL_INTERVAL', '5'))  # 5ì´ˆë§ˆë‹¤ ì²´í¬
BACKGROUND_POLL_INTERVAL = int(os.getenv('BACKGROUND_POLL_INTERVAL', '120'))  # 2ë¶„ë§ˆë‹¤ ì²´í¬
BATCH_SIZE = int(os.getenv('BATCH_SIZE', '20'))
MASTER_FILENAME = "master_certificates.xlsx"

# ===================================================================
# Firebase ì´ˆê¸°í™”
# ===================================================================
def initialize_firebase():
    """Firebase Admin SDK ì´ˆê¸°í™”"""
    try:
        if not firebase_admin._apps:
            firebase_creds = {
                "type": os.environ.get("type", "service_account"),
                "project_id": os.environ["project_id"],
                "private_key_id": os.environ.get("private_key_id", ""),
                "private_key": os.environ["private_key"].replace('\\n', '\n'),
                "client_email": os.environ["client_email"],
                "client_id": os.environ.get("client_id", ""),
                "auth_uri": os.environ.get("auth_uri", "https://accounts.google.com/o/oauth2/auth"),
                "token_uri": os.environ.get("token_uri", "https://oauth2.googleapis.com/token"),
                "auth_provider_x509_cert_url": os.environ.get("auth_provider_x509_cert_url", "https://www.googleapis.com/oauth2/v1/certs"),
                "client_x509_cert_url": os.environ.get("client_x509_cert_url", "")
            }
            
            cred = credentials.Certificate(firebase_creds)
            firebase_admin.initialize_app(cred, {
                'storageBucket': f"{os.environ['project_id']}.appspot.com"
            })
            
        db = firestore.client()
        bucket = storage.bucket()
        
        logger.info(f"âœ… Firebase ì´ˆê¸°í™” ì™„ë£Œ - Project: {os.environ['project_id']}")
        return db, bucket
        
    except Exception as e:
        logger.error(f"âŒ Firebase ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise

# Firebase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
db, bucket = initialize_firebase()

# ===================================================================
# ì „ì—­ ë³€ìˆ˜
# ===================================================================
shutdown_flag = False
processing_queue = queue.Queue()
realtime_stats = {
    'processed_realtime': 0,
    'processed_background': 0,
    'failed': 0,
    'last_activity': None
}

def signal_handler(signum, frame):
    """ì¢…ë£Œ ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
    global shutdown_flag
    logger.info(f"ğŸ›‘ ì¢…ë£Œ ì‹œê·¸ë„ ë°›ìŒ ({signum}). ì•ˆì „í•˜ê²Œ ì¢…ë£Œí•©ë‹ˆë‹¤...")
    shutdown_flag = True

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ===================================================================
# ìˆ˜ë£Œì¦ ì²˜ë¦¬ í•µì‹¬ í•¨ìˆ˜ë“¤
# ===================================================================

def update_health_status():
    """í—¬ìŠ¤ì²´í¬ íŒŒì¼ ì—…ë°ì´íŠ¸"""
    try:
        with open('/tmp/worker_healthy', 'w') as f:
            f.write(f"healthy at {datetime.utcnow().isoformat()}")
    except Exception as e:
        logger.warning(f"í—¬ìŠ¤ íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

def is_valid_pdf_url(pdf_url):
    """PDF URL ìœ íš¨ì„± ê²€ì‚¬"""
    if not pdf_url:
        return False, "PDF URLì´ ë¹„ì–´ìˆìŒ"
    
    if not isinstance(pdf_url, str):
        return False, f"PDF URLì´ ë¬¸ìì—´ì´ ì•„ë‹˜: {type(pdf_url)}"
    
    pdf_url = pdf_url.strip()
    if not pdf_url:
        return False, "PDF URLì´ ê³µë°±ë§Œ í¬í•¨"
    
    if not pdf_url.startswith('https://firebasestorage.googleapis.com'):
        return False, f"Firebase Storage URLì´ ì•„ë‹˜: {pdf_url[:100]}..."
    
    return True, "ìœ íš¨í•¨"

def get_fresh_certificates(limit=20):
    """
    ìµœê·¼ ìƒì„±ëœ ìˆ˜ë£Œì¦ ì¡°íšŒ (5ë¶„ ì´ë‚´)
    ì‹¤ì‹œê°„ ì²˜ë¦¬ìš©
    """
    try:
        # 5ë¶„ ì´ë‚´ ìƒì„±ëœ ê²ƒë“¤ë§Œ
        recent_threshold = datetime.utcnow() - timedelta(minutes=5)
        
        query = db.collection_group('completedCertificates') \
                  .where('readyForExcel', '==', True) \
                  .where('excelUpdated', '==', False) \
                  .limit(limit * 2)  # ì—¬ìœ ë¶„ í™•ë³´
        
        results = []
        for doc in query.stream():
            try:
                data = doc.to_dict()
                issued_at = data.get('issuedAt')
                
                # ìµœê·¼ ìƒì„±ëœ ê²ƒì¸ì§€ í™•ì¸
                if hasattr(issued_at, 'to_datetime'):
                    issued_time = issued_at.to_datetime().replace(tzinfo=None)
                    if issued_time >= recent_threshold:
                        
                        # PDF URL ê²€ì¦
                        pdf_url = data.get('pdfUrl', '')
                        is_valid, reason = is_valid_pdf_url(pdf_url)
                        
                        if is_valid:
                            path_parts = doc.reference.path.split('/')
                            if len(path_parts) >= 4:
                                user_uid = path_parts[1]
                                cert_id = doc.id
                                results.append((user_uid, cert_id, data, 'fresh'))
                                
                                if len(results) >= limit:
                                    break
                        else:
                            # ë¬´íš¨í•œ PDF URLì€ ì—ëŸ¬ ë§ˆí‚¹
                            mark_as_error(doc.reference, f"PDF URL ê²€ì¦ ì‹¤íŒ¨: {reason}")
                            
            except Exception as e:
                logger.error(f"ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜ {doc.id}: {e}")
        
        if results:
            logger.info(f"ğŸš€ ì‹¤ì‹œê°„ ì²˜ë¦¬ ëŒ€ìƒ: {len(results)}ê°œ")
        return results
        
    except Exception as e:
        logger.error(f"âŒ ìµœì‹  ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def get_old_pending_certificates(limit=30):
    """
    ì˜¤ë˜ëœ ë¯¸ì²˜ë¦¬ ìˆ˜ë£Œì¦ ì¡°íšŒ (5ë¶„ ì´ìƒ)
    ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ìš©
    """
    try:
        old_threshold = datetime.utcnow() - timedelta(minutes=5)
        
        query = db.collection_group('completedCertificates') \
                  .where('readyForExcel', '==', True) \
                  .where('excelUpdated', '==', False) \
                  .limit(limit * 2)
        
        results = []
        for doc in query.stream():
            try:
                data = doc.to_dict()
                issued_at = data.get('issuedAt')
                
                # ì˜¤ë˜ëœ ê²ƒì¸ì§€ í™•ì¸
                if hasattr(issued_at, 'to_datetime'):
                    issued_time = issued_at.to_datetime().replace(tzinfo=None)
                    if issued_time < old_threshold:
                        
                        # PDF URL ê²€ì¦
                        pdf_url = data.get('pdfUrl', '')
                        is_valid, reason = is_valid_pdf_url(pdf_url)
                        
                        if is_valid:
                            path_parts = doc.reference.path.split('/')
                            if len(path_parts) >= 4:
                                user_uid = path_parts[1]
                                cert_id = doc.id
                                results.append((user_uid, cert_id, data, 'old'))
                                
                                if len(results) >= limit:
                                    break
                        else:
                            mark_as_error(doc.reference, f"PDF URL ê²€ì¦ ì‹¤íŒ¨: {reason}")
                            
            except Exception as e:
                logger.error(f"ë¬¸ì„œ íŒŒì‹± ì˜¤ë¥˜ {doc.id}: {e}")
        
        if results:
            logger.info(f"ğŸ•°ï¸ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ëŒ€ìƒ: {len(results)}ê°œ")
        return results
        
    except Exception as e:
        logger.error(f"âŒ ì˜¤ë˜ëœ ìˆ˜ë£Œì¦ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def get_user_info(user_uid):
    """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
    try:
        user_doc = db.collection('users').document(user_uid).get()
        
        if user_doc.exists:
            user_data = user_doc.to_dict()
            return {
                'name': user_data.get('name', ''),
                'phone': user_data.get('phone', ''),
                'email': user_data.get('email', '')
            }
        else:
            logger.warning(f"ì‚¬ìš©ì ë¬¸ì„œ ì—†ìŒ: {user_uid}")
            return {'name': '', 'phone': '', 'email': ''}
            
    except Exception as e:
        logger.error(f"ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ ({user_uid}): {e}")
        return {'name': '', 'phone': '', 'email': ''}

def get_or_create_master_excel():
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            master_blob = bucket.blob(MASTER_FILENAME)
            
            try:
                existing_bytes = master_blob.download_as_bytes()
                excel_buffer = io.BytesIO(existing_bytes)
                df = pd.read_excel(excel_buffer, engine='openpyxl')
                logger.debug(f"ğŸ“¥ ê¸°ì¡´ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ì™„ë£Œ (í–‰ ìˆ˜: {len(df)})")
                
                # Cert ID ì»¬ëŸ¼ í™•ì¸
                if 'Cert ID' not in df.columns:
                    df['Cert ID'] = ""
                    
            except Exception:
                logger.info("ğŸ“„ ìƒˆ ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ìƒì„±")
                df = pd.DataFrame(columns=[
                    'ì—…ë°ì´íŠ¸ ë‚ ì§œ', 'ì‚¬ìš©ì UID', 'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼',
                    'ì‚¬ìš©ì ì´ë¦„', 'ê°•ì˜ ì œëª©', 'ë°œê¸‰ ì¼ì‹œ', 'PDF URL', 'Cert ID'
                ])
                
            return df
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2
                logger.warning(f"âš ï¸ ì—‘ì…€ ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}), {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time.sleep(wait_time)
            else:
                logger.error(f"âŒ ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {e}")
                raise

def save_master_excel(df):
    """ë§ˆìŠ¤í„° ì—‘ì…€ íŒŒì¼ ì €ì¥ (ì¬ì‹œë„ í¬í•¨)"""
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            out_buffer = io.BytesIO()
            with pd.ExcelWriter(out_buffer, engine='openpyxl') as writer:
                df.to_excel(writer, index=False, sheet_name='Certificates')
            out_buffer.seek(0)
            
            master_blob = bucket.blob(MASTER_FILENAME)
            master_blob.upload_from_file(
                out_buffer,
                content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )
            
            logger.debug("âœ… ë§ˆìŠ¤í„° ì—‘ì…€ ì €ì¥ ì™„ë£Œ")
            return True
            
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = (attempt + 1) * 2
                logger.warning(f"âš ï¸ ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}), {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time.sleep(wait_time)
            else:
                logger.error(f"âŒ ë§ˆìŠ¤í„° ì—‘ì…€ ì €ì¥ ìµœì¢… ì‹¤íŒ¨: {e}")
                return False

def process_certificate_batch(certificates, process_type='realtime'):
    """
    ìˆ˜ë£Œì¦ ë°°ì¹˜ ì²˜ë¦¬ (ìŠ¤ë ˆë“œ ì•ˆì „)
    """
    if not certificates:
        return 0, 0
    
    try:
        # ë§ˆìŠ¤í„° ì—‘ì…€ ë¡œë“œ (í•œ ë²ˆë§Œ)
        df = get_or_create_master_excel()
        initial_count = len(df)
        
        success_count = 0
        error_count = 0
        
        # ê° ìˆ˜ë£Œì¦ ì²˜ë¦¬
        for user_uid, cert_id, cert_data, reason in certificates:
            if shutdown_flag:
                break
                
            try:
                # ì¤‘ë³µ í™•ì¸
                if not df.empty and 'Cert ID' in df.columns:
                    existing_cert_ids = df['Cert ID'].astype(str).values
                    if cert_id in existing_cert_ids:
                        logger.info(f"ğŸ”„ ì´ë¯¸ ì—‘ì…€ì— ì¡´ì¬: {cert_id}")
                        mark_as_processed(user_uid, cert_id, process_type)
                        success_count += 1
                        continue
                
                # ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
                user_info = get_user_info(user_uid)
                
                # ë°œê¸‰ ì‹œê°„ ì²˜ë¦¬
                issued_at = cert_data.get('issuedAt')
                if hasattr(issued_at, 'to_datetime'):
                    issued_str = issued_at.to_datetime().strftime('%Y-%m-%d %H:%M:%S')
                else:
                    issued_str = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
                
                # ìƒˆ í–‰ ì¶”ê°€
                updated_date = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
                new_row = pd.DataFrame([{
                    'ì—…ë°ì´íŠ¸ ë‚ ì§œ': updated_date,
                    'ì‚¬ìš©ì UID': user_uid,
                    'ì „í™”ë²ˆí˜¸': user_info['phone'],
                    'ì´ë©”ì¼': user_info['email'],
                    'ì‚¬ìš©ì ì´ë¦„': user_info['name'],
                    'ê°•ì˜ ì œëª©': cert_data.get('lectureTitle', cert_id),
                    'ë°œê¸‰ ì¼ì‹œ': issued_str,
                    'PDF URL': cert_data.get('pdfUrl', ''),
                    'Cert ID': cert_id
                }])
                
                df = pd.concat([df, new_row], ignore_index=True)
                
                # Firestore í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
                if mark_as_processed(user_uid, cert_id, process_type):
                    success_count += 1
                    logger.info(f"âœ… {process_type} ì²˜ë¦¬ ì™„ë£Œ: {user_uid}/{cert_id}")
                else:
                    error_count += 1
                    
            except Exception as e:
                error_count += 1
                logger.error(f"âŒ ìˆ˜ë£Œì¦ ì²˜ë¦¬ ì‹¤íŒ¨ ({user_uid}/{cert_id}): {e}")
                mark_as_error_with_details(user_uid, cert_id, str(e))
        
        # ë³€ê²½ì‚¬í•­ì´ ìˆìœ¼ë©´ ì €ì¥
        if success_count > 0:
            if save_master_excel(df):
                final_count = len(df)
                added_count = final_count - initial_count
                logger.info(f"ğŸ“Š {process_type} ë°°ì¹˜ ì™„ë£Œ - ì„±ê³µ: {success_count}, ì‹¤íŒ¨: {error_count}, ì¶”ê°€ëœ í–‰: {added_count}")
            else:
                logger.error(f"âŒ {process_type} ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨")
                return 0, success_count + error_count
        
        return success_count, error_count
        
    except Exception as e:
        logger.error(f"âŒ {process_type} ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return 0, len(certificates)

def mark_as_processed(user_uid, cert_id, process_type):
    """Firestore ë¬¸ì„œì— ì²˜ë¦¬ ì™„ë£Œ ë§ˆí‚¹"""
    try:
        cert_ref = db.collection('users').document(user_uid) \
                     .collection('completedCertificates').document(cert_id)
        
        update_data = {
            'excelUpdated': True,
            'readyForExcel': False,
            'processedAt': firestore.SERVER_TIMESTAMP,
            'processedBy': f'realtime_worker_{process_type}'
        }
        
        # ê¸°ì¡´ ì—ëŸ¬ í•„ë“œë“¤ ì œê±°
        cert_snapshot = cert_ref.get()
        if cert_snapshot.exists:
            existing_data = cert_snapshot.to_dict()
            if existing_data.get('excelUpdateError'):
                update_data['excelUpdateError'] = firestore.DELETE_FIELD
            if existing_data.get('errorOccurredAt'):
                update_data['errorOccurredAt'] = firestore.DELETE_FIELD
        
        cert_ref.update(update_data)
        return True
        
    except Exception as e:
        logger.error(f"âŒ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ ({user_uid}/{cert_id}): {e}")
        return False

def mark_as_error(doc_ref, error_message):
    """ë¬¸ì„œì— ì—ëŸ¬ ìƒíƒœ ë§ˆí‚¹"""
    try:
        doc_ref.update({
            'excelUpdateError': error_message,
            'errorOccurredAt': firestore.SERVER_TIMESTAMP,
            'readyForExcel': False
        })
    except Exception as e:
        logger.error(f"ì—ëŸ¬ ë§ˆí‚¹ ì‹¤íŒ¨: {e}")

def mark_as_error_with_details(user_uid, cert_id, error_message):
    """ìƒì„¸ ì—ëŸ¬ ë§ˆí‚¹"""
    try:
        cert_ref = db.collection('users').document(user_uid) \
                     .collection('completedCertificates').document(cert_id)
        cert_ref.update({
            'excelUpdateError': error_message,
            'errorOccurredAt': firestore.SERVER_TIMESTAMP,
            'readyForExcel': False
        })
    except Exception as e:
        logger.error(f"ìƒì„¸ ì—ëŸ¬ ë§ˆí‚¹ ì‹¤íŒ¨ ({user_uid}/{cert_id}): {e}")

# ===================================================================
# ì´ì¤‘ ëª¨ë“œ ì›Œì»¤: ì‹¤ì‹œê°„ + ë°±ê·¸ë¼ìš´ë“œ
# ===================================================================

def realtime_worker():
    """ì‹¤ì‹œê°„ ì›Œì»¤ ìŠ¤ë ˆë“œ (5ì´ˆë§ˆë‹¤ ì²´í¬)"""
    logger.info("ğŸš€ ì‹¤ì‹œê°„ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    while not shutdown_flag:
        try:
            # ìµœê·¼ ìƒì„±ëœ ìˆ˜ë£Œì¦ ì¡°íšŒ
            fresh_certs = get_fresh_certificates(limit=BATCH_SIZE)
            
            if fresh_certs:
                success, failed = process_certificate_batch(fresh_certs, 'realtime')
                realtime_stats['processed_realtime'] += success
                realtime_stats['failed'] += failed
                realtime_stats['last_activity'] = datetime.utcnow()
            
            # ì§§ì€ ê°„ê²©ìœ¼ë¡œ ëŒ€ê¸°
            for _ in range(REALTIME_POLL_INTERVAL):
                if shutdown_flag:
                    break
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"âŒ ì‹¤ì‹œê°„ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            time.sleep(10)
    
    logger.info("ğŸ‘‹ ì‹¤ì‹œê°„ ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

def background_worker():
    """ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ (2ë¶„ë§ˆë‹¤ ì²´í¬)"""
    logger.info("ğŸ•°ï¸ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    while not shutdown_flag:
        try:
            # ì˜¤ë˜ëœ ë¯¸ì²˜ë¦¬ ìˆ˜ë£Œì¦ ì¡°íšŒ
            old_certs = get_old_pending_certificates(limit=BATCH_SIZE)
            
            if old_certs:
                success, failed = process_certificate_batch(old_certs, 'background')
                realtime_stats['processed_background'] += success
                realtime_stats['failed'] += failed
                realtime_stats['last_activity'] = datetime.utcnow()
            
            # ê¸´ ê°„ê²©ìœ¼ë¡œ ëŒ€ê¸°
            for _ in range(BACKGROUND_POLL_INTERVAL):
                if shutdown_flag:
                    break
                time.sleep(1)
                
        except Exception as e:
            logger.error(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ì˜¤ë¥˜: {e}")
            time.sleep(30)
    
    logger.info("ğŸ‘‹ ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

def statistics_worker():
    """í†µê³„ ë¡œê¹… ìŠ¤ë ˆë“œ (10ë¶„ë§ˆë‹¤)"""
    logger.info("ğŸ“Š í†µê³„ ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    while not shutdown_flag:
        try:
            # 10ë¶„ë§ˆë‹¤ í†µê³„ ë¡œê¹…
            for _ in range(600):  # 10ë¶„ = 600ì´ˆ
                if shutdown_flag:
                    break
                time.sleep(1)
            
            if not shutdown_flag:
                logger.info(f"ğŸ“ˆ ëˆ„ì  í†µê³„:")
                logger.info(f"  ğŸš€ ì‹¤ì‹œê°„ ì²˜ë¦¬: {realtime_stats['processed_realtime']}")
                logger.info(f"  ğŸ•°ï¸ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬: {realtime_stats['processed_background']}")
                logger.info(f"  âŒ ì‹¤íŒ¨: {realtime_stats['failed']}")
                logger.info(f"  ğŸ• ë§ˆì§€ë§‰ í™œë™: {realtime_stats['last_activity']}")
                
        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    
    logger.info("ğŸ‘‹ í†µê³„ ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ")

# ===================================================================
# ë©”ì¸ í•¨ìˆ˜
# ===================================================================

def run_dual_mode_worker():
    """ì´ì¤‘ ëª¨ë“œ ì›Œì»¤ ì‹¤í–‰"""
    logger.info("ğŸš€ ì‹¤ì‹œê°„ ìˆ˜ë£Œì¦ ì›Œì»¤ ì‹œì‘")
    logger.info(f"   âš¡ ì‹¤ì‹œê°„ ì²´í¬: {REALTIME_POLL_INTERVAL}ì´ˆë§ˆë‹¤")
    logger.info(f"   ğŸ•°ï¸ ë°±ê·¸ë¼ìš´ë“œ ì²´í¬: {BACKGROUND_POLL_INTERVAL}ì´ˆë§ˆë‹¤")
    logger.info(f"   ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")
    
    # ì´ˆê¸° í—¬ìŠ¤ ìƒíƒœ
    update_health_status()
    
    # ìŠ¤ë ˆë“œ í’€ ìƒì„±
    threads = []
    
    try:
        # ì‹¤ì‹œê°„ ì›Œì»¤ ìŠ¤ë ˆë“œ
        realtime_thread = threading.Thread(target=realtime_worker, daemon=True)
        realtime_thread.start()
        threads.append(realtime_thread)
        
        # ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ìŠ¤ë ˆë“œ
        background_thread = threading.Thread(target=background_worker, daemon=True)
        background_thread.start()
        threads.append(background_thread)
        
        # í†µê³„ ì›Œì»¤ ìŠ¤ë ˆë“œ
        stats_thread = threading.Thread(target=statistics_worker, daemon=True)
        stats_thread.start()
        threads.append(stats_thread)
        
        # ë©”ì¸ ë£¨í”„ (í—¬ìŠ¤ì²´í¬ë§Œ)
        while not shutdown_flag:
            update_health_status()
            time.sleep(30)  # 30ì´ˆë§ˆë‹¤ í—¬ìŠ¤ì²´í¬
            
    except KeyboardInterrupt:
        logger.info("âŒ¨ï¸ í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸")
    except Exception as e:
        logger.error(f"âŒ ë©”ì¸ ì›Œì»¤ ì˜¤ë¥˜: {e}")
    finally:
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        logger.info("ğŸ›‘ ëª¨ë“  ì›Œì»¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸° ì¤‘...")
        for thread in threads:
            if thread.is_alive():
                thread.join(timeout=10)
        
        logger.info("ğŸ ì‹¤ì‹œê°„ ìˆ˜ë£Œì¦ ì›Œì»¤ ì¢…ë£Œ ì™„ë£Œ")
        logger.info(f"ğŸ“Š ìµœì¢… í†µê³„:")
        logger.info(f"   ğŸš€ ì‹¤ì‹œê°„ ì²˜ë¦¬: {realtime_stats['processed_realtime']}")
        logger.info(f"   ğŸ•°ï¸ ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬: {realtime_stats['processed_background']}")
        logger.info(f"   âŒ ì´ ì‹¤íŒ¨: {realtime_stats['failed']}")

# ===================================================================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# ===================================================================

if __name__ == "__main__":
    try:
        run_dual_mode_worker()
    except Exception as e:
        logger.error(f"âŒ ì›Œì»¤ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)